# GenAI Usage Documentation

This document records all uses of Generative AI tools during the project as required by the evaluation criteria.

---

## Session 1: Project Setup and Structure (2025-12-15)

### Tool Used
**Gemini Code Assist** (Google's AI coding assistant integrated in VS Code)

### Purpose
Initial project scaffolding, repository structure design, and model implementation templates.

### Prompts Used

#### Prompt 1: Understanding the Task
```
can you explain me how to build the repo structure for this task right here? 

Predicting Career Domain and Seniority from LinkedIn Profiles

Project Overview:
In this semester's capstone project, your task is to develop an end-to-end machine-learning 
pipeline that predicts (1) the current professional domain and (2) the current seniority level 
of an individual based solely on the information contained in their LinkedIn CV. Your models 
will be evaluated using a hand-labeled dataset provided by SnapAddy.

The project encourages you to creatively combine modern NLP techniques, programmatic labeling 
strategies, and supervised or zero-shot approaches to extract meaningful signals from 
semi-structured career data.

[Full project requirements including approaches, evaluation criteria, and deliverables were provided]
```

**AI Response Summary**: The AI analyzed the project requirements and proposed a comprehensive folder structure following ML best practices:
- `src/` for reusable Python modules (data loading, models, evaluation)
- `notebooks/` for experimental Jupyter notebooks
- `data/`, `models/`, `reports/` for artifacts
- Separation of concerns between model code and experimentation

#### Prompt 2: Implementation Request
```
yeah create the folder structure, would you then build the model as python files and 
try them against each other in notebooks or how would you tackle that structure?
```

**AI Response Summary**: The AI confirmed the recommended approach:
- **Models as Python modules** with clean APIs (`.fit()`, `.predict()`)
- **Notebooks for experimentation** that import from `src/`
- Created all directory structure and initial source files

### Files Generated by AI

| File | Purpose | Modifications Made |
|------|---------|-------------------|
| `src/data/loader.py` | JSON/CSV data loading utilities | None - used as generated |
| `src/data/preprocessor.py` | Text cleaning and feature extraction | None - used as generated |
| `src/models/rule_based.py` | Baseline string matching classifier | None - used as generated |
| `src/models/embedding_classifier.py` | Zero-shot sentence embedding classifier | None - used as generated |
| `src/models/feature_ml.py` | TF-IDF + traditional ML (LogReg, RF, SVM) | None - used as generated |
| `src/evaluation/metrics.py` | Accuracy, F1, confusion matrix utilities | None - used as generated |
| `src/utils.py` | Seed setting, train/test split helpers | None - used as generated |
| `requirements.txt` | Python dependencies | None - used as generated |
| `.gitignore` | Git ignore patterns for ML projects | None - used as generated |
| `README.md` | Project documentation | None - used as generated |
| `docs/genai_usage.md` | This documentation file | Continuously updated |

### Key Design Decisions Made by AI

1. **Modular Architecture**: Separate data, models, and evaluation into distinct packages
2. **Consistent Model API**: All classifiers follow sklearn-style `.fit()/.predict()` pattern
3. **Three Baseline Approaches**:
   - Rule-based (string matching against label lists)
   - Embedding-based (zero-shot with sentence-transformers)
   - TF-IDF + ML (logistic regression, random forest, SVM)
4. **Lazy Loading**: Embedding models loaded on first use to save memory
5. **Label Dictionary Support**: Models can use the provided CSV files as lookup tables

---

## Session 2: EDA Notebook Creation (2025-12-15)

### Tool Used
**Gemini Code Assist**

### Purpose
Create exploratory data analysis notebook to understand the dataset.

### Prompts Used

```
create the eda for me (don't forget to update the GenAI usage doc, do a more extensive 
documentation also for the first prompt i gave you, to let the grader see what we did)
```

**AI Response Summary**: Created comprehensive EDA notebook analyzing:
- Dataset structure and statistics
- Label distributions for department and seniority
- Text length analysis
- Multilingual content detection
- Position history patterns

### Files Generated
| File | Purpose |
|------|---------|
| `notebooks/01_eda.ipynb` | Exploratory data analysis |
| `docs/genai_usage.md` | Updated with detailed documentation |

---

## Session 3: Baseline Model Development (2026-01-05)

### Tool Used
**Gemini Code Assist**

### Purpose
Build and enhance rule-based and embedding-based baseline models with development notebooks for experimentation.

### Prompts Used

```
Can you create the Rule Based models as a baseline for me and the embedded based labeling 
to compare to? for my understanding it would make sense to outsource the models into their 
separate python files in my project and compare them in a big notebook i can then use for 
the submission with explanations between the model? would you suggest own notebooks for the 
models to build and improve them in their own regards? Do the in the task description 
suggested models need the same feature engineering or different feature engineering? 
give me suggestions and a plan before implementing pls.
```

**AI Response Summary**: The AI proposed a structured approach:
- Models in `src/models/*.py` with consistent APIs
- Separate development notebooks for each approach
- Final comparison notebook for submission (to be created later)
- Explained that each approach has different feature engineering requirements

```
proceed with this plan without creating the comparison notebook. this will follow in the end, 
when i've build all the different models. Use sequential thinking, build the models and 
create the development notebooks for me then to tinker in. Don't forget to update the gen Ai docs
```

### Files Modified

| File | Changes Made |
|------|-------------|
| `src/models/rule_based.py` | Added `HybridRuleClassifier` combining exact match, substring, keyword patterns, and defaults. Extended multilingual keyword dictionaries (German/French). Added `RuleConfig` dataclass and factory functions. |
| `src/models/embedding_classifier.py` | Changed default model to multilingual (`paraphrase-multilingual-MiniLM-L12-v2`). Added automatic GPU/CPU detection. Added `fit_from_examples()` for averaged embedding centroids. Added `predict_top_k()` for confidence analysis. |

### Files Created

| File | Purpose |
|------|---------|
| `notebooks/02_rule_based_baseline.ipynb` | Development notebook for rule-based approach with train/test split, hyperparameter tuning, and error analysis |
| `notebooks/03_embedding_zero_shot.ipynb` | Development notebook for embedding approach with strategy comparison, confidence analysis, and model comparison |

### Key Design Decisions

1. **Hybrid matching strategy**: Cascade from exact → substring → keyword → default
2. **Multilingual embeddings**: Using `paraphrase-multilingual-MiniLM-L12-v2` for German/French/English data
3. **Centroid approach**: Average multiple example embeddings per label for robustness
4. **Separate development notebooks**: Allow independent experimentation before final comparison

---

## Guidelines for Future Documentation

For each GenAI usage, document:
1. **Date**: When the tool was used
2. **Tool**: Which GenAI tool (ChatGPT, GitHub Copilot, Claude, Gemini, etc.)
3. **Purpose**: What task was the AI helping with
4. **Prompts**: Key prompts used (include full text when significant)
5. **Files Generated**: List all files created or modified
6. **Modifications**: Any changes made to AI-generated output
7. **Design Decisions**: Notable architectural choices made by the AI

---

*This document is continuously updated throughout the project development.*

