# GenAI Usage Documentation

This document records all uses of Generative AI tools during the project as required by the evaluation criteria.

---

## Session 1: Project Setup and Structure (2025-12-15)

### Tool Used
**Gemini Code Assist** (Google's AI coding assistant integrated in VS Code)

### Purpose
Initial project scaffolding, repository structure design, and model implementation templates.

### Prompts Used

#### Prompt 1: Understanding the Task
```
can you explain me how to build the repo structure for this task right here? 

Predicting Career Domain and Seniority from LinkedIn Profiles

Project Overview:
In this semester's capstone project, your task is to develop an end-to-end machine-learning 
pipeline that predicts (1) the current professional domain and (2) the current seniority level 
of an individual based solely on the information contained in their LinkedIn CV. Your models 
will be evaluated using a hand-labeled dataset provided by SnapAddy.

The project encourages you to creatively combine modern NLP techniques, programmatic labeling 
strategies, and supervised or zero-shot approaches to extract meaningful signals from 
semi-structured career data.

[Full project requirements including approaches, evaluation criteria, and deliverables were provided]
```

**AI Response Summary**: The AI analyzed the project requirements and proposed a comprehensive folder structure following ML best practices:
- `src/` for reusable Python modules (data loading, models, evaluation)
- `notebooks/` for experimental Jupyter notebooks
- `data/`, `models/`, `reports/` for artifacts
- Separation of concerns between model code and experimentation

#### Prompt 2: Implementation Request
```
yeah create the folder structure, would you then build the model as python files and 
try them against each other in notebooks or how would you tackle that structure?
```

**AI Response Summary**: The AI confirmed the recommended approach:
- **Models as Python modules** with clean APIs (`.fit()`, `.predict()`)
- **Notebooks for experimentation** that import from `src/`
- Created all directory structure and initial source files

### Files Generated by AI

| File | Purpose | Modifications Made |
|------|---------|-------------------|
| `src/data/loader.py` | JSON/CSV data loading utilities | None - used as generated |
| `src/data/preprocessor.py` | Text cleaning and feature extraction | None - used as generated |
| `src/models/rule_based.py` | Baseline string matching classifier | None - used as generated |
| `src/models/embedding_classifier.py` | Zero-shot sentence embedding classifier | None - used as generated |
| `src/models/feature_ml.py` | TF-IDF + traditional ML (LogReg, RF, SVM) | None - used as generated |
| `src/evaluation/metrics.py` | Accuracy, F1, confusion matrix utilities | None - used as generated |
| `src/utils.py` | Seed setting, train/test split helpers | None - used as generated |
| `requirements.txt` | Python dependencies | None - used as generated |
| `.gitignore` | Git ignore patterns for ML projects | None - used as generated |
| `README.md` | Project documentation | None - used as generated |
| `docs/genai_usage.md` | This documentation file | Continuously updated |

### Key Design Decisions Made by AI

1. **Modular Architecture**: Separate data, models, and evaluation into distinct packages
2. **Consistent Model API**: All classifiers follow sklearn-style `.fit()/.predict()` pattern
3. **Three Baseline Approaches**:
   - Rule-based (string matching against label lists)
   - Embedding-based (zero-shot with sentence-transformers)
   - TF-IDF + ML (logistic regression, random forest, SVM)
4. **Lazy Loading**: Embedding models loaded on first use to save memory
5. **Label Dictionary Support**: Models can use the provided CSV files as lookup tables

---

## Session 2: EDA Notebook Creation (2025-12-15)

### Tool Used
**Gemini Code Assist**

### Purpose
Create exploratory data analysis notebook to understand the dataset.

### Prompts Used

```
create the eda for me (don't forget to update the GenAI usage doc, do a more extensive 
documentation also for the first prompt i gave you, to let the grader see what we did)
```

**AI Response Summary**: Created comprehensive EDA notebook analyzing:
- Dataset structure and statistics
- Label distributions for department and seniority
- Text length analysis
- Multilingual content detection
- Position history patterns

### Files Generated
| File | Purpose |
|------|---------|
| `notebooks/01_eda.ipynb` | Exploratory data analysis |
| `docs/genai_usage.md` | Updated with detailed documentation |

---

## Guidelines for Future Documentation

For each GenAI usage, document:
1. **Date**: When the tool was used
2. **Tool**: Which GenAI tool (ChatGPT, GitHub Copilot, Claude, Gemini, etc.)
3. **Purpose**: What task was the AI helping with
4. **Prompts**: Key prompts used (include full text when significant)
5. **Files Generated**: List all files created or modified
6. **Modifications**: Any changes made to AI-generated output
7. **Design Decisions**: Notable architectural choices made by the AI

---

*This document is continuously updated throughout the project development.*
