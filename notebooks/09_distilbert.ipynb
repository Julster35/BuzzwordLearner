{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - DistilBERT Experiments\n",
    "\n",
    "Ziel dieses Notebooks:\n",
    "- Erst ein plain DistilBERT Baseline-Training.\n",
    "- Danach ein kleines Hyperparameter Tuning.\n",
    "- Danach vier weitere Experimente, um systematisch Hypothesen zu testen.\n",
    "\n",
    "Alle Abschnitte enthalten kurze Erklaerungen, was genau getestet wird und warum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Wir importieren alle benoetigten Bibliotheken, setzen einen Seed und definieren Standard-Parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68555b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import random\n",
    "import warnings\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path('/Users/batuklkn/Desktop/GustAbgabe/BuzzwordLearner/data')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "BASE_MODEL = 'distilbert-base-multilingual-cased'\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    'model_name': BASE_MODEL,\n",
    "    'epochs': 3,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'use_class_weights': False\n",
    "}\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "\n",
    "\n",
    "def _fix_encoding(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    try:\n",
    "        if 'Ãƒ' in text:\n",
    "            return text.encode('latin-1').decode('utf-8', errors='ignore')\n",
    "    except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "        pass\n",
    "    return text\n",
    "\n",
    "\n",
    "def deduplicate_label_df(label_df, max_per_class=500):\n",
    "    label_df = label_df.copy()\n",
    "    label_df['text_normalized'] = label_df['text'].str.lower().str.strip()\n",
    "    original_count = len(label_df)\n",
    "    label_df = label_df.drop_duplicates(subset=['text_normalized', 'label'])\n",
    "    dedup_count = len(label_df)\n",
    "\n",
    "    if max_per_class is not None:\n",
    "        label_df = label_df.groupby('label', group_keys=False).apply(\n",
    "            lambda x: x.sample(min(len(x), max_per_class), random_state=42)\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    final_count = len(label_df)\n",
    "    label_df = label_df.drop(columns=['text_normalized'])\n",
    "\n",
    "    print(f\"  Deduplication: {original_count} -> {dedup_count} (removed {original_count - dedup_count} duplicates)\")\n",
    "    if max_per_class is not None:\n",
    "        print(f\"  Capping: {dedup_count} -> {final_count} (max {max_per_class} per class)\")\n",
    "\n",
    "    return label_df\n",
    "\n",
    "\n",
    "def balance_dataset(df, label_col='label', min_samples=500, max_samples=2000, return_weights=False):\n",
    "    balanced_dfs = []\n",
    "    weights = []\n",
    "\n",
    "    class_counts = df[label_col].value_counts()\n",
    "\n",
    "    for label, count in class_counts.items():\n",
    "        class_df = df[df[label_col] == label]\n",
    "\n",
    "        if count < min_samples:\n",
    "            n_repeats = min_samples // count\n",
    "            remainder = min_samples % count\n",
    "            repeated = pd.concat([class_df] * n_repeats, ignore_index=True)\n",
    "            if remainder > 0:\n",
    "                repeated = pd.concat([repeated, class_df.sample(remainder, random_state=42)], ignore_index=True)\n",
    "            balanced_dfs.append(repeated)\n",
    "            weights.extend([0.8] * len(repeated))\n",
    "        elif count > max_samples:\n",
    "            sampled = class_df.sample(max_samples, random_state=42)\n",
    "            balanced_dfs.append(sampled)\n",
    "            weights.extend([1.0] * len(sampled))\n",
    "        else:\n",
    "            balanced_dfs.append(class_df)\n",
    "            weights.extend([1.0] * len(class_df))\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "    print(f\"Balancing: {len(df)} -> {len(balanced_df)} samples\")\n",
    "    print(f\"  Class distribution: {balanced_df[label_col].value_counts().to_dict()}\")\n",
    "\n",
    "    if return_weights:\n",
    "        return balanced_df, weights\n",
    "    return balanced_df, None\n",
    "\n",
    "\n",
    "def load_linkedin_data(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_dataset(cvs, include_history=False):\n",
    "    records = []\n",
    "\n",
    "    for cv_idx, cv in enumerate(cvs):\n",
    "        if isinstance(cv, list):\n",
    "            positions = cv\n",
    "        else:\n",
    "            positions = cv.get('positions', cv) if isinstance(cv, dict) else []\n",
    "\n",
    "        active_positions = [p for p in positions if p.get('status') == 'ACTIVE']\n",
    "\n",
    "        if not active_positions:\n",
    "            continue\n",
    "\n",
    "        active = active_positions[0]\n",
    "\n",
    "        title = active.get('position', active.get('title', ''))\n",
    "        company = active.get('organization', active.get('companyName', ''))\n",
    "\n",
    "        record = {\n",
    "            'cv_id': cv_idx,\n",
    "            'title': title,\n",
    "            'company': company,\n",
    "            'text': f\"{title} at {company}\".strip() if company else title,\n",
    "        }\n",
    "\n",
    "        if 'department' in active:\n",
    "            record['department'] = active['department']\n",
    "        if 'seniority' in active:\n",
    "            record['seniority'] = active['seniority']\n",
    "\n",
    "        if include_history:\n",
    "            past_positions = [p for p in positions if p.get('status') != 'ACTIVE']\n",
    "            record['history'] = ' | '.join([\n",
    "                p.get('position', p.get('title', '')) for p in past_positions\n",
    "            ])\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def load_label_lists(data_dir, fix_encoding=True, deduplicate=True, max_per_class=500):\n",
    "    data_path = Path(data_dir)\n",
    "\n",
    "    department_df = pd.read_csv(data_path / 'department-v2.csv', encoding='utf-8')\n",
    "    seniority_df = pd.read_csv(data_path / 'seniority-v2.csv', encoding='utf-8')\n",
    "\n",
    "    if fix_encoding:\n",
    "        print('Applying encoding fix...')\n",
    "        department_df['text'] = department_df['text'].apply(_fix_encoding)\n",
    "        seniority_df['text'] = seniority_df['text'].apply(_fix_encoding)\n",
    "\n",
    "    if deduplicate:\n",
    "        print('Deduplicating department labels...')\n",
    "        department_df = deduplicate_label_df(department_df, max_per_class)\n",
    "        print('Deduplicating seniority labels...')\n",
    "        seniority_df = deduplicate_label_df(seniority_df, max_per_class)\n",
    "\n",
    "    return department_df, seniority_df\n",
    "\n",
    "\n",
    "def load_evaluation_dataset(data_dir):\n",
    "    data_path = Path(data_dir)\n",
    "    cvs = load_linkedin_data(str(data_path / 'linkedin-cvs-annotated.json'))\n",
    "    return prepare_dataset(cvs)\n",
    "\n",
    "\n",
    "class JobTitleDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop('labels')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        if self.class_weights is not None:\n",
    "            weight = torch.tensor(self.class_weights, device=logits.device, dtype=logits.dtype)\n",
    "            loss_fn = CrossEntropyLoss(weight=weight)\n",
    "        else:\n",
    "            loss_fn = CrossEntropyLoss()\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "class TransformerClassifier:\n",
    "    def __init__(self, model_name='distilbert-base-multilingual-cased', num_labels=2, id2label=None, label2id=None):\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        self.id2label = id2label or {}\n",
    "        self.label2id = label2id or {}\n",
    "\n",
    "        self.tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        print(f\"Model loaded on {self.device}\")\n",
    "\n",
    "    def train(self, texts, labels, val_texts=None, val_labels=None, epochs=3, batch_size=16, learning_rate=1e-5, warmup_ratio=0.1, use_class_weights=False):\n",
    "        print(f\"Training on {len(texts)} examples...\")\n",
    "\n",
    "        train_encodings = self.tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "        train_dataset = JobTitleDataset(train_encodings, labels)\n",
    "\n",
    "        if val_texts is not None and val_labels is not None:\n",
    "            val_encodings = self.tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n",
    "            val_dataset = JobTitleDataset(val_encodings, val_labels)\n",
    "            eval_strategy = 'epoch'\n",
    "        else:\n",
    "            val_dataset = None\n",
    "            eval_strategy = 'no'\n",
    "\n",
    "        class_weights = None\n",
    "        if use_class_weights:\n",
    "            from sklearn.utils.class_weight import compute_class_weight\n",
    "            unique_labels = np.unique(labels)\n",
    "            class_weights = compute_class_weight('balanced', classes=unique_labels, y=labels)\n",
    "            print(f\"Using class weights: {dict(zip(unique_labels, class_weights))}\")\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=tmp_dir,\n",
    "                num_train_epochs=epochs,\n",
    "                per_device_train_batch_size=batch_size,\n",
    "                per_device_eval_batch_size=batch_size,\n",
    "                warmup_ratio=warmup_ratio,\n",
    "                weight_decay=0.01,\n",
    "                evaluation_strategy=eval_strategy,\n",
    "                save_strategy='no',\n",
    "                logging_strategy='no',\n",
    "                learning_rate=learning_rate,\n",
    "                report_to='none',\n",
    "                disable_tqdm=True\n",
    "            )\n",
    "\n",
    "            if class_weights is not None:\n",
    "                trainer = WeightedTrainer(\n",
    "                    class_weights=class_weights,\n",
    "                    model=self.model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=val_dataset\n",
    "                )\n",
    "            else:\n",
    "                trainer = Trainer(\n",
    "                    model=self.model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=val_dataset\n",
    "                )\n",
    "\n",
    "            trainer.train()\n",
    "\n",
    "        print('Training complete!')\n",
    "\n",
    "    def predict(self, texts, batch_size=32):\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = self.tokenizer(\n",
    "                batch_texts, padding=True, truncation=True, max_length=128, return_tensors='pt'\n",
    "            ).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                all_predictions.extend(predictions.cpu().tolist())\n",
    "\n",
    "        return all_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c24ed",
   "metadata": {},
   "source": [
    "## 2. Daten laden\n",
    "\n",
    "Wir trainieren auf den Lookup-Tabellen und evaluieren auf den annotierten CVs.\n",
    "Das entspricht dem Zero-Shot/Transfer-Setup der vorherigen Notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup-Tabellen (Training)\n",
    "dept_df, sen_df = load_label_lists(\n",
    "    DATA_DIR,\n",
    "    fix_encoding=True,\n",
    "    deduplicate=True,\n",
    "    max_per_class=None\n",
    ")\n",
    "\n",
    "# Annotierte CVs (Evaluation)\n",
    "eval_df = load_evaluation_dataset(DATA_DIR)\n",
    "\n",
    "print(f\"Department lookup: {len(dept_df):,} examples\")\n",
    "print(f\"Seniority lookup:  {len(sen_df):,} examples\")\n",
    "print(f\"Annotated CVs:     {len(eval_df):,} positions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e5b26",
   "metadata": {},
   "source": [
    "## 3. Hilfsfunktionen\n",
    "\n",
    "Wir kapseln den wiederholten Code fuer Mapping, Training und Evaluation in Funktionen.\n",
    "Das macht die Experimente konsistent und leichter vergleichbar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ed5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_label_maps(label_series):\n",
    "    labels = sorted(label_series.unique())\n",
    "    label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "    id2label = {idx: label for label, idx in label2id.items()}\n",
    "    return label2id, id2label\n",
    "\n",
    "\n",
    "def prepare_eval_data(eval_df, label_col, label2id, text_col='title'):\n",
    "    subset = eval_df[eval_df[label_col].notna()].copy()\n",
    "    subset = subset[subset[label_col].isin(label2id.keys())]\n",
    "    texts = subset[text_col].fillna('').tolist()\n",
    "    labels = [label2id[l] for l in subset[label_col].tolist()]\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def compute_metrics(true_ids, pred_ids, id2label):\n",
    "    acc = accuracy_score(true_ids, pred_ids)\n",
    "    precision, recall, f1_macro, _ = precision_recall_fscore_support(\n",
    "        true_ids, pred_ids, average='macro', zero_division=0\n",
    "    )\n",
    "    f1_weighted = precision_recall_fscore_support(\n",
    "        true_ids, pred_ids, average='weighted', zero_division=0\n",
    "    )[2]\n",
    "\n",
    "    labels = sorted(set(true_ids) | set(pred_ids))\n",
    "    _, _, f1_per_class, _ = precision_recall_fscore_support(\n",
    "        true_ids, pred_ids, labels=labels, average=None, zero_division=0\n",
    "    )\n",
    "    per_class_f1 = {id2label[i]: float(f1_per_class[idx]) for idx, i in enumerate(labels)}\n",
    "\n",
    "    return {\n",
    "        'accuracy': float(acc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_macro': float(f1_macro),\n",
    "        'f1_weighted': float(f1_weighted),\n",
    "        'per_class_f1': per_class_f1\n",
    "    }\n",
    "\n",
    "\n",
    "def freeze_base_layers(clf):\n",
    "    base = None\n",
    "    if hasattr(clf.model, 'base_model_prefix'):\n",
    "        prefix = clf.model.base_model_prefix\n",
    "        base = getattr(clf.model, prefix, None)\n",
    "    if base is None:\n",
    "        base = getattr(clf.model, 'base_model', None)\n",
    "    if base is None and hasattr(clf.model, 'distilbert'):\n",
    "        base = clf.model.distilbert\n",
    "\n",
    "    if base is None:\n",
    "        print('Could not find base model to freeze')\n",
    "        return\n",
    "\n",
    "    for param in base.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    print('Base layers frozen')\n",
    "\n",
    "\n",
    "def train_eval_distilbert(\n",
    "    task_name,\n",
    "    train_df,\n",
    "    eval_df,\n",
    "    label_col,\n",
    "    config,\n",
    "    text_col='title',\n",
    "    eval_real_world=True,\n",
    "    freeze_base=False\n",
    "):\n",
    "    label2id, id2label = build_label_maps(train_df['label'])\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_df['text'].tolist(),\n",
    "        train_df['label'].tolist(),\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=train_df['label']\n",
    "    )\n",
    "\n",
    "    y_train_ids = [label2id[l] for l in y_train]\n",
    "    y_val_ids = [label2id[l] for l in y_val]\n",
    "\n",
    "    clf = TransformerClassifier(\n",
    "        model_name=config['model_name'],\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    if freeze_base:\n",
    "        freeze_base_layers(clf)\n",
    "\n",
    "    clf.train(\n",
    "        texts=X_train,\n",
    "        labels=y_train_ids,\n",
    "        val_texts=X_val,\n",
    "        val_labels=y_val_ids,\n",
    "        epochs=config['epochs'],\n",
    "        batch_size=config['batch_size'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        warmup_ratio=config.get('warmup_ratio', 0.1),\n",
    "        use_class_weights=config.get('use_class_weights', False)\n",
    "    )\n",
    "\n",
    "    val_pred_ids = clf.predict(X_val)\n",
    "    in_dist = compute_metrics(y_val_ids, val_pred_ids, id2label)\n",
    "\n",
    "    real_world = None\n",
    "    if eval_real_world:\n",
    "        eval_texts, eval_labels = prepare_eval_data(\n",
    "            eval_df, label_col, label2id, text_col=text_col\n",
    "        )\n",
    "        eval_pred_ids = clf.predict(eval_texts)\n",
    "        real_world = compute_metrics(eval_labels, eval_pred_ids, id2label)\n",
    "\n",
    "    return {\n",
    "        'in_distribution': in_dist,\n",
    "        'real_world': real_world,\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label\n",
    "    }, clf\n",
    "\n",
    "\n",
    "def print_summary(name, results):\n",
    "    in_acc = results['in_distribution']['accuracy']\n",
    "    in_f1 = results['in_distribution']['f1_macro']\n",
    "    if results['real_world']:\n",
    "        rw_acc = results['real_world']['accuracy']\n",
    "        rw_f1 = results['real_world']['f1_macro']\n",
    "        print(f\"{name} | in-dist acc {in_acc:.4f} f1 {in_f1:.4f} | real-world acc {rw_acc:.4f} f1 {rw_f1:.4f}\")\n",
    "    else:\n",
    "        print(f\"{name} | in-dist acc {in_acc:.4f} f1 {in_f1:.4f} | real-world skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ddf95",
   "metadata": {},
   "source": [
    "## 4. Plain DistilBERT Baseline\n",
    "\n",
    "Wir trainieren DistilBERT mit Standard-Parametern auf den Lookup-Tabellen\n",
    "und evaluieren auf den annotierten CVs. Das ist der Ausgangspunkt fuer alle\n",
    "weiteren Vergleiche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = {}\n",
    "\n",
    "# Department baseline\n",
    "base_dept, base_dept_clf = train_eval_distilbert(\n",
    "    task_name='department',\n",
    "    train_df=dept_df,\n",
    "    eval_df=eval_df,\n",
    "    label_col='department',\n",
    "    config=BASE_CONFIG\n",
    ")\n",
    "print_summary('Baseline Department', base_dept)\n",
    "\n",
    "# Seniority baseline\n",
    "base_sen, base_sen_clf = train_eval_distilbert(\n",
    "    task_name='seniority',\n",
    "    train_df=sen_df,\n",
    "    eval_df=eval_df,\n",
    "    label_col='seniority',\n",
    "    config=BASE_CONFIG\n",
    ")\n",
    "print_summary('Baseline Seniority', base_sen)\n",
    "\n",
    "baseline_results['department'] = base_dept\n",
    "baseline_results['seniority'] = base_sen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7e4a7",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning\n",
    "\n",
    "Wir testen mehrere Kombinationen aus Lernrate, Batch-Size und Epochen.\n",
    "Die Bewertung erfolgt auf dem In-Distribution Validation-Split, um fair zu\n",
    "vergleichen. Real-World Evaluation wird hier ausgelassen, um die Anzahl der\n",
    "Trainingslaeufe nicht weiter zu vergroessern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_GRID = [\n",
    "    {'learning_rate': 1e-5, 'batch_size': 16, 'epochs': 2, 'warmup_ratio': 0.1},\n",
    "    {'learning_rate': 2e-5, 'batch_size': 16, 'epochs': 2, 'warmup_ratio': 0.1},\n",
    "    {'learning_rate': 3e-5, 'batch_size': 16, 'epochs': 2, 'warmup_ratio': 0.1},\n",
    "    {'learning_rate': 2e-5, 'batch_size': 8,  'epochs': 2, 'warmup_ratio': 0.1},\n",
    "]\n",
    "\n",
    "\n",
    "def run_tuning(task_name, train_df, label_col):\n",
    "    rows = []\n",
    "    for idx, cfg in enumerate(TUNING_GRID, start=1):\n",
    "        config = BASE_CONFIG.copy()\n",
    "        config.update(cfg)\n",
    "\n",
    "        result, _ = train_eval_distilbert(\n",
    "            task_name=task_name,\n",
    "            train_df=train_df,\n",
    "            eval_df=eval_df,\n",
    "            label_col=label_col,\n",
    "            config=config,\n",
    "            eval_real_world=False\n",
    "        )\n",
    "\n",
    "        rows.append({\n",
    "            'run': idx,\n",
    "            'learning_rate': cfg['learning_rate'],\n",
    "            'batch_size': cfg['batch_size'],\n",
    "            'epochs': cfg['epochs'],\n",
    "            'warmup_ratio': cfg['warmup_ratio'],\n",
    "            'val_accuracy': result['in_distribution']['accuracy'],\n",
    "            'val_f1_macro': result['in_distribution']['f1_macro']\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "tuning_dept = run_tuning('department', dept_df, 'department')\n",
    "tuning_sen = run_tuning('seniority', sen_df, 'seniority')\n",
    "\n",
    "print('Tuning Department:')\n",
    "print(tuning_dept.sort_values('val_f1_macro', ascending=False).head(5))\n",
    "\n",
    "print('Tuning Seniority:')\n",
    "print(tuning_sen.sort_values('val_f1_macro', ascending=False).head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Weitere Experimente (4 Stueck)\n",
    "\n",
    "Jedes Experiment testet eine konkrete Hypothese. So kann man gezielt sehen,\n",
    "welche Massnahme wirklich hilft.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Class Weights\n",
    "\n",
    "Hypothese: Class-Weighted Loss hilft bei unbalancierten Klassen und verbessert\n",
    "F1 fuer Minoritaeten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_config = BASE_CONFIG.copy()\n",
    "exp1_config['use_class_weights'] = True\n",
    "\n",
    "exp1_dept, _ = train_eval_distilbert(\n",
    "    task_name='department',\n",
    "    train_df=dept_df,\n",
    "    eval_df=eval_df,\n",
    "    label_col='department',\n",
    "    config=exp1_config\n",
    ")\n",
    "print_summary('Exp1 Department', exp1_dept)\n",
    "\n",
    "exp1_sen, _ = train_eval_distilbert(\n",
    "    task_name='seniority',\n",
    "    train_df=sen_df,\n",
    "    eval_df=eval_df,\n",
    "    label_col='seniority',\n",
    "    config=exp1_config\n",
    ")\n",
    "print_summary('Exp1 Seniority', exp1_sen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Balanced Training Data\n",
    "\n",
    "Hypothese: Balancing (Over- und Undersampling) reduziert die Dominanz grosser Klassen\n",
    "und verbessert den Macro-F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance department and seniority with min/max per class\n",
    "balanced_dept, _ = balance_dataset(dept_df, min_samples=500, max_samples=2000)\n",
    "balanced_sen, _ = balance_dataset(sen_df, min_samples=500, max_samples=2000)\n",
    "\n",
    "exp2_dept, _ = train_eval_distilbert(\n",
    "    task_name='department',\n",
    "    train_df=balanced_dept,\n",
    "    eval_df=eval_df,\n",
    "    label_col='department',\n",
    "    config=BASE_CONFIG\n",
    ")\n",
    "print_summary('Exp2 Department', exp2_dept)\n",
    "\n",
    "exp2_sen, _ = train_eval_distilbert(\n",
    "    task_name='seniority',\n",
    "    train_df=balanced_sen,\n",
    "    eval_df=eval_df,\n",
    "    label_col='seniority',\n",
    "    config=BASE_CONFIG\n",
    ")\n",
    "print_summary('Exp2 Seniority', exp2_sen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Silver Data Augmentation\n",
    "\n",
    "Hypothese: Pseudo-Labels aus unannotierten CVs vergroessern die Trainingsmenge\n",
    "und verbessern die Generalisierung.\n",
    "\n",
    "Falls die Datei nicht existiert, wird das Experiment uebersprungen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_silver_data(data_dir):\n",
    "    silver_path = Path(data_dir) / 'processed' / 'unannotated_pseudo_labeled.csv'\n",
    "    if not silver_path.exists():\n",
    "        return None, None\n",
    "\n",
    "    df = pd.read_csv(silver_path)\n",
    "    if 'text' not in df.columns and 'title' in df.columns:\n",
    "        df['text'] = df['title']\n",
    "\n",
    "    dept_silver = df[df['dept_pseudo'].notna()][['text', 'dept_pseudo']].copy()\n",
    "    dept_silver = dept_silver.rename(columns={'dept_pseudo': 'label'})\n",
    "\n",
    "    sen_silver = df[df['sen_pseudo'].notna()][['text', 'sen_pseudo']].copy()\n",
    "    sen_silver = sen_silver.rename(columns={'sen_pseudo': 'label'})\n",
    "\n",
    "    return dept_silver, sen_silver\n",
    "\n",
    "\n",
    "dep_silver, sen_silver = load_silver_data(DATA_DIR)\n",
    "\n",
    "if dep_silver is None or dep_silver.empty:\n",
    "    exp3_dept = None\n",
    "    print('No department silver data found. Skipping exp3 department.')\n",
    "else:\n",
    "    dept_aug = pd.concat([dept_df[['text', 'label']], dep_silver], ignore_index=True)\n",
    "    exp3_dept, _ = train_eval_distilbert(\n",
    "        task_name='department',\n",
    "        train_df=dept_aug,\n",
    "        eval_df=eval_df,\n",
    "        label_col='department',\n",
    "        config=BASE_CONFIG\n",
    "    )\n",
    "    print_summary('Exp3 Department', exp3_dept)\n",
    "\n",
    "if sen_silver is None or sen_silver.empty:\n",
    "    exp3_sen = None\n",
    "    print('No seniority silver data found. Skipping exp3 seniority.')\n",
    "else:\n",
    "    sen_aug = pd.concat([sen_df[['text', 'label']], sen_silver], ignore_index=True)\n",
    "    exp3_sen, _ = train_eval_distilbert(\n",
    "        task_name='seniority',\n",
    "        train_df=sen_aug,\n",
    "        eval_df=eval_df,\n",
    "        label_col='seniority',\n",
    "        config=BASE_CONFIG\n",
    "    )\n",
    "    print_summary('Exp3 Seniority', exp3_sen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Freeze Base Layers\n",
    "\n",
    "Hypothese: Wenn wir nur den Klassifikationskopf trainieren, reduzieren wir Overfitting\n",
    "und die Trainingszeit. Das kann sinnvoll sein, wenn die Daten klein sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4_config = BASE_CONFIG.copy()\n",
    "exp4_config['epochs'] = 2\n",
    "\n",
    "exp4_dept, _ = train_eval_distilbert(\n",
    "    task_name='department',\n",
    "    train_df=dept_df,\n",
    "    eval_df=eval_df,\n",
    "    label_col='department',\n",
    "    config=exp4_config,\n",
    "    freeze_base=True\n",
    ")\n",
    "print_summary('Exp4 Department', exp4_dept)\n",
    "\n",
    "exp4_sen, _ = train_eval_distilbert(\n",
    "    task_name='seniority',\n",
    "    train_df=sen_df,\n",
    "    eval_df=eval_df,\n",
    "    label_col='seniority',\n",
    "    config=exp4_config,\n",
    "    freeze_base=True\n",
    ")\n",
    "print_summary('Exp4 Seniority', exp4_sen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ergebnisse speichern\n",
    "\n",
    "Wir sammeln alle Ergebnisse in einem JSON-File, damit spaetere Vergleiche\n",
    "mit anderen Notebooks leichter sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {\n",
    "    'approach': 'DistilBERT Experiments',\n",
    "    'baseline': baseline_results,\n",
    "    'tuning': {\n",
    "        'department': tuning_dept.to_dict(orient='records'),\n",
    "        'seniority': tuning_sen.to_dict(orient='records')\n",
    "    },\n",
    "    'experiments': {\n",
    "        'exp1_class_weights': {\n",
    "            'department': exp1_dept,\n",
    "            'seniority': exp1_sen\n",
    "        },\n",
    "        'exp2_balanced': {\n",
    "            'department': exp2_dept,\n",
    "            'seniority': exp2_sen\n",
    "        },\n",
    "        'exp3_silver': {\n",
    "            'department': exp3_dept,\n",
    "            'seniority': exp3_sen\n",
    "        },\n",
    "        'exp4_frozen': {\n",
    "            'department': exp4_dept,\n",
    "            'seniority': exp4_sen\n",
    "        }\n",
    "    },\n",
    "    'metadata': {\n",
    "        'base_model': BASE_MODEL,\n",
    "        'train_source': 'lookup tables',\n",
    "        'eval_source': 'annotated CVs',\n",
    "        'random_state': RANDOM_STATE\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "print('All results available in all_results.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
