{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 09 - DistilBERT Experiments\n",
        "\n",
        "Ziel dieses Notebooks:\n",
        "- Erst ein plain DistilBERT Baseline-Training.\n",
        "- Danach ein kleines Hyperparameter Tuning.\n",
        "- Danach vier weitere Experimente, um systematisch Hypothesen zu testen.\n",
        "\n",
        "Alle Abschnitte enthalten kurze Erklaerungen, was genau getestet wird und warum.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "\n",
        "Wir importieren alle benoetigten Bibliotheken, setzen einen Seed und definieren Standard-Parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "import sys\n",
        "sys.path.append('../')\n",
        "from src.data.loader import load_label_lists, load_evaluation_dataset, balance_dataset\n",
        "from src.models.transformer_classifier import TransformerClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DATA_DIR = Path('../data')\n",
        "RESULTS_DIR = Path('./results')\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "BASE_MODEL = 'distilbert-base-multilingual-cased'\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    'model_name': BASE_MODEL,\n",
        "    'epochs': 3,\n",
        "    'batch_size': 16,\n",
        "    'learning_rate': 2e-5,\n",
        "    'warmup_ratio': 0.1,\n",
        "    'use_class_weights': False\n",
        "}\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(RANDOM_STATE)\n",
        "\n",
        "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Daten laden\n",
        "\n",
        "Wir trainieren auf den Lookup-Tabellen und evaluieren auf den annotierten CVs.\n",
        "Das entspricht dem Zero-Shot/Transfer-Setup der vorherigen Notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lookup-Tabellen (Training)\n",
        "dept_df, sen_df = load_label_lists(\n",
        "    DATA_DIR,\n",
        "    fix_encoding=True,\n",
        "    deduplicate=True,\n",
        "    max_per_class=None\n",
        ")\n",
        "\n",
        "# Annotierte CVs (Evaluation)\n",
        "eval_df = load_evaluation_dataset(DATA_DIR)\n",
        "\n",
        "print(f\"Department lookup: {len(dept_df):,} examples\")\n",
        "print(f\"Seniority lookup:  {len(sen_df):,} examples\")\n",
        "print(f\"Annotated CVs:     {len(eval_df):,} positions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hilfsfunktionen\n",
        "\n",
        "Wir kapseln den wiederholten Code fuer Mapping, Training und Evaluation in Funktionen.\n",
        "Das macht die Experimente konsistent und leichter vergleichbar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_label_maps(label_series):\n",
        "    labels = sorted(label_series.unique())\n",
        "    label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "    id2label = {idx: label for label, idx in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "\n",
        "def prepare_eval_data(eval_df, label_col, label2id, text_col='title'):\n",
        "    subset = eval_df[eval_df[label_col].notna()].copy()\n",
        "    subset = subset[subset[label_col].isin(label2id.keys())]\n",
        "    texts = subset[text_col].fillna('').tolist()\n",
        "    labels = [label2id[l] for l in subset[label_col].tolist()]\n",
        "    return texts, labels\n",
        "\n",
        "\n",
        "def compute_metrics(true_ids, pred_ids, id2label):\n",
        "    acc = accuracy_score(true_ids, pred_ids)\n",
        "    precision, recall, f1_macro, _ = precision_recall_fscore_support(\n",
        "        true_ids, pred_ids, average='macro', zero_division=0\n",
        "    )\n",
        "    f1_weighted = precision_recall_fscore_support(\n",
        "        true_ids, pred_ids, average='weighted', zero_division=0\n",
        "    )[2]\n",
        "\n",
        "    labels = sorted(set(true_ids) | set(pred_ids))\n",
        "    _, _, f1_per_class, _ = precision_recall_fscore_support(\n",
        "        true_ids, pred_ids, labels=labels, average=None, zero_division=0\n",
        "    )\n",
        "    per_class_f1 = {id2label[i]: float(f1_per_class[idx]) for idx, i in enumerate(labels)}\n",
        "\n",
        "    return {\n",
        "        'accuracy': float(acc),\n",
        "        'precision': float(precision),\n",
        "        'recall': float(recall),\n",
        "        'f1_macro': float(f1_macro),\n",
        "        'f1_weighted': float(f1_weighted),\n",
        "        'per_class_f1': per_class_f1\n",
        "    }\n",
        "\n",
        "\n",
        "def freeze_base_layers(clf):\n",
        "    base = None\n",
        "    if hasattr(clf.model, 'base_model_prefix'):\n",
        "        prefix = clf.model.base_model_prefix\n",
        "        base = getattr(clf.model, prefix, None)\n",
        "    if base is None:\n",
        "        base = getattr(clf.model, 'base_model', None)\n",
        "    if base is None and hasattr(clf.model, 'distilbert'):\n",
        "        base = clf.model.distilbert\n",
        "\n",
        "    if base is None:\n",
        "        print('Could not find base model to freeze')\n",
        "        return\n",
        "\n",
        "    for param in base.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print('Base layers frozen')\n",
        "\n",
        "\n",
        "def train_eval_distilbert(\n",
        "    task_name,\n",
        "    train_df,\n",
        "    eval_df,\n",
        "    label_col,\n",
        "    config,\n",
        "    output_dir,\n",
        "    text_col='title',\n",
        "    eval_real_world=True,\n",
        "    freeze_base=False\n",
        "):\n",
        "    label2id, id2label = build_label_maps(train_df['label'])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        train_df['text'].tolist(),\n",
        "        train_df['label'].tolist(),\n",
        "        test_size=0.2,\n",
        "        random_state=RANDOM_STATE,\n",
        "        stratify=train_df['label']\n",
        "    )\n",
        "\n",
        "    y_train_ids = [label2id[l] for l in y_train]\n",
        "    y_val_ids = [label2id[l] for l in y_val]\n",
        "\n",
        "    clf = TransformerClassifier(\n",
        "        model_name=config['model_name'],\n",
        "        num_labels=len(label2id),\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "    if freeze_base:\n",
        "        freeze_base_layers(clf)\n",
        "\n",
        "    clf.train(\n",
        "        texts=X_train,\n",
        "        labels=y_train_ids,\n",
        "        val_texts=X_val,\n",
        "        val_labels=y_val_ids,\n",
        "        output_dir=output_dir,\n",
        "        epochs=config['epochs'],\n",
        "        batch_size=config['batch_size'],\n",
        "        learning_rate=config['learning_rate'],\n",
        "        warmup_ratio=config.get('warmup_ratio', 0.1),\n",
        "        use_class_weights=config.get('use_class_weights', False)\n",
        "    )\n",
        "\n",
        "    # In-distribution evaluation\n",
        "    val_pred_ids = clf.predict(X_val)\n",
        "    in_dist = compute_metrics(y_val_ids, val_pred_ids, id2label)\n",
        "\n",
        "    real_world = None\n",
        "    if eval_real_world:\n",
        "        eval_texts, eval_labels = prepare_eval_data(\n",
        "            eval_df, label_col, label2id, text_col=text_col\n",
        "        )\n",
        "        eval_pred_ids = clf.predict(eval_texts)\n",
        "        real_world = compute_metrics(eval_labels, eval_pred_ids, id2label)\n",
        "\n",
        "    return {\n",
        "        'in_distribution': in_dist,\n",
        "        'real_world': real_world,\n",
        "        'label2id': label2id,\n",
        "        'id2label': id2label\n",
        "    }, clf\n",
        "\n",
        "\n",
        "def print_summary(name, results):\n",
        "    in_acc = results['in_distribution']['accuracy']\n",
        "    in_f1 = results['in_distribution']['f1_macro']\n",
        "    if results['real_world']:\n",
        "        rw_acc = results['real_world']['accuracy']\n",
        "        rw_f1 = results['real_world']['f1_macro']\n",
        "        print(f\"{name} | in-dist acc {in_acc:.4f} f1 {in_f1:.4f} | real-world acc {rw_acc:.4f} f1 {rw_f1:.4f}\")\n",
        "    else:\n",
        "        print(f\"{name} | in-dist acc {in_acc:.4f} f1 {in_f1:.4f} | real-world skipped\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Plain DistilBERT Baseline\n",
        "\n",
        "Wir trainieren DistilBERT mit Standard-Parametern auf den Lookup-Tabellen\n",
        "und evaluieren auf den annotierten CVs. Das ist der Ausgangspunkt fuer alle\n",
        "weiteren Vergleiche.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_results = {}\n",
        "\n",
        "# Department baseline\n",
        "base_dept, base_dept_clf = train_eval_distilbert(\n",
        "    task_name='department',\n",
        "    train_df=dept_df,\n",
        "    eval_df=eval_df,\n",
        "    label_col='department',\n",
        "    config=BASE_CONFIG,\n",
        "    output_dir='./results/09_distilbert/baseline/department'\n",
        ")\n",
        "print_summary('Baseline Department', base_dept)\n",
        "\n",
        "# Seniority baseline\n",
        "base_sen, base_sen_clf = train_eval_distilbert(\n",
        "    task_name='seniority',\n",
        "    train_df=sen_df,\n",
        "    eval_df=eval_df,\n",
        "    label_col='seniority',\n",
        "    config=BASE_CONFIG,\n",
        "    output_dir='./results/09_distilbert/baseline/seniority'\n",
        ")\n",
        "print_summary('Baseline Seniority', base_sen)\n",
        "\n",
        "baseline_results['department'] = base_dept\n",
        "baseline_results['seniority'] = base_sen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Hyperparameter Tuning\n",
        "\n",
        "Wir testen mehrere Kombinationen aus Lernrate, Batch-Size und Epochen.\n",
        "Die Bewertung erfolgt auf dem In-Distribution Validation-Split, um fair zu\n",
        "vergleichen. Real-World Evaluation wird hier ausgelassen, um die Anzahl der\n",
        "Trainingslaeufe nicht weiter zu vergroessern.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TUNING_GRID = [\n",
        "    {'learning_rate': 1e-5, 'batch_size': 16, 'epochs': 2, 'warmup_ratio': 0.1},\n",
        "    {'learning_rate': 2e-5, 'batch_size': 16, 'epochs': 2, 'warmup_ratio': 0.1},\n",
        "    {'learning_rate': 3e-5, 'batch_size': 16, 'epochs': 2, 'warmup_ratio': 0.1},\n",
        "    {'learning_rate': 2e-5, 'batch_size': 8,  'epochs': 2, 'warmup_ratio': 0.1},\n",
        "]\n",
        "\n",
        "\n",
        "def run_tuning(task_name, train_df, label_col):\n",
        "    rows = []\n",
        "    for idx, cfg in enumerate(TUNING_GRID, start=1):\n",
        "        config = BASE_CONFIG.copy()\n",
        "        config.update(cfg)\n",
        "        output_dir = f'./results/09_distilbert/tuning/{task_name}/run_{idx}'\n",
        "\n",
        "        result, _ = train_eval_distilbert(\n",
        "            task_name=task_name,\n",
        "            train_df=train_df,\n",
        "            eval_df=eval_df,\n",
        "            label_col=label_col,\n",
        "            config=config,\n",
        "            output_dir=output_dir,\n",
        "            eval_real_world=False\n",
        "        )\n",
        "\n",
        "        rows.append({\n",
        "            'run': idx,\n",
        "            'learning_rate': cfg['learning_rate'],\n",
        "            'batch_size': cfg['batch_size'],\n",
        "            'epochs': cfg['epochs'],\n",
        "            'warmup_ratio': cfg['warmup_ratio'],\n",
        "            'val_accuracy': result['in_distribution']['accuracy'],\n",
        "            'val_f1_macro': result['in_distribution']['f1_macro']\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "tuning_dept = run_tuning('department', dept_df, 'department')\n",
        "tuning_sen = run_tuning('seniority', sen_df, 'seniority')\n",
        "\n",
        "print('Tuning Department:')\n",
        "print(tuning_dept.sort_values('val_f1_macro', ascending=False).head(5))\n",
        "\n",
        "print('\n",
        "Tuning Seniority:')\n",
        "print(tuning_sen.sort_values('val_f1_macro', ascending=False).head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Weitere Experimente (4 Stueck)\n",
        "\n",
        "Jedes Experiment testet eine konkrete Hypothese. So kann man gezielt sehen,\n",
        "welche Massnahme wirklich hilft.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 1: Class Weights\n",
        "\n",
        "Hypothese: Class-Weighted Loss hilft bei unbalancierten Klassen und verbessert\n",
        "F1 fuer Minoritaeten.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exp1_config = BASE_CONFIG.copy()\n",
        "exp1_config['use_class_weights'] = True\n",
        "\n",
        "exp1_dept, _ = train_eval_distilbert(\n",
        "    task_name='department',\n",
        "    train_df=dept_df,\n",
        "    eval_df=eval_df,\n",
        "    label_col='department',\n",
        "    config=exp1_config,\n",
        "    output_dir='./results/09_distilbert/exp1_class_weights/department'\n",
        ")\n",
        "print_summary('Exp1 Department', exp1_dept)\n",
        "\n",
        "exp1_sen, _ = train_eval_distilbert(\n",
        "    task_name='seniority',\n",
        "    train_df=sen_df,\n",
        "    eval_df=eval_df,\n",
        "    label_col='seniority',\n",
        "    config=exp1_config,\n",
        "    output_dir='./results/09_distilbert/exp1_class_weights/seniority'\n",
        ")\n",
        "print_summary('Exp1 Seniority', exp1_sen)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 2: Balanced Training Data\n",
        "\n",
        "Hypothese: Balancing (Over- und Undersampling) reduziert die Dominanz grosser Klassen\n",
        "und verbessert den Macro-F1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balance department and seniority with min/max per class\n",
        "balanced_dept, _ = balance_dataset(dept_df, min_samples=500, max_samples=2000)\n",
        "balanced_sen, _ = balance_dataset(sen_df, min_samples=500, max_samples=2000)\n",
        "\n",
        "exp2_dept, _ = train_eval_distilbert(\n",
        "    task_name='department',\n",
        "    train_df=balanced_dept,\n",
        "    eval_df=eval_df,\n",
        "    label_col='department',\n",
        "    config=BASE_CONFIG,\n",
        "    output_dir='./results/09_distilbert/exp2_balanced/department'\n",
        ")\n",
        "print_summary('Exp2 Department', exp2_dept)\n",
        "\n",
        "exp2_sen, _ = train_eval_distilbert(\n",
        "    task_name='seniority',\n",
        "    train_df=balanced_sen,\n",
        "    eval_df=eval_df,\n",
        "    label_col='seniority',\n",
        "    config=BASE_CONFIG,\n",
        "    output_dir='./results/09_distilbert/exp2_balanced/seniority'\n",
        ")\n",
        "print_summary('Exp2 Seniority', exp2_sen)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 3: Silver Data Augmentation\n",
        "\n",
        "Hypothese: Pseudo-Labels aus unannotierten CVs vergroessern die Trainingsmenge\n",
        "und verbessern die Generalisierung.\n",
        "\n",
        "Falls die Datei nicht existiert, wird das Experiment uebersprungen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_silver_data(data_dir):\n",
        "    silver_path = Path(data_dir) / 'processed' / 'unannotated_pseudo_labeled.csv'\n",
        "    if not silver_path.exists():\n",
        "        return None, None\n",
        "\n",
        "    df = pd.read_csv(silver_path)\n",
        "    if 'text' not in df.columns and 'title' in df.columns:\n",
        "        df['text'] = df['title']\n",
        "\n",
        "    dept_silver = df[df['dept_pseudo'].notna()][['text', 'dept_pseudo']].copy()\n",
        "    dept_silver = dept_silver.rename(columns={'dept_pseudo': 'label'})\n",
        "\n",
        "    sen_silver = df[df['sen_pseudo'].notna()][['text', 'sen_pseudo']].copy()\n",
        "    sen_silver = sen_silver.rename(columns={'sen_pseudo': 'label'})\n",
        "\n",
        "    return dept_silver, sen_silver\n",
        "\n",
        "\n",
        "dep_silver, sen_silver = load_silver_data(DATA_DIR)\n",
        "\n",
        "if dep_silver is None or dep_silver.empty:\n",
        "    exp3_dept = None\n",
        "    print('No department silver data found. Skipping exp3 department.')\n",
        "else:\n",
        "    dept_aug = pd.concat([dept_df[['text', 'label']], dep_silver], ignore_index=True)\n",
        "    exp3_dept, _ = train_eval_distilbert(\n",
        "        task_name='department',\n",
        "        train_df=dept_aug,\n",
        "        eval_df=eval_df,\n",
        "        label_col='department',\n",
        "        config=BASE_CONFIG,\n",
        "        output_dir='./results/09_distilbert/exp3_silver/department'\n",
        "    )\n",
        "    print_summary('Exp3 Department', exp3_dept)\n",
        "\n",
        "if sen_silver is None or sen_silver.empty:\n",
        "    exp3_sen = None\n",
        "    print('No seniority silver data found. Skipping exp3 seniority.')\n",
        "else:\n",
        "    sen_aug = pd.concat([sen_df[['text', 'label']], sen_silver], ignore_index=True)\n",
        "    exp3_sen, _ = train_eval_distilbert(\n",
        "        task_name='seniority',\n",
        "        train_df=sen_aug,\n",
        "        eval_df=eval_df,\n",
        "        label_col='seniority',\n",
        "        config=BASE_CONFIG,\n",
        "        output_dir='./results/09_distilbert/exp3_silver/seniority'\n",
        "    )\n",
        "    print_summary('Exp3 Seniority', exp3_sen)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 4: Freeze Base Layers\n",
        "\n",
        "Hypothese: Wenn wir nur den Klassifikationskopf trainieren, reduzieren wir Overfitting\n",
        "und die Trainingszeit. Das kann sinnvoll sein, wenn die Daten klein sind.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exp4_config = BASE_CONFIG.copy()\n",
        "exp4_config['epochs'] = 2\n",
        "\n",
        "exp4_dept, _ = train_eval_distilbert(\n",
        "    task_name='department',\n",
        "    train_df=dept_df,\n",
        "    eval_df=eval_df,\n",
        "    label_col='department',\n",
        "    config=exp4_config,\n",
        "    output_dir='./results/09_distilbert/exp4_frozen/department',\n",
        "    freeze_base=True\n",
        ")\n",
        "print_summary('Exp4 Department', exp4_dept)\n",
        "\n",
        "exp4_sen, _ = train_eval_distilbert(\n",
        "    task_name='seniority',\n",
        "    train_df=sen_df,\n",
        "    eval_df=eval_df,\n",
        "    label_col='seniority',\n",
        "    config=exp4_config,\n",
        "    output_dir='./results/09_distilbert/exp4_frozen/seniority',\n",
        "    freeze_base=True\n",
        ")\n",
        "print_summary('Exp4 Seniority', exp4_sen)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Ergebnisse speichern\n",
        "\n",
        "Wir sammeln alle Ergebnisse in einem JSON-File, damit spaetere Vergleiche\n",
        "mit anderen Notebooks leichter sind.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_results = {\n",
        "    'approach': 'DistilBERT Experiments',\n",
        "    'baseline': baseline_results,\n",
        "    'tuning': {\n",
        "        'department': tuning_dept.to_dict(orient='records'),\n",
        "        'seniority': tuning_sen.to_dict(orient='records')\n",
        "    },\n",
        "    'experiments': {\n",
        "        'exp1_class_weights': {\n",
        "            'department': exp1_dept,\n",
        "            'seniority': exp1_sen\n",
        "        },\n",
        "        'exp2_balanced': {\n",
        "            'department': exp2_dept,\n",
        "            'seniority': exp2_sen\n",
        "        },\n",
        "        'exp3_silver': {\n",
        "            'department': exp3_dept,\n",
        "            'seniority': exp3_sen\n",
        "        },\n",
        "        'exp4_frozen': {\n",
        "            'department': exp4_dept,\n",
        "            'seniority': exp4_sen\n",
        "        }\n",
        "    },\n",
        "    'metadata': {\n",
        "        'base_model': BASE_MODEL,\n",
        "        'train_source': 'lookup tables',\n",
        "        'eval_source': 'annotated CVs',\n",
        "        'random_state': RANDOM_STATE\n",
        "    },\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "output_path = RESULTS_DIR / 'distilbert_experiments.json'\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(f'Results saved to: {output_path}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
