{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ab4ca2",
   "metadata": {},
   "source": [
    "# 09 - Lexicon-Supervised TF-IDF Baseline\n",
    "\n",
    "**Constraint**: Annotated CVs must NOT be used for training, only for evaluation.\n",
    "\n",
    "**Training Data**:\n",
    "- `department-v2.csv` - Lookup table (text → department labels)\n",
    "- `seniority-v2.csv` - Lookup table (text → seniority labels)\n",
    "\n",
    "**Evaluation Data**:\n",
    "- `linkedin-cvs-annotated.json` - ONLY for final evaluation (ACTIVE entries)\n",
    "\n",
    "**Approach**:\n",
    "1. Train TF-IDF + LogisticRegression on lookup tables only\n",
    "2. Extract structural features from unannotated CVs (experience duration)\n",
    "3. Post-process seniority predictions with experience heuristics\n",
    "4. Evaluate on annotated CVs (test-only)\n",
    "\n",
    "**Goal**: Demonstrate how far lexicon-supervised learning can go without labeled CV training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b66fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "RESULTS_DIR = Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc11cc",
   "metadata": {},
   "source": [
    "## 1. Text Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f792526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Light text normalization: lowercase and whitespace cleanup.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        \n",
    "    Returns:\n",
    "        Normalized text\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove common suffixes\n",
    "    text = text.replace('(m/f/d)', '').replace('(m/w/d)', '')\n",
    "    text = text.replace('(m/f)', '').replace('(w/m)', '')\n",
    "    \n",
    "    # Whitespace cleanup\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def create_input_text(entry: Dict[str, Any], include_org: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Create input text from a job entry.\n",
    "    \n",
    "    Args:\n",
    "        entry: Job entry dictionary\n",
    "        include_org: Whether to include organization name\n",
    "        \n",
    "    Returns:\n",
    "        Concatenated text string\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Add position/title\n",
    "    position = entry.get('position', '') or entry.get('title', '')\n",
    "    if position and isinstance(position, str):\n",
    "        parts.append(position.strip())\n",
    "    \n",
    "    # Add organization\n",
    "    if include_org:\n",
    "        org = entry.get('organization', '') or entry.get('company', '')\n",
    "        if org and isinstance(org, str):\n",
    "            parts.append(org.strip())\n",
    "    \n",
    "    # Add description (first 200 chars)\n",
    "    desc = entry.get('description', '') or entry.get('text', '')\n",
    "    if desc and isinstance(desc, str):\n",
    "        desc_clean = desc.strip()[:200]\n",
    "        if desc_clean:\n",
    "            parts.append(desc_clean)\n",
    "    \n",
    "    return ' '.join(parts) if parts else 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfbc17",
   "metadata": {},
   "source": [
    "## 2. Load Training Data (Lookup Tables Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae86c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load department lookup table\n",
    "print(\"Loading training data (lookup tables only)...\")\n",
    "dept_df = pd.read_csv(DATA_DIR / 'department-v2.csv')\n",
    "sen_df = pd.read_csv(DATA_DIR / 'seniority-v2.csv')\n",
    "\n",
    "# Inspect actual column names and adapt\n",
    "print(f\"\\nDepartment lookup: {len(dept_df):,} examples\")\n",
    "print(f\"  Columns: {dept_df.columns.tolist()}\")\n",
    "\n",
    "# Determine column names (flexible handling)\n",
    "dept_text_col = 'text' if 'text' in dept_df.columns else dept_df.columns[0]\n",
    "dept_label_col = 'department' if 'department' in dept_df.columns else dept_df.columns[1]\n",
    "\n",
    "sen_text_col = 'text' if 'text' in sen_df.columns else sen_df.columns[0]\n",
    "sen_label_col = 'seniority' if 'seniority' in sen_df.columns else sen_df.columns[1]\n",
    "\n",
    "print(f\"  Using columns: text='{dept_text_col}', label='{dept_label_col}'\")\n",
    "print(f\"  Classes: {dept_df[dept_label_col].nunique()}\")\n",
    "print(f\"  Distribution:\\n{dept_df[dept_label_col].value_counts()}\")\n",
    "\n",
    "print(f\"\\nSeniority lookup: {len(sen_df):,} examples\")\n",
    "print(f\"  Columns: {sen_df.columns.tolist()}\")\n",
    "print(f\"  Using columns: text='{sen_text_col}', label='{sen_label_col}'\")\n",
    "print(f\"  Classes: {sen_df[sen_label_col].nunique()}\")\n",
    "print(f\"  Distribution:\\n{sen_df[sen_label_col].value_counts()}\")\n",
    "\n",
    "# Normalize text in lookup tables\n",
    "dept_df['text_normalized'] = dept_df[dept_text_col].apply(normalize_text)\n",
    "sen_df['text_normalized'] = sen_df[sen_text_col].apply(normalize_text)\n",
    "\n",
    "# Store label column names for later use\n",
    "dept_df['label'] = dept_df[dept_label_col]\n",
    "sen_df['label'] = sen_df[sen_label_col]\n",
    "\n",
    "print(\"\\n✓ Text normalization applied to lookup tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa0b64",
   "metadata": {},
   "source": [
    "## 3. Build TF-IDF Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_pipeline(max_features_word: int = 5000, \n",
    "                        max_features_char: int = 3000) -> FeatureUnion:\n",
    "    \"\"\"\n",
    "    Create TF-IDF feature union combining word and character n-grams.\n",
    "    \n",
    "    Args:\n",
    "        max_features_word: Max features for word n-grams\n",
    "        max_features_char: Max features for character n-grams\n",
    "        \n",
    "    Returns:\n",
    "        FeatureUnion pipeline\n",
    "    \"\"\"\n",
    "    return FeatureUnion([\n",
    "        ('word_ngrams', TfidfVectorizer(\n",
    "            max_features=max_features_word,\n",
    "            ngram_range=(1, 2),\n",
    "            analyzer='word',\n",
    "            lowercase=True,\n",
    "            min_df=1,  # Keep all features from small lookup table\n",
    "            max_df=0.95\n",
    "        )),\n",
    "        ('char_ngrams', TfidfVectorizer(\n",
    "            max_features=max_features_char,\n",
    "            ngram_range=(3, 5),\n",
    "            analyzer='char',\n",
    "            lowercase=True,\n",
    "            min_df=1,  # Keep all features from small lookup table\n",
    "            max_df=0.95\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Create feature extractors\n",
    "print(\"Creating TF-IDF pipelines...\")\n",
    "dept_vectorizer = create_tfidf_pipeline(max_features_word=5000, max_features_char=3000)\n",
    "sen_vectorizer = create_tfidf_pipeline(max_features_word=3000, max_features_char=2000)\n",
    "\n",
    "print(\"✓ TF-IDF pipelines created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993681d",
   "metadata": {},
   "source": [
    "## 4. Train Department Classifier (on Lookup Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c606b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data from lookup table\n",
    "X_train_dept = dept_df['text_normalized'].tolist()\n",
    "y_train_dept = dept_df['label'].tolist()\n",
    "\n",
    "print(f\"Training Department classifier on lookup table...\")\n",
    "print(f\"  Training samples: {len(X_train_dept)}\")\n",
    "print(f\"  Classes: {len(set(y_train_dept))}\")\n",
    "\n",
    "# Fit vectorizer and transform\n",
    "dept_X_train = dept_vectorizer.fit_transform(X_train_dept)\n",
    "print(f\"  Feature dimension: {dept_X_train.shape[1]:,}\")\n",
    "\n",
    "# Train classifier\n",
    "dept_classifier = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=1.0,\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial',\n",
    "    random_state=RANDOM_SEED,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "dept_classifier.fit(dept_X_train, y_train_dept)\n",
    "print(\"✓ Department classifier trained\")\n",
    "print(f\"  Classes: {dept_classifier.classes_.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57361a29",
   "metadata": {},
   "source": [
    "## 5. Train Seniority Classifier (on Lookup Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data from lookup table\n",
    "X_train_sen = sen_df['text_normalized'].tolist()\n",
    "y_train_sen = sen_df['label'].tolist()\n",
    "\n",
    "print(f\"Training Seniority classifier on lookup table...\")\n",
    "print(f\"  Training samples: {len(X_train_sen)}\")\n",
    "print(f\"  Classes: {len(set(y_train_sen))}\")\n",
    "\n",
    "# Fit vectorizer and transform\n",
    "sen_X_train = sen_vectorizer.fit_transform(X_train_sen)\n",
    "print(f\"  Feature dimension: {sen_X_train.shape[1]:,}\")\n",
    "\n",
    "# Train classifier\n",
    "sen_classifier = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=1.0,\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial',\n",
    "    random_state=RANDOM_SEED,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "sen_classifier.fit(sen_X_train, y_train_sen)\n",
    "print(\"✓ Seniority classifier trained\")\n",
    "print(f\"  Classes: {sen_classifier.classes_.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58befb",
   "metadata": {},
   "source": [
    "## 6. Extract Structural Features (from Unannotated CVs)\n",
    "\n",
    "Extract experience-related features WITHOUT using labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_experience_years(entry: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate years of experience for a job entry.\n",
    "    Uses start/end dates or duration field.\n",
    "    \n",
    "    Args:\n",
    "        entry: Job entry dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Years of experience (float)\n",
    "    \"\"\"\n",
    "    # Try to get duration directly\n",
    "    if 'duration_years' in entry:\n",
    "        return float(entry['duration_years'])\n",
    "    \n",
    "    # Try to parse dates (simplified - you can enhance this)\n",
    "    start = entry.get('start_date', '')\n",
    "    end = entry.get('end_date', '')\n",
    "    \n",
    "    # If no dates available, assume 1 year per job\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def extract_cv_features(cv: Any) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Extract structural features from a CV (unlabeled).\n",
    "    \n",
    "    Args:\n",
    "        cv: CV dictionary or list of positions\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with experience features\n",
    "    \"\"\"\n",
    "    entries = cv if isinstance(cv, list) else cv.get('positions', [])\n",
    "    \n",
    "    total_experience = 0.0\n",
    "    active_experience = 0.0\n",
    "    num_jobs = 0\n",
    "    \n",
    "    for entry in entries:\n",
    "        if not isinstance(entry, dict):\n",
    "            continue\n",
    "        \n",
    "        years = calculate_experience_years(entry)\n",
    "        total_experience += years\n",
    "        num_jobs += 1\n",
    "        \n",
    "        # Track active role experience\n",
    "        status = entry.get('status', 'ACTIVE')\n",
    "        if status and status.upper() == 'ACTIVE':\n",
    "            active_experience += years\n",
    "    \n",
    "    avg_tenure = total_experience / num_jobs if num_jobs > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'total_experience': total_experience,\n",
    "        'active_experience': active_experience,\n",
    "        'num_jobs': num_jobs,\n",
    "        'avg_tenure': avg_tenure\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Structural features defined (experience-based heuristics)\")\n",
    "print(\"These will be used for seniority post-processing only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be22d6f",
   "metadata": {},
   "source": [
    "## 7. Seniority Post-Processing with Experience Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f42b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_seniority(text_prediction: str, text_confidence: float, \n",
    "                         total_experience: float, available_classes: List[str],\n",
    "                         confidence_threshold: float = 0.5) -> str:\n",
    "    \"\"\"\n",
    "    Post-process seniority prediction with experience heuristics.\n",
    "    ONLY returns classes that exist in training data!\n",
    "    \n",
    "    Rules (transparent and interpretable):\n",
    "    - If total experience < 2 years → predict lowest level\n",
    "    - If total experience > 10 years → predict highest level\n",
    "    - If text confidence is low → fall back to experience-based heuristic\n",
    "    - All predictions are mapped to available classes from training\n",
    "    \n",
    "    Args:\n",
    "        text_prediction: Seniority prediction from text classifier\n",
    "        text_confidence: Confidence (max probability)\n",
    "        total_experience: Total years of experience\n",
    "        available_classes: List of classes available from training (sorted)\n",
    "        confidence_threshold: Threshold for trusting text prediction\n",
    "        \n",
    "    Returns:\n",
    "        Final seniority prediction (guaranteed to be in available_classes)\n",
    "    \"\"\"\n",
    "    # Ensure we only return known classes\n",
    "    if not available_classes:\n",
    "        return text_prediction\n",
    "    \n",
    "    # Sort classes to establish hierarchy (assume alphabetical or predefined order)\n",
    "    sorted_classes = sorted(available_classes)\n",
    "    \n",
    "    # If high confidence in text prediction, use it (already from model, so it's valid)\n",
    "    if text_confidence >= confidence_threshold:\n",
    "        # Apply experience constraints\n",
    "        if total_experience < 2:\n",
    "            # Find lowest seniority class\n",
    "            junior_candidates = [c for c in sorted_classes if 'junior' in c.lower() or 'intern' in c.lower()]\n",
    "            return junior_candidates[0] if junior_candidates else sorted_classes[0]\n",
    "        return text_prediction\n",
    "    \n",
    "    # Low confidence → fall back to experience heuristic (map to available classes)\n",
    "    if total_experience < 2:\n",
    "        # Lowest level\n",
    "        junior_candidates = [c for c in sorted_classes if 'junior' in c.lower() or 'intern' in c.lower()]\n",
    "        return junior_candidates[0] if junior_candidates else sorted_classes[0]\n",
    "    elif total_experience < 5:\n",
    "        # Mid-low level\n",
    "        if len(sorted_classes) >= 3:\n",
    "            return sorted_classes[1]\n",
    "        else:\n",
    "            return sorted_classes[0]\n",
    "    elif total_experience < 10:\n",
    "        # Mid-high level\n",
    "        senior_candidates = [c for c in sorted_classes if 'senior' in c.lower()]\n",
    "        if senior_candidates:\n",
    "            return senior_candidates[0]\n",
    "        elif len(sorted_classes) >= 3:\n",
    "            return sorted_classes[-2]\n",
    "        else:\n",
    "            return sorted_classes[-1]\n",
    "    else:\n",
    "        # Highest level\n",
    "        lead_candidates = [c for c in sorted_classes if 'lead' in c.lower() or 'director' in c.lower()]\n",
    "        return lead_candidates[0] if lead_candidates else sorted_classes[-1]\n",
    "\n",
    "\n",
    "print(\"✓ Seniority post-processing rules defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available classes from training data\n",
    "available_seniority_classes = sorted(sen_df['label'].unique().tolist())\n",
    "available_department_classes = sorted(dept_df['label'].unique().tolist())\n",
    "\n",
    "print(\"Available classes from lookup tables:\")\n",
    "print(f\"  Department: {available_department_classes}\")\n",
    "print(f\"  Seniority: {available_seniority_classes}\")\n",
    "\n",
    "# Create label mapping for test data (map unknown labels to closest known class)\n",
    "def map_label_to_available(label: str, available_classes: List[str], task: str = 'seniority') -> str:\n",
    "    \"\"\"\n",
    "    Map potentially unknown label to closest available class.\n",
    "    \n",
    "    Args:\n",
    "        label: Original label\n",
    "        available_classes: List of known classes from training\n",
    "        task: 'seniority' or 'department'\n",
    "    \n",
    "    Returns:\n",
    "        Mapped label\n",
    "    \"\"\"\n",
    "    if label in available_classes:\n",
    "        return label\n",
    "    \n",
    "    # Seniority mapping (if label not in training data)\n",
    "    if task == 'seniority':\n",
    "        label_lower = label.lower()\n",
    "        \n",
    "        # Define hierarchy and synonyms\n",
    "        seniority_hierarchy = {\n",
    "            'intern': ['intern', 'internship', 'trainee', 'praktikant'],\n",
    "            'junior': ['junior', 'entry', 'associate', 'assistant'],\n",
    "            'professional': ['professional', 'mid', 'middle', 'regular', 'specialist'],\n",
    "            'senior': ['senior', 'principal', 'expert', 'experienced'],\n",
    "            'lead': ['lead', 'staff', 'director', 'head', 'chief', 'manager']\n",
    "        }\n",
    "        \n",
    "        # Try to find best match\n",
    "        for known_class in available_classes:\n",
    "            if label_lower == known_class.lower():\n",
    "                return known_class\n",
    "            \n",
    "            # Check synonyms\n",
    "            for standard, synonyms in seniority_hierarchy.items():\n",
    "                if label_lower in synonyms and standard in [c.lower() for c in available_classes]:\n",
    "                    # Find the actual case in available_classes\n",
    "                    for c in available_classes:\n",
    "                        if c.lower() == standard:\n",
    "                            return c\n",
    "        \n",
    "        # Default fallback: middle of hierarchy\n",
    "        if available_classes:\n",
    "            return available_classes[len(available_classes) // 2]\n",
    "    \n",
    "    # Department mapping (if label not in training data)\n",
    "    else:\n",
    "        # Return first available class as fallback\n",
    "        return available_classes[0] if available_classes else label\n",
    "    \n",
    "    return label\n",
    "\n",
    "print(\"\\n✓ Label mapping function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfccf7e",
   "metadata": {},
   "source": [
    "## 8. Load Evaluation Data (Annotated CVs - Test Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf53186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_linkedin_cvs(filepath: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load LinkedIn CV JSON data.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to JSON file\n",
    "        \n",
    "    Returns:\n",
    "        List of CV dictionaries\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data if isinstance(data, list) else [data]\n",
    "\n",
    "\n",
    "def extract_test_samples(cvs: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract ACTIVE job entries from annotated CVs for evaluation.\n",
    "    \n",
    "    Args:\n",
    "        cvs: List of CV dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with test samples\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    for cv_idx, cv in enumerate(cvs):\n",
    "        entries = cv if isinstance(cv, list) else cv.get('positions', [])\n",
    "        \n",
    "        # Extract CV-level features\n",
    "        cv_features = extract_cv_features(cv)\n",
    "        \n",
    "        for entry in entries:\n",
    "            if not isinstance(entry, dict):\n",
    "                continue\n",
    "            \n",
    "            # Only evaluate ACTIVE entries\n",
    "            status = entry.get('status', 'ACTIVE')\n",
    "            if not status or status.upper() != 'ACTIVE':\n",
    "                continue\n",
    "            \n",
    "            # Create input text\n",
    "            text = create_input_text(entry, include_org=True)\n",
    "            text_normalized = normalize_text(text)\n",
    "            \n",
    "            sample = {\n",
    "                'cv_id': cv_idx,\n",
    "                'input_text': text_normalized,\n",
    "                'department': entry.get('department', 'Other'),\n",
    "                'seniority': entry.get('seniority', 'Professional'),\n",
    "                'total_experience': cv_features['total_experience'],\n",
    "                'active_experience': cv_features['active_experience'],\n",
    "                'num_jobs': cv_features['num_jobs'],\n",
    "                'avg_tenure': cv_features['avg_tenure']\n",
    "            }\n",
    "            samples.append(sample)\n",
    "    \n",
    "    df = pd.DataFrame(samples)\n",
    "    \n",
    "    # Map labels to available classes (important!)\n",
    "    if 'department' in df.columns:\n",
    "        df['department_original'] = df['department'].copy()\n",
    "        df['department'] = df['department'].apply(\n",
    "            lambda x: map_label_to_available(x, available_department_classes, 'department')\n",
    "        )\n",
    "    \n",
    "    if 'seniority' in df.columns:\n",
    "        df['seniority_original'] = df['seniority'].copy()\n",
    "        df['seniority'] = df['seniority'].apply(\n",
    "            lambda x: map_label_to_available(x, available_seniority_classes, 'seniority')\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Load annotated CVs (TEST ONLY - not for training!)\n",
    "print(\"Loading annotated CVs for evaluation (TEST ONLY)...\")\n",
    "annotated_cvs = load_linkedin_cvs(DATA_DIR / 'linkedin-cvs-annotated.json')\n",
    "test_df = extract_test_samples(annotated_cvs)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(annotated_cvs)} CVs\")\n",
    "print(f\"  Test samples (ACTIVE only): {len(test_df)}\")\n",
    "\n",
    "# Check if any labels were mapped\n",
    "if 'department_original' in test_df.columns:\n",
    "    unmapped_dept = (test_df['department'] != test_df['department_original']).sum()\n",
    "    if unmapped_dept > 0:\n",
    "        print(f\"  ⚠️  {unmapped_dept} department labels mapped to available classes\")\n",
    "        print(f\"     Original labels: {test_df['department_original'].unique().tolist()}\")\n",
    "\n",
    "if 'seniority_original' in test_df.columns:\n",
    "    unmapped_sen = (test_df['seniority'] != test_df['seniority_original']).sum()\n",
    "    if unmapped_sen > 0:\n",
    "        print(f\"  ⚠️  {unmapped_sen} seniority labels mapped to available classes\")\n",
    "        print(f\"     Original labels: {test_df['seniority_original'].unique().tolist()}\")\n",
    "\n",
    "print(f\"\\nDepartment distribution (mapped):\")\n",
    "print(test_df['department'].value_counts())\n",
    "print(f\"\\nSeniority distribution (mapped):\")\n",
    "print(test_df['seniority'].value_counts())\n",
    "print(f\"\\nExperience statistics:\")\n",
    "print(test_df[['total_experience', 'active_experience', 'num_jobs']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e63b21",
   "metadata": {},
   "source": [
    "## 9. Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb22cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department predictions\n",
    "print(\"Making predictions on test set...\")\n",
    "dept_X_test = dept_vectorizer.transform(test_df['input_text'].tolist())\n",
    "dept_predictions = dept_classifier.predict(dept_X_test)\n",
    "dept_probas = dept_classifier.predict_proba(dept_X_test)\n",
    "dept_confidences = dept_probas.max(axis=1)\n",
    "\n",
    "# Seniority predictions (text-based)\n",
    "sen_X_test = sen_vectorizer.transform(test_df['input_text'].tolist())\n",
    "sen_predictions_text = sen_classifier.predict(sen_X_test)\n",
    "sen_probas = sen_classifier.predict_proba(sen_X_test)\n",
    "sen_confidences = sen_probas.max(axis=1)\n",
    "\n",
    "# Seniority post-processing with experience heuristics\n",
    "sen_predictions_final = []\n",
    "for text_pred, text_conf, total_exp in zip(sen_predictions_text, sen_confidences, test_df['total_experience']):\n",
    "    final_pred = postprocess_seniority(\n",
    "        text_pred, text_conf, total_exp, \n",
    "        available_seniority_classes,\n",
    "        confidence_threshold=0.6\n",
    "    )\n",
    "    sen_predictions_final.append(final_pred)\n",
    "\n",
    "print(\"✓ Predictions completed\")\n",
    "print(f\"  Department predictions: {len(dept_predictions)}\")\n",
    "print(f\"  Seniority predictions (with post-processing): {len(sen_predictions_final)}\")\n",
    "print(f\"\\n  Department classes predicted: {sorted(set(dept_predictions))}\")\n",
    "print(f\"  Seniority classes predicted: {sorted(set(sen_predictions_final))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c61dac",
   "metadata": {},
   "source": [
    "## 10. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6faf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true: List[str], y_pred: List[str], task_name: str, \n",
    "                        available_classes: List[str] = None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate predictions and print metrics.\n",
    "    Shows warning if true labels contain classes not in training.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        task_name: Name of the task (for display)\n",
    "        available_classes: Classes available in training data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metrics\n",
    "    \"\"\"\n",
    "    # Check for labels not in training\n",
    "    if available_classes:\n",
    "        true_labels_set = set(y_true)\n",
    "        unknown_labels = true_labels_set - set(available_classes)\n",
    "        if unknown_labels:\n",
    "            print(f\"\\n⚠️  WARNING: Test set contains labels NOT in training data!\")\n",
    "            print(f\"   Unknown labels: {sorted(unknown_labels)}\")\n",
    "            print(f\"   These labels were never seen during training.\")\n",
    "            print(f\"   Model cannot predict them correctly.\\n\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    _, _, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{task_name.upper()} - Test Set Results (ACTIVE entries only)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Test samples:         {len(y_true)}\")\n",
    "    print(f\"Accuracy:             {accuracy:.4f}\")\n",
    "    print(f\"Precision (macro):    {precision:.4f}\")\n",
    "    print(f\"Recall (macro):       {recall:.4f}\")\n",
    "    print(f\"F1 (macro):           {f1_macro:.4f}\")\n",
    "    print(f\"F1 (weighted):        {f1_weighted:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision_macro': float(precision),\n",
    "        'recall_macro': float(recall),\n",
    "        'f1_macro': float(f1_macro),\n",
    "        'f1_weighted': float(f1_weighted),\n",
    "        'test_samples': len(y_true)\n",
    "    }\n",
    "\n",
    "\n",
    "# Evaluate Department (use ORIGINAL labels if available)\n",
    "dept_true_original = test_df['department_original'].tolist() if 'department_original' in test_df.columns else test_df['department'].tolist()\n",
    "dept_metrics = evaluate_predictions(dept_true_original, dept_predictions, 'Department', available_department_classes)\n",
    "\n",
    "# Evaluate Seniority (with post-processing) - use ORIGINAL labels\n",
    "sen_true_original = test_df['seniority_original'].tolist() if 'seniority_original' in test_df.columns else test_df['seniority'].tolist()\n",
    "sen_metrics = evaluate_predictions(sen_true_original, sen_predictions_final, 'Seniority (with heuristics)', available_seniority_classes)\n",
    "\n",
    "# Compare seniority with/without post-processing\n",
    "sen_metrics_text_only = evaluate_predictions(sen_true_original, sen_predictions_text, 'Seniority (text only)', available_seniority_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b8b6a2",
   "metadata": {},
   "source": [
    "## 11. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a040374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrices (use ORIGINAL labels to show unmapped classes)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Department confusion matrix (with original labels)\n",
    "dept_true_original = test_df['department_original'].tolist() if 'department_original' in test_df.columns else test_df['department'].tolist()\n",
    "dept_cm = confusion_matrix(dept_true_original, dept_predictions)\n",
    "dept_labels = sorted(set(dept_true_original + list(dept_predictions)))\n",
    "\n",
    "sns.heatmap(dept_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=dept_labels, yticklabels=dept_labels, ax=axes[0])\n",
    "axes[0].set_title('Department Confusion Matrix\\n(Lexicon-Supervised)\\nRed labels = Not in training data', fontsize=14)\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "axes[0].tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "# Color y-axis labels (true labels) that were not in training\n",
    "for label, tick in zip(dept_labels, axes[0].get_yticklabels()):\n",
    "    if label not in available_department_classes:\n",
    "        tick.set_color('red')\n",
    "        tick.set_weight('bold')\n",
    "\n",
    "# Seniority confusion matrix (with original labels)\n",
    "sen_true_original = test_df['seniority_original'].tolist() if 'seniority_original' in test_df.columns else test_df['seniority'].tolist()\n",
    "sen_cm = confusion_matrix(sen_true_original, sen_predictions_final)\n",
    "sen_labels = sorted(set(sen_true_original + sen_predictions_final))\n",
    "\n",
    "sns.heatmap(sen_cm, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=sen_labels, yticklabels=sen_labels, ax=axes[1])\n",
    "axes[1].set_title('Seniority Confusion Matrix\\n(Lexicon-Supervised + Heuristics)\\nRed labels = Not in training data', fontsize=14)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "axes[1].tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "# Color y-axis labels (true labels) that were not in training\n",
    "for label, tick in zip(sen_labels, axes[1].get_yticklabels()):\n",
    "    if label not in available_seniority_classes:\n",
    "        tick.set_color('red')\n",
    "        tick.set_weight('bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'lexicon_supervised_confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary of unmapped labels\n",
    "print(\"\\nLabel Coverage Analysis:\")\n",
    "print(f\"Department - Training classes: {available_department_classes}\")\n",
    "print(f\"Department - Test classes: {sorted(set(dept_true_original))}\")\n",
    "unmapped_dept = set(dept_true_original) - set(available_department_classes)\n",
    "if unmapped_dept:\n",
    "    print(f\"⚠️  Department labels NOT in training: {sorted(unmapped_dept)}\")\n",
    "else:\n",
    "    print(\"✓ All department test labels were in training data\")\n",
    "\n",
    "print(f\"\\nSeniority - Training classes: {available_seniority_classes}\")\n",
    "print(f\"Seniority - Test classes: {sorted(set(sen_true_original))}\")\n",
    "unmapped_sen = set(sen_true_original) - set(available_seniority_classes)\n",
    "if unmapped_sen:\n",
    "    print(f\"⚠️  Seniority labels NOT in training: {sorted(unmapped_sen)}\")\n",
    "else:\n",
    "    print(\"✓ All seniority test labels were in training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91622f48",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd71e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL PERFORMANCE SUMMARY - Lexicon-Supervised Baseline\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTraining Data:\")\n",
    "print(f\"  Department: {len(dept_df)} examples from lookup table\")\n",
    "print(f\"  Seniority:  {len(sen_df)} examples from lookup table\")\n",
    "print(f\"  ⚠️  NO annotated CVs used for training!\")\n",
    "\n",
    "print(f\"\\nTest Performance (ACTIVE entries only):\")\n",
    "print(f\"  Department:\")\n",
    "print(f\"    Accuracy:  {dept_metrics['accuracy']:.3f}\")\n",
    "print(f\"    F1 macro:  {dept_metrics['f1_macro']:.3f}\")\n",
    "print(f\"    F1 weight: {dept_metrics['f1_weighted']:.3f}\")\n",
    "\n",
    "print(f\"\\n  Seniority (text only):\")\n",
    "print(f\"    Accuracy:  {sen_metrics_text_only['accuracy']:.3f}\")\n",
    "print(f\"    F1 macro:  {sen_metrics_text_only['f1_macro']:.3f}\")\n",
    "print(f\"    F1 weight: {sen_metrics_text_only['f1_weighted']:.3f}\")\n",
    "\n",
    "print(f\"\\n  Seniority (with experience heuristics):\")\n",
    "print(f\"    Accuracy:  {sen_metrics['accuracy']:.3f}\")\n",
    "print(f\"    F1 macro:  {sen_metrics['f1_macro']:.3f}\")\n",
    "print(f\"    F1 weight: {sen_metrics['f1_weighted']:.3f}\")\n",
    "\n",
    "improvement = sen_metrics['accuracy'] - sen_metrics_text_only['accuracy']\n",
    "print(f\"\\n  Improvement from heuristics: {improvement:+.3f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n✓ Constraint satisfied: Annotated CVs used ONLY for evaluation\")\n",
    "print(f\"✓ Lexicon-supervised learning demonstrates feasibility of training on lookup tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61246e1d",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e98837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results dictionary\n",
    "results = {\n",
    "    \"approach\": \"Lexicon-Supervised TF-IDF + LogReg (No CV Training Data)\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"constraint\": \"Annotated CVs NOT used for training, only for evaluation\",\n",
    "    \"training_data\": {\n",
    "        \"department_samples\": len(dept_df),\n",
    "        \"seniority_samples\": len(sen_df),\n",
    "        \"source\": \"Lookup tables only (department-v2.csv, seniority-v2.csv)\"\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"text\": \"TF-IDF (word 1-2 + char 3-5)\",\n",
    "        \"structural\": \"Experience years (for seniority heuristics only)\",\n",
    "        \"dept_features\": dept_X_train.shape[1],\n",
    "        \"sen_features\": sen_X_train.shape[1]\n",
    "    },\n",
    "    \"department\": dept_metrics,\n",
    "    \"seniority_text_only\": sen_metrics_text_only,\n",
    "    \"seniority_with_heuristics\": sen_metrics,\n",
    "    \"config\": {\n",
    "        \"random_seed\": RANDOM_SEED,\n",
    "        \"classifier\": \"LogisticRegression\",\n",
    "        \"C\": 1.0,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"confidence_threshold\": 0.6\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "results_path = RESULTS_DIR / 'lexicon_supervised_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575f024",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Key Findings**:\n",
    "- Lexicon-supervised learning (training only on lookup tables) is feasible\n",
    "- Shows how far we can go without labeled CV training data\n",
    "- Experience heuristics provide additional boost for seniority classification\n",
    "- Transparent and interpretable: all rules are explicit\n",
    "\n",
    "**Limitations**:\n",
    "- Performance limited by quality and coverage of lookup tables\n",
    "- Cannot learn patterns beyond what's in the lexicon\n",
    "- May struggle with novel job titles or industry-specific terminology\n",
    "\n",
    "**Next Steps**:\n",
    "- Compare with supervised baselines (Notebooks 07, 11, etc.)\n",
    "- Analyze which job titles are well-covered vs. missing from lookup tables\n",
    "- Consider semi-supervised approaches (pseudo-labeling) to bridge the gap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
