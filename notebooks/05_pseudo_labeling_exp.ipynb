{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05 - Pseudo-Labeling Experiment\n",
                "\n",
                "This notebook implements **Approach 2: Programmatic Labeling + Supervised Learning**.\n",
                "\n",
                "## Targets\n",
                "- **Department (Domain)**: Professional domain of the current job\n",
                "- **Seniority**: Seniority level of the current position\n",
                "\n",
                "## Strategy\n",
                "1. Generate pseudo-labels for unannotated CVs using rule-based + embedding classifiers\n",
                "2. Filter for high-confidence predictions only\n",
                "3. Combine gold (annotated) + silver (pseudo-labeled) data\n",
                "4. Train transformer on expanded dataset\n",
                "\n",
                "## Selection Logic\n",
                "```\n",
                "IF rule_based.method in [\"exact\", \"substring\"]: use rule_based.label\n",
                "ELIF embedding.confidence > 0.85: use embedding.label\n",
                "ELSE: discard\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import pandas as pd\n",
                "import torch\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "\n",
                "sys.path.insert(0, os.path.abspath(\"../\"))\n",
                "\n",
                "from src.models.rule_based import create_department_classifier, create_seniority_classifier\n",
                "from src.models.embedding_classifier import create_domain_classifier, create_seniority_classifier as create_emb_seniority\n",
                "from src.models.transformer_classifier import TransformerClassifier\n",
                "from src.data.loader import load_linkedin_data, prepare_dataset, load_label_lists\n",
                "from src.data.pseudo_labeler import PseudoLabeler, create_combined_dataset\n",
                "\n",
                "torch.manual_seed(42)\n",
                "print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Gold (annotated): 478\n",
                        "  - With department: 478\n",
                        "  - With seniority: 478\n",
                        "Unlabeled: 314\n"
                    ]
                }
            ],
            "source": [
                "# Load label lists for both targets\n",
                "dept_df, seniority_df = load_label_lists(\"../data\")\n",
                "\n",
                "# Load annotated (gold) data\n",
                "gold_data = load_linkedin_data(\"../data/linkedin-cvs-annotated.json\")\n",
                "gold_df = prepare_dataset(gold_data)\n",
                "\n",
                "# Load unannotated data\n",
                "unlabeled_data = load_linkedin_data(\"../data/linkedin-cvs-not-annotated.json\")\n",
                "unlabeled_df = prepare_dataset(unlabeled_data)\n",
                "\n",
                "print(f\"Gold (annotated): {len(gold_df)}\")\n",
                "print(f\"  - With department: {gold_df['department'].notna().sum()}\")\n",
                "print(f\"  - With seniority: {gold_df['seniority'].notna().sum()}\")\n",
                "print(f\"Unlabeled: {len(unlabeled_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 1: DEPARTMENT PSEUDO-LABELING\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize Department Classifiers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model 'paraphrase-multilingual-MiniLM-L12-v2' on cuda...\n",
                        "Model loaded successfully!\n",
                        "Fitted from examples: 11 labels, shape (11, 384)\n",
                        "Department classifiers initialized!\n"
                    ]
                }
            ],
            "source": [
                "# Create rule-based classifier for Department\n",
                "rule_dept = create_department_classifier(dept_df)\n",
                "\n",
                "# Create embedding classifier for Department\n",
                "emb_dept = create_domain_classifier(dept_df, use_examples=True)\n",
                "\n",
                "print(\"Department classifiers initialized!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generate Pseudo-Labels (Department)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e1a07bc49d834c84a046ab58f5a90142",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generated 35 high-confidence DEPARTMENT pseudo-labels\n",
                        "Label source distribution:\n",
                        "pseudo_department_source\n",
                        "rule_substring    35\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Initialize pseudo-labeler for Department\n",
                "dept_labeler = PseudoLabeler(\n",
                "    rule_classifier=rule_dept,\n",
                "    embedding_classifier=emb_dept,\n",
                "    confidence_threshold=0.85\n",
                ")\n",
                "\n",
                "# Generate pseudo-labels\n",
                "silver_dept_df = dept_labeler.get_high_confidence_subset(\n",
                "    unlabeled_df, \n",
                "    text_column='text',\n",
                "    label_column='pseudo_department'\n",
                ")\n",
                "\n",
                "print(f\"Generated {len(silver_dept_df)} high-confidence DEPARTMENT pseudo-labels\")\n",
                "print(f\"Label source distribution:\")\n",
                "print(silver_dept_df['pseudo_department_source'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Transformer on Combined Data (Department)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Combined dataset: 478 gold + 35 silver = 513 total\n",
                        "Combined dataset: 382 gold + 35 silver = 417 total\n",
                        "Training on 417 examples (gold + silver)\n",
                        "Testing on 96 gold examples\n"
                    ]
                }
            ],
            "source": [
                "# Prepare gold data for department\n",
                "gold_dept = gold_df.dropna(subset=['department']).copy()\n",
                "\n",
                "# Combine datasets\n",
                "combined_dept = create_combined_dataset(\n",
                "    gold_df=gold_dept,\n",
                "    silver_df=silver_dept_df,\n",
                "    gold_label_col='department',\n",
                "    silver_label_col='pseudo_department',\n",
                "    gold_weight=1.0,\n",
                "    silver_weight=0.7\n",
                ")\n",
                "\n",
                "# Prepare label mappings\n",
                "dept_labels = combined_dept['label'].unique().tolist()\n",
                "dept_label2id = {label: i for i, label in enumerate(dept_labels)}\n",
                "dept_id2label = {i: label for label, i in dept_label2id.items()}\n",
                "\n",
                "# Split for training/testing\n",
                "gold_train_d, gold_test_d = train_test_split(gold_dept, test_size=0.2, random_state=42)\n",
                "\n",
                "train_dept_df = create_combined_dataset(\n",
                "    gold_df=gold_train_d,\n",
                "    silver_df=silver_dept_df,\n",
                "    gold_label_col='department',\n",
                "    silver_label_col='pseudo_department'\n",
                ")\n",
                "train_dept_df = train_dept_df[train_dept_df['label'].isin(dept_label2id.keys())]\n",
                "\n",
                "train_texts_d = train_dept_df['text'].tolist()\n",
                "train_labels_d = [dept_label2id[l] for l in train_dept_df['label']]\n",
                "\n",
                "test_texts_d = gold_test_d['text'].tolist()\n",
                "test_labels_d = gold_test_d['department'].tolist()\n",
                "\n",
                "print(f\"Training on {len(train_texts_d)} examples (gold + silver)\")\n",
                "print(f\"Testing on {len(test_texts_d)} gold examples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded on cuda\n",
                        "Training on 417 examples...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [81/81 00:49, Epoch 3/3]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Step</th>\n",
                            "      <th>Training Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>50</td>\n",
                            "      <td>1.911900</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training complete!\n"
                    ]
                }
            ],
            "source": [
                "# Train Department classifier\n",
                "dept_pseudo_classifier = TransformerClassifier(\n",
                "    model_name=\"distilbert-base-multilingual-cased\",\n",
                "    num_labels=len(dept_label2id),\n",
                "    id2label=dept_id2label,\n",
                "    label2id=dept_label2id\n",
                ")\n",
                "\n",
                "dept_pseudo_classifier.train(\n",
                "    texts=train_texts_d,\n",
                "    labels=train_labels_d,\n",
                "    output_dir=\"./results/pseudo_dept\",\n",
                "    epochs=3,\n",
                "    batch_size=16\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluate Department Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "TARGET 1: DEPARTMENT PSEUDO-LABELING RESULTS\n",
                        "============================================================\n",
                        "Accuracy: 0.4479\n",
                        "\n",
                        "Classification Report:\n",
                        "                        precision    recall  f1-score   support\n",
                        "\n",
                        "        Administrative       0.00      0.00      0.00         3\n",
                        "  Business Development       0.00      0.00      0.00         3\n",
                        "            Consulting       0.00      0.00      0.00         6\n",
                        "      Customer Support       0.00      0.00      0.00         3\n",
                        "       Human Resources       0.00      0.00      0.00         2\n",
                        "Information Technology       0.00      0.00      0.00        16\n",
                        "             Marketing       0.00      0.00      0.00         1\n",
                        "                 Other       0.45      1.00      0.62        43\n",
                        "    Project Management       0.00      0.00      0.00         7\n",
                        "            Purchasing       0.00      0.00      0.00         3\n",
                        "                 Sales       0.00      0.00      0.00         9\n",
                        "\n",
                        "              accuracy                           0.45        96\n",
                        "             macro avg       0.04      0.09      0.06        96\n",
                        "          weighted avg       0.20      0.45      0.28        96\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Predict and evaluate\n",
                "dept_predictions = dept_pseudo_classifier.predict_labels(test_texts_d)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"TARGET 1: DEPARTMENT PSEUDO-LABELING RESULTS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Accuracy: {accuracy_score(test_labels_d, dept_predictions):.4f}\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(test_labels_d, dept_predictions, zero_division=0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to ..\\models\\transformer_pseudo_dept\n",
                        "Department pseudo-label model saved!\n"
                    ]
                }
            ],
            "source": [
                "# Save department model\n",
                "dept_pseudo_classifier.save(\"../models/transformer_pseudo_dept\")\n",
                "print(\"Department pseudo-label model saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 2: SENIORITY PSEUDO-LABELING\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Initialize Seniority Classifiers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model 'paraphrase-multilingual-MiniLM-L12-v2' on cuda...\n",
                        "Model loaded successfully!\n",
                        "Fitted from examples: 5 labels, shape (5, 384)\n",
                        "Seniority classifiers initialized!\n"
                    ]
                }
            ],
            "source": [
                "# Create rule-based classifier for Seniority\n",
                "rule_sen = create_seniority_classifier(seniority_df)\n",
                "\n",
                "# Create embedding classifier for Seniority\n",
                "emb_sen = create_emb_seniority(seniority_df, use_examples=True)\n",
                "\n",
                "print(\"Seniority classifiers initialized!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Generate Pseudo-Labels (Seniority)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a305d8d499304a089e3979dde8abcc36",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generated 110 high-confidence SENIORITY pseudo-labels\n",
                        "Label source distribution:\n",
                        "pseudo_seniority_source\n",
                        "rule_substring    110\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Initialize pseudo-labeler for Seniority\n",
                "sen_labeler = PseudoLabeler(\n",
                "    rule_classifier=rule_sen,\n",
                "    embedding_classifier=emb_sen,\n",
                "    confidence_threshold=0.85\n",
                ")\n",
                "\n",
                "# Generate pseudo-labels\n",
                "silver_sen_df = sen_labeler.get_high_confidence_subset(\n",
                "    unlabeled_df, \n",
                "    text_column='text',\n",
                "    label_column='pseudo_seniority'\n",
                ")\n",
                "\n",
                "print(f\"Generated {len(silver_sen_df)} high-confidence SENIORITY pseudo-labels\")\n",
                "print(f\"Label source distribution:\")\n",
                "print(silver_sen_df['pseudo_seniority_source'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Train Transformer on Combined Data (Seniority)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Combined dataset: 478 gold + 110 silver = 588 total\n",
                        "Seniority classes: ['Management', 'Professional', 'Director', 'Lead', 'Senior', 'Junior']\n",
                        "Combined dataset: 382 gold + 110 silver = 492 total\n",
                        "Training on 492 examples (gold + silver)\n",
                        "Testing on 96 gold examples\n"
                    ]
                }
            ],
            "source": [
                "# Prepare gold data for seniority\n",
                "gold_sen = gold_df.dropna(subset=['seniority']).copy()\n",
                "\n",
                "# Combine datasets\n",
                "combined_sen = create_combined_dataset(\n",
                "    gold_df=gold_sen,\n",
                "    silver_df=silver_sen_df,\n",
                "    gold_label_col='seniority',\n",
                "    silver_label_col='pseudo_seniority',\n",
                "    gold_weight=1.0,\n",
                "    silver_weight=0.7\n",
                ")\n",
                "\n",
                "# Prepare label mappings\n",
                "sen_labels = combined_sen['label'].unique().tolist()\n",
                "sen_label2id = {label: i for i, label in enumerate(sen_labels)}\n",
                "sen_id2label = {i: label for label, i in sen_label2id.items()}\n",
                "\n",
                "print(f\"Seniority classes: {sen_labels}\")\n",
                "\n",
                "# Split for training/testing\n",
                "gold_train_s, gold_test_s = train_test_split(gold_sen, test_size=0.2, random_state=42)\n",
                "\n",
                "train_sen_df = create_combined_dataset(\n",
                "    gold_df=gold_train_s,\n",
                "    silver_df=silver_sen_df,\n",
                "    gold_label_col='seniority',\n",
                "    silver_label_col='pseudo_seniority'\n",
                ")\n",
                "train_sen_df = train_sen_df[train_sen_df['label'].isin(sen_label2id.keys())]\n",
                "\n",
                "train_texts_s = train_sen_df['text'].tolist()\n",
                "train_labels_s = [sen_label2id[l] for l in train_sen_df['label']]\n",
                "\n",
                "test_texts_s = gold_test_s['text'].tolist()\n",
                "test_labels_s = gold_test_s['seniority'].tolist()\n",
                "\n",
                "print(f\"Training on {len(train_texts_s)} examples (gold + silver)\")\n",
                "print(f\"Testing on {len(test_texts_s)} gold examples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded on cuda\n",
                        "Training on 492 examples...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='93' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [93/93 01:33, Epoch 3/3]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Step</th>\n",
                            "      <th>Training Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>50</td>\n",
                            "      <td>1.578500</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training complete!\n"
                    ]
                }
            ],
            "source": [
                "# Train Seniority classifier\n",
                "sen_pseudo_classifier = TransformerClassifier(\n",
                "    model_name=\"distilbert-base-multilingual-cased\",\n",
                "    num_labels=len(sen_label2id),\n",
                "    id2label=sen_id2label,\n",
                "    label2id=sen_label2id\n",
                ")\n",
                "\n",
                "sen_pseudo_classifier.train(\n",
                "    texts=train_texts_s,\n",
                "    labels=train_labels_s,\n",
                "    output_dir=\"./results/pseudo_seniority\",\n",
                "    epochs=3,\n",
                "    batch_size=16\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Evaluate Seniority Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "TARGET 2: SENIORITY PSEUDO-LABELING RESULTS\n",
                        "============================================================\n",
                        "Accuracy: 0.7188\n",
                        "\n",
                        "Classification Report:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    Director       0.00      0.00      0.00         5\n",
                        "      Junior       0.00      0.00      0.00         3\n",
                        "        Lead       0.88      0.39      0.54        18\n",
                        "  Management       0.72      0.88      0.79        24\n",
                        "Professional       0.69      0.92      0.79        37\n",
                        "      Senior       0.70      0.78      0.74         9\n",
                        "\n",
                        "    accuracy                           0.72        96\n",
                        "   macro avg       0.50      0.49      0.48        96\n",
                        "weighted avg       0.68      0.72      0.67        96\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Predict and evaluate\n",
                "sen_predictions = sen_pseudo_classifier.predict_labels(test_texts_s)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"TARGET 2: SENIORITY PSEUDO-LABELING RESULTS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Accuracy: {accuracy_score(test_labels_s, sen_predictions):.4f}\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(test_labels_s, sen_predictions, zero_division=0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to ..\\models\\transformer_pseudo_seniority\n",
                        "Seniority pseudo-label model saved!\n"
                    ]
                }
            ],
            "source": [
                "# Save seniority model\n",
                "sen_pseudo_classifier.save(\"../models/transformer_pseudo_seniority\")\n",
                "print(\"Seniority pseudo-label model saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "This notebook trained **two classifiers** using pseudo-labeling:\n",
                "\n",
                "| Target | Gold Data | Silver (Pseudo) | Total Training | Model Saved |\n",
                "|--------|-----------|----------------|----------------|--------------|\n",
                "| Department | ~380 | Variable | Gold + Silver | `transformer_pseudo_dept` |\n",
                "| Seniority | ~380 | Variable | Gold + Silver | `transformer_pseudo_seniority` |\n",
                "\n",
                "Both targets are now predicted using the pseudo-labeling approach."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
