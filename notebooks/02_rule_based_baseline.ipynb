{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-Based Baseline with Text Normalization\n",
    "\n",
    "**Approach**: Exact and fuzzy string matching against lookup tables with text normalization\n",
    "\n",
    "## Baseline Performance Target\n",
    "\n",
    "From the EDA (Exploratory Data Analysis) we observed the class distribution in our evaluation dataset:\n",
    "- **55% of departments are labeled as \"Other\"**\n",
    "- **35% of seniority levels are \"Professional\"**\n",
    "\n",
    "**Naive Baseline**: A model that always predicts \"Other\" for department would achieve 55% accuracy. A model that always predicts \"Professional\" for seniority would achieve 35% accuracy.\n",
    "\n",
    "**Goal**: Every model in this project must beat these naive baseline accuracies.\n",
    "\n",
    "## Model Configuration:\n",
    "This notebook implements the optimized rule-based approach with:\n",
    "\n",
    "1. **Text Normalization**: Lowercase conversion + whitespace cleaning\n",
    "2. **Department Classification**: Can fall back to \"Other\" if no match found\n",
    "3. **Seniority Classification**: Must always assign one of 6 levels, can fall back to \"Professional\"\n",
    "\n",
    "## Module Optimizations (src/models/rule_based.py):\n",
    "- Fuzzy matching implementation using `difflib.SequenceMatcher`\n",
    "- Strategy reordering: Fast methods (Keyword) before slow methods (Fuzzy)\n",
    "- Length-based pre-filtering to skip impossible matches\n",
    "\n",
    "## Matching Strategies (in order):\n",
    "1. Exact match (O(1) - instant)\n",
    "2. Substring match (O(n) - fast)\n",
    "3. Keyword match (O(n) - fast)\n",
    "4. Fuzzy match (O(n*m) - last resort, optimized)\n",
    "5. Default fallback (Department: \"Other\", Seniority: \"Professional\")\n",
    "\n",
    "**Training Data**: Lookup tables (~19k examples)  \n",
    "**Validation Data**: Annotated LinkedIn CVs (623 positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import data loaders and models\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.data.loader import load_label_lists, load_inference_dataset, load_evaluation_dataset\n",
    "from src.models.rule_based import RuleConfig, create_department_classifier, create_seniority_classifier\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "RESULTS_DIR = Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Training Data (Lookup Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying encoding fix...\n",
      "  Deduplication: 10145 -> 10145 (removed 0 duplicates)\n",
      "  Deduplication: 9428 -> 9428 (removed 0 duplicates)\n",
      "Department lookup: 10,145 examples\n",
      "Seniority lookup:  9,428 examples\n",
      "\n",
      "Unique departments: 11\n",
      "Unique seniority levels: 5\n"
     ]
    }
   ],
   "source": [
    "# Load lookup tables\n",
    "# removed capping\n",
    "dept_df, sen_df = load_label_lists(DATA_DIR, max_per_class=None)\n",
    "\n",
    "print(f\"Department lookup: {len(dept_df):,} examples\")\n",
    "print(f\"Seniority lookup:  {len(sen_df):,} examples\")\n",
    "print(f\"\\nUnique departments: {dept_df['label'].nunique()}\")\n",
    "print(f\"Unique seniority levels: {sen_df['label'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note: Rule-based models do not \"train\" on the lookup tables.\n",
    "# The lookup tables are treated as fixed rule/label dictionaries.\n",
    "# We only use train_test_split later to create a fair dev/test split\n",
    "# on the annotated SnapAddy evaluation dataset (to avoid tuning on the test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Approach 1a: Basic Rule-Based Classifiers (No Fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.rule_based import RuleConfig, create_department_classifier, create_seniority_classifier\n",
    "\n",
    "# Basic config: ONLY text normalization, NO default labels\n",
    "config_no_fallback = RuleConfig(\n",
    "    fuzzy_threshold=0.8, \n",
    "    use_text_normalization=True,\n",
    "    default_label=None  # Handle unknown titles as None\n",
    ")\n",
    "\n",
    "dept_clf_basic = create_department_classifier(dept_df, config=config_no_fallback)\n",
    "sen_clf_basic = create_seniority_classifier(sen_df, config=config_no_fallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(Seniority will return None if no match is found (instead of defaulting to 'Professional')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef804eb",
   "metadata": {},
   "source": [
    "## 3. Approach 1b: Enhanced Rule-Based Classifiers (With Fallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b89c5",
   "metadata": {},
   "source": [
    "Now we introduce the enhanced version. Since we know from EDA that `Other` and `Professional` are the most frequent classes, we can use them as intelligent fallbacks when explicit matching fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64a06542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced configuration: WITH fallbacks for unclassified titles\n",
    "config_dept_enhanced = RuleConfig(\n",
    "    fuzzy_threshold=0.8, \n",
    "    use_text_normalization=True, \n",
    "    default_label=\"Other\"\n",
    ")\n",
    "\n",
    "config_sen_enhanced = RuleConfig(\n",
    "    fuzzy_threshold=0.8, \n",
    "    use_text_normalization=True, \n",
    "    default_label=\"Professional\"\n",
    ")\n",
    "\n",
    "dept_clf = create_department_classifier(dept_df, config=config_dept_enhanced)\n",
    "sen_clf = create_seniority_classifier(sen_df, config=config_sen_enhanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanced Classifiers created (WITH fallback)\n",
    "- Default fallback: 'Other' (department)\n",
    "- Default fallback: 'Professional' (seniority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration: Text Normalization Effect\n",
    "\n",
    "Let's see how text normalization works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Normalization Examples:\n",
      "================================================================================\n",
      "Original                                 → Normalized                              \n",
      "--------------------------------------------------------------------------------\n",
      "'Senior  Software   Engineer'            → senior software engineer                \n",
      "'Senior Software Engineer'               → senior software engineer                \n",
      "' Senior Software Engineer '             → senior software engineer                \n",
      "'SENIOR SOFTWARE ENGINEER'               → senior software engineer                \n",
      "'Senior\\tSoftware\\nEngineer'             → senior software engineer                \n",
      "'  TEAM  LEADER   IT  '                  → team leader it                          \n"
     ]
    }
   ],
   "source": [
    "# Example: How text normalization works\n",
    "from src.models.rule_based import HybridRuleClassifier\n",
    "\n",
    "# Create a dummy classifier to use the normalization function\n",
    "dummy_df = pd.DataFrame({'text': ['dummy'], 'label': ['dummy']})\n",
    "dummy_clf = HybridRuleClassifier(dummy_df)\n",
    "\n",
    "# Test cases showing normalization effects\n",
    "test_cases = [\n",
    "    \"Senior  Software   Engineer\",      # Multiple spaces\n",
    "    \"Senior Software Engineer\",         # Normal\n",
    "    \" Senior Software Engineer \",       # Leading/trailing spaces\n",
    "    \"SENIOR SOFTWARE ENGINEER\",         # Uppercase\n",
    "    \"Senior\\tSoftware\\nEngineer\",       # Tabs & newlines\n",
    "    \"  TEAM  LEADER   IT  \",            # Mixed issues\n",
    "]\n",
    "\n",
    "print(\"Text Normalization Examples:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Original':<40} → {'Normalized':<40}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for text in test_cases:\n",
    "    normalized = dummy_clf._clean_text(text)\n",
    "    # Show whitespace issues visually\n",
    "    original_display = repr(text)[:38]\n",
    "    print(f\"{original_display:<40} → {normalized:<40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variations are now normalized to the same format!\n",
    "\n",
    "This helps matching: 'Senior  Engineer' will now match 'Senior Engineer' in lookup table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference Demo on Unannotated CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 314 unannotated CV positions for inference demo\n",
      "\n",
      "First few job titles:\n",
      "  1. Bookkeeper\n",
      "  2. Strategy & Investments\n",
      "  3. Corporate Auditor\n",
      "  4. Marketing Manager\n",
      "  5. Professor\n",
      "  6. Program Purchasing Leader / Program / Acquisition Buyer\n",
      "  7. Business Analyst\n",
      "  8. Managementberater IT- und Governance\n",
      "  9. Founder & CEO\n",
      "  10. Geschäftsführer\n"
     ]
    }
   ],
   "source": [
    "# Load unannotated CVs for demonstration\n",
    "inference_df = load_inference_dataset(DATA_DIR)\n",
    "\n",
    "print(f\"Loaded {len(inference_df):,} unannotated CV positions for inference demo\")\n",
    "print(f\"\\nFirst few job titles:\")\n",
    "for i, row in inference_df.head(10).iterrows():\n",
    "    print(f\"  {i+1}. {row['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "INFERENCE DEMO: Rule-Based Predictions\n",
      "====================================================================================================\n",
      "Title                                    | Department           | Seniority       | Methods             \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Bookkeeper                               | Other                | Professional    | defa/defa           \n",
      "Strategy & Investments                   | Other                | Professional    | defa/defa           \n",
      "Corporate Auditor                        | Other                | Professional    | defa/defa           \n",
      "Marketing Manager                        | Marketing            | Senior          | exac/exac           \n",
      "Professor                                | Other                | Professional    | defa/defa           \n",
      "Program Purchasing Leader / Program /... | Purchasing           | Lead            | keyw/keyw           \n",
      "Business Analyst                         | Business Development | Junior          | exac/exac           \n",
      "Managementberater IT- und Governance     | Consulting           | Senior          | keyw/keyw           \n",
      "Founder & CEO                            | Other                | Management      | defa/exac           \n",
      "Geschäftsführer                          | Other                | Management      | defa/exac           \n",
      "Manager                                  | Other                | Senior          | defa/exac           \n",
      "Koordinerende sagsbehandler              | Other                | Professional    | defa/defa           \n",
      "Head of Supply Chain                     | Purchasing           | Director        | keyw/keyw           \n",
      "Director of Finance (China)              | Other                | Director        | defa/subs           \n",
      "Inhaber                                  | Other                | Management      | defa/keyw           \n",
      "Geschäftsführer CFO                      | Other                | Management      | defa/subs           \n",
      "Mitglied der Geschäftsleitung            | Administrative       | Lead            | fuzz/exac           \n",
      "Global Marketing Director, Nonwovens     | Marketing            | Director        | subs/subs           \n",
      "Social Researcher                        | Other                | Professional    | defa/defa           \n",
      "Berater                                  | Consulting           | Senior          | exac/keyw           \n"
     ]
    }
   ],
   "source": [
    "# Make predictions on sample\n",
    "sample_titles = inference_df['title'].head(20).tolist()\n",
    "\n",
    "# Predict with details (includes match method and confidence)\n",
    "dept_preds = dept_clf.predict_with_details(sample_titles)\n",
    "sen_preds = sen_clf.predict_with_details(sample_titles)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"INFERENCE DEMO: Rule-Based Predictions\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Title':<40} | {'Department':<20} | {'Seniority':<15} | {'Methods':<20}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for title, (dept, dept_conf, dept_method), (sen, sen_conf, sen_method) in zip(sample_titles, dept_preds, sen_preds):\n",
    "    title_short = title[:37] + \"...\" if len(title) > 40 else title\n",
    "    methods = f\"{dept_method[:4]}/{sen_method[:4]}\"\n",
    "    print(f\"{title_short:<40} | {dept:<20} | {sen:<15} | {methods:<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Match Method Statistics\n",
    "\n",
    "Let's analyze which matching strategies are being used most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department Classification Methods:\n",
      "--------------------------------------------------\n",
      "  Exact          :    24 (  7.6%)\n",
      "  Substring      :    26 (  8.3%)\n",
      "  Keyword        :    67 ( 21.3%)\n",
      "  Fuzzy          :    32 ( 10.2%)\n",
      "  Default        :   165 ( 52.5%)\n",
      "  TOTAL          :   314 (100.0%)\n",
      "\n",
      "Seniority Classification Methods:\n",
      "--------------------------------------------------\n",
      "  Exact          :    91 ( 29.0%)\n",
      "  Substring      :    77 ( 24.5%)\n",
      "  Keyword        :    81 ( 25.8%)\n",
      "  Fuzzy          :     0 (  0.0%)\n",
      "  Default        :    65 ( 20.7%)\n",
      "  TOTAL          :   314 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze matching methods on inference data\n",
    "all_titles = inference_df['title'].tolist()\n",
    "dept_stats = dept_clf.get_stats(all_titles)\n",
    "sen_stats = sen_clf.get_stats(all_titles)\n",
    "\n",
    "print(\"Department Classification Methods:\")\n",
    "print(\"-\" * 50)\n",
    "total = len(all_titles)\n",
    "for method, count in dept_stats.items():\n",
    "    pct = 100 * count / total\n",
    "    print(f\"  {method.capitalize():<15}: {count:>5} ({pct:>5.1f}%)\")\n",
    "print(f\"  {'TOTAL':<15}: {total:>5} (100.0%)\")\n",
    "\n",
    "print(\"\\nSeniority Classification Methods:\")\n",
    "print(\"-\" * 50)\n",
    "for method, count in sen_stats.items():\n",
    "    pct = 100 * count / total\n",
    "    print(f\"  {method.capitalize():<15}: {count:>5} ({pct:>5.1f}%)\")\n",
    "print(f\"  {'TOTAL':<15}: {total:>5} (100.0%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation on Annotated Dataset\n",
    "\n",
    "**FIRST TIME LOADING ANNOTATED DATA**\n",
    "\n",
    "Now we evaluate on the held-out annotated dataset to get true performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5df42",
   "metadata": {},
   "source": [
    "We now evaluate both the **Basic (No Fallback)** and **Enhanced (With Fallback)** versions on our real-world dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 478 annotated positions for evaluation\n"
     ]
    }
   ],
   "source": [
    "# Load annotated evaluation dataset\n",
    "eval_df = load_evaluation_dataset(DATA_DIR)\n",
    "print(f\"Loaded {len(eval_df):,} annotated positions for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29a731ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Version</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Department</td>\n",
       "      <td>Basic (No Fallback)</td>\n",
       "      <td>0.282427</td>\n",
       "      <td>0.443919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Department</td>\n",
       "      <td>Enhanced (With Fallback)</td>\n",
       "      <td>0.682008</td>\n",
       "      <td>0.552541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seniority</td>\n",
       "      <td>Basic (No Fallback)</td>\n",
       "      <td>0.430962</td>\n",
       "      <td>0.388610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seniority</td>\n",
       "      <td>Enhanced (With Fallback)</td>\n",
       "      <td>0.583682</td>\n",
       "      <td>0.548060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Task                   Version  Accuracy  F1 Macro\n",
       "0  Department       Basic (No Fallback)  0.282427  0.443919\n",
       "1  Department  Enhanced (With Fallback)  0.682008  0.552541\n",
       "2   Seniority       Basic (No Fallback)  0.430962  0.388610\n",
       "3   Seniority  Enhanced (With Fallback)  0.583682  0.548060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Run predictions for both versions on the evaluation set\n",
    "eval_titles = eval_df['title'].tolist()\n",
    "dept_true = eval_df['department'].tolist()\n",
    "sen_true = eval_df['seniority'].tolist()\n",
    "\n",
    "# Basic version (Unclassified if no match)\n",
    "dept_preds_basic = [p if p is not None else 'Unclassified' for p in dept_clf_basic.predict(eval_titles)]\n",
    "sen_preds_basic = [p if p is not None else 'Unclassified' for p in sen_clf_basic.predict(eval_titles)]\n",
    "\n",
    "# Enhanced version (Statistical fallbacks)\n",
    "dept_preds_enhanced = dept_clf.predict(eval_titles)\n",
    "sen_preds_enhanced = sen_clf.predict(eval_titles)\n",
    "\n",
    "# Results compilation\n",
    "comparison = pd.DataFrame({\n",
    "    'Task': ['Department', 'Department', 'Seniority', 'Seniority'],\n",
    "    'Version': ['Basic (No Fallback)', 'Enhanced (With Fallback)', 'Basic (No Fallback)', 'Enhanced (With Fallback)'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(dept_true, dept_preds_basic),\n",
    "        accuracy_score(dept_true, dept_preds_enhanced),\n",
    "        accuracy_score(sen_true, sen_preds_basic),\n",
    "        accuracy_score(sen_true, sen_preds_enhanced)\n",
    "    ],\n",
    "    'F1 Macro': [\n",
    "        f1_score(dept_true, dept_preds_basic, average='macro', zero_division=0),\n",
    "        f1_score(dept_true, dept_preds_enhanced, average='macro', zero_division=0),\n",
    "        f1_score(sen_true, sen_preds_basic, average='macro', zero_division=0),\n",
    "        f1_score(sen_true, sen_preds_enhanced, average='macro', zero_division=0)\n",
    "    ]\n",
    "})\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dept_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m fig, axes = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m20\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Department confusion matrix (left)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m dept_cm = confusion_matrix(dept_true, \u001b[43mdept_predictions\u001b[49m)\n\u001b[32m      6\u001b[39m dept_labels = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(dept_true + dept_predictions))\n\u001b[32m      8\u001b[39m sns.heatmap(dept_cm, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      9\u001b[39m             xticklabels=dept_labels, yticklabels=dept_labels, ax=axes[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'dept_predictions' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkwAAAKZCAYAAAD6TgfdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAALKpJREFUeJzt3X+M1/V9wPHXAXJoJmcdE5CdZdpZ26rQgtzQmsaG9RINrX8sZWqEEX/M6UzHZauglqt1FeesIalniVZn/5iDtlHTFHLO0pLGykIKkthVbCy2sKYgrJNz2ILCZ/l8FiiHh+VDubvvl9fjkXwrn899Pnefb/P2+Lx9fj7fT0tRFEUAAAAAAAAkNmK4DwAAAAAAAGC4CSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAerWDyfe///2YPXt2nHnmmdHS0hJPP/3079xnzZo18ZGPfCRaW1vjfe97Xzz++OPHerwAAAANzZwJAACSBJPdu3fHlClToqen56i2f/XVV+OKK66Iyy67LDZu3Bh/93d/F9dff30888wzx3K8AAAADc2cCQAAmlNLURTFMe/c0hJPPfVUXHnllUfc5rbbbouVK1fGj370o4Pr/vIv/zJef/316O3tPdYfDQAA0PDMmQAAoHmMGuwfsHbt2pg1a1a/dZ2dndVVU0eyZ8+e6nXA/v3741e/+lX84R/+YTXhAACAE1l5TdMbb7xRfaTTiBEeO3iiM2cCAIDGmDcNejDZtm1bjB8/vt+6crmvry9+/etfx8knn/yOfZYsWRJ33XXXYB8aAAA0tK1bt8Yf//EfD/dhMMjMmQAAoDHmTYMeTI7FokWLoqur6+Dyrl274qyzzqre+NixY4f12AAAYLCV/6G8vb09Tj311OE+FBqUORMAANn1DcK8adCDyYQJE2L79u391pXL5Un8QFdKlVpbW6vX4cp9nPwDAJCFj1bKwZwJAAAaY9406B+IPHPmzFi9enW/dc8++2y1HgAAIDtzJgAAaAy1g8n//u//xsaNG6tX6dVXX63+vGXLloO3hs+dO/fg9jfddFNs3rw5PvvZz8amTZvioYceiq9//euxYMGC4/k+AAAAGoI5EwAAJAkmP/zhD+PDH/5w9SqVn5tb/nnx4sXV8i9/+cuDE4HSn/zJn8TKlSurK6SmTJkSX/rSl+KrX/1qdHZ2Hs/3AQAA0BDMmQAAoDm1FEVRRBM8vKWtra16kKHP4wUA4ETn/Je6jBkAALLpG4Rz4EF/hgkAAAAAAECjE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEjvmIJJT09PTJ48OcaMGRMdHR2xbt26d91+6dKl8f73vz9OPvnkaG9vjwULFsRvfvObYz1mAACAhmbOBAAACYLJihUroqurK7q7u2PDhg0xZcqU6OzsjNdee23A7Z944olYuHBhtf1LL70Ujz76aPU9br/99uNx/AAAAA3FnAkAAJIEkwceeCBuuOGGmD9/fnzwgx+MZcuWxSmnnBKPPfbYgNs///zzcckll8TVV19dXWH1iU98Iq666qrfeYUVAABAMzJnAgCABMFk7969sX79+pg1a9Zvv8GIEdXy2rVrB9zn4osvrvY5cLK/efPmWLVqVVx++eVH/Dl79uyJvr6+fi8AAIBGZ84EAADNa1SdjXfu3Bn79u2L8ePH91tfLm/atGnAfcqrpMr9PvrRj0ZRFPH222/HTTfd9K63ly9ZsiTuuuuuOocGAAAw7MyZAAAg2UPf61izZk3cc8898dBDD1Wf3/vkk0/GypUr4+677z7iPosWLYpdu3YdfG3dunWwDxMAAGBYmDMBAEAT3mEybty4GDlyZGzfvr3f+nJ5woQJA+7zuc99Lq699tq4/vrrq+ULLrggdu/eHTfeeGPccccd1e3ph2ttba1eAAAAzcScCQAAktxhMnr06Jg2bVqsXr364Lr9+/dXyzNnzhxwnzfffPMdJ/jlBKJU3m4OAABwojBnAgCAJHeYlLq6umLevHkxffr0mDFjRixdurS6+mn+/PnV1+fOnRuTJk2qPlO3NHv27HjggQfiwx/+cHR0dMQrr7xSXUFVrj8wCQAAADhRmDMBAECSYDJnzpzYsWNHLF68OLZt2xZTp06N3t7egw813LJlS7+ro+68885oaWmp/vmLX/wi/uiP/qg68f/iF794fN8JAABAAzBnAgCA5tRSNME93n19fdHW1lY9zHDs2LHDfTgAADConP9SlzEDAEA2fYNwDlzrGSYAAAAAAAAnIsEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0jimY9PT0xOTJk2PMmDHR0dER69ate9ftX3/99bjlllti4sSJ0draGueee26sWrXqWI8ZAACgoZkzAQBA8xlVd4cVK1ZEV1dXLFu2rDrxX7p0aXR2dsbLL78cZ5xxxju237t3b/z5n/959bVvfvObMWnSpPj5z38ep5122vF6DwAAAA3DnAkAAJpTS1EURZ0dyhP+iy66KB588MFqef/+/dHe3h633nprLFy48B3bl5OEf/7nf45NmzbFSSeddEwH2dfXF21tbbFr164YO3bsMX0PAABoFs5/m5s5EwAADL7BOAeu9ZFc5ZVP69evj1mzZv32G4wYUS2vXbt2wH2+9a1vxcyZM6vby8ePHx/nn39+3HPPPbFv377f/+gBAAAaiDkTAAAk+UiunTt3Vift5Un8ocrl8mqogWzevDm++93vxjXXXFN9Bu8rr7wSN998c7z11lvR3d094D579uypXoeWIgAAgEZnzgQAAMke+l5Heft5+Vm8Dz/8cEybNi3mzJkTd9xxR3Xb+ZEsWbKkupXmwKu8fR0AAOBEZM4EAABNGEzGjRsXI0eOjO3bt/dbXy5PmDBhwH0mTpwY5557brXfAR/4wAdi27Zt1e3qA1m0aFH1uWMHXlu3bq1zmAAAAMPCnAkAAJIEk9GjR1dXPK1evbrf1VDlcvmZuwO55JJLqlvKy+0O+MlPflJNCsrvN5DW1tbqIS2HvgAAABqdORMAACT6SK6urq545JFH4mtf+1q89NJL8Td/8zexe/fumD9/fvX1uXPnVlc7HVB+/Ve/+lV85jOfqU76V65cWT3AsHygIQAAwInGnAkAABI89L1Ufp7ujh07YvHixdUt4lOnTo3e3t6DDzXcsmVLjBjx2w5TfpbuM888EwsWLIgLL7wwJk2aVE0EbrvttuP7TgAAABqAORMAADSnlqIoimhwfX191YMMy8/mdas5AAAnOue/1GXMAACQTd8gnAPX/kguAAAAAACAE41gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQ3jEFk56enpg8eXKMGTMmOjo6Yt26dUe13/Lly6OlpSWuvPLKY/mxAAAATcGcCQAAEgSTFStWRFdXV3R3d8eGDRtiypQp0dnZGa+99tq77vezn/0s/v7v/z4uvfTS3+d4AQAAGpo5EwAAJAkmDzzwQNxwww0xf/78+OAHPxjLli2LU045JR577LEj7rNv37645ppr4q677oqzzz779z1mAACAhmXOBAAACYLJ3r17Y/369TFr1qzffoMRI6rltWvXHnG/L3zhC3HGGWfEddddd1Q/Z8+ePdHX19fvBQAA0OjMmQAAIEkw2blzZ3Xl0/jx4/utL5e3bds24D7PPfdcPProo/HII48c9c9ZsmRJtLW1HXy1t7fXOUwAAIBhYc4EAADJHvp+tN5444249tprqxP/cePGHfV+ixYtil27dh18bd26dTAPEwAAYFiYMwEAQOMYVWfj8gR+5MiRsX379n7ry+UJEya8Y/uf/vSn1YMLZ8+efXDd/v37//8HjxoVL7/8cpxzzjnv2K+1tbV6AQAANBNzJgAASHKHyejRo2PatGmxevXqfifz5fLMmTPfsf15550XL774YmzcuPHg65Of/GRcdtll1Z/dNg4AAJxIzJkAACDJHSalrq6umDdvXkyfPj1mzJgRS5cujd27d8f8+fOrr8+dOzcmTZpUfabumDFj4vzzz++3/2mnnVb98/D1AAAAJwJzJgAASBJM5syZEzt27IjFixdXDy2cOnVq9Pb2Hnyo4ZYtW2LEiEF9NAoAAEDDMmcCAIDm1FIURRENrq+vL9ra2qqHGY4dO3a4DwcAAAaV81/qMmYAAMimbxDOgV3WBAAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6ggkAAAAAAJCeYAIAAAAAAKQnmAAAAAAAAOkJJgAAAAAAQHqCCQAAAAAAkJ5gAgAAAAAApCeYAAAAAAAA6QkmAAAAAABAeoIJAAAAAACQ3jEFk56enpg8eXKMGTMmOjo6Yt26dUfc9pFHHolLL7003vOe91SvWbNmvev2AAAAzc6cCQAAEgSTFStWRFdXV3R3d8eGDRtiypQp0dnZGa+99tqA269Zsyauuuqq+N73vhdr166N9vb2+MQnPhG/+MUvjsfxAwAANBRzJgAAaE4tRVEUdXYor4666KKL4sEHH6yW9+/fX53Q33rrrbFw4cLfuf++ffuqq6bK/efOnXtUP7Ovry/a2tpi165dMXbs2DqHCwAATcf5b3MzZwIAgME3GOfAte4w2bt3b6xfv766RfzgNxgxolour4Q6Gm+++Wa89dZbcfrppx9xmz179lRv9tAXAABAozNnAgCA5lUrmOzcubO62mn8+PH91pfL27ZtO6rvcdttt8WZZ57ZbwJxuCVLllRl6MCrvBoLAACg0ZkzAQBAsoe+H6t77703li9fHk899VT18MMjWbRoUXUbzYHX1q1bh/IwAQAAhoU5EwAADJ9RdTYeN25cjBw5MrZv395vfbk8YcKEd933/vvvr07+v/Od78SFF174rtu2trZWLwAAgGZizgQAAEnuMBk9enRMmzYtVq9efXBd+QDDcnnmzJlH3O++++6Lu+++O3p7e2P69Om/3xEDAAA0KHMmAABIcodJqaurK+bNm1edxM+YMSOWLl0au3fvjvnz51dfnzt3bkyaNKn6TN3SP/3TP8XixYvjiSeeiMmTJx/83N4/+IM/qF4AAAAnEnMmAABIEkzmzJkTO3bsqE7oyxP5qVOnVldBHXio4ZYtW2LEiN/euPKVr3wl9u7dG3/xF3/R7/t0d3fH5z//+ePxHgAAABqGORMAADSnlqIoimhwfX190dbWVj3McOzYscN9OAAAMKic/1KXMQMAQDZ9g3AOXOsZJgAAAAAAACciwQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAABITzABAAAAAADSE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPSOKZj09PTE5MmTY8yYMdHR0RHr1q171+2/8Y1vxHnnnVdtf8EFF8SqVauO9XgBAAAanjkTAAAkCCYrVqyIrq6u6O7ujg0bNsSUKVOis7MzXnvttQG3f/755+Oqq66K6667Ll544YW48sorq9ePfvSj43H8AAAADcWcCQAAmlNLURRFnR3Kq6MuuuiiePDBB6vl/fv3R3t7e9x6662xcOHCd2w/Z86c2L17d3z7298+uO7P/uzPYurUqbFs2bKj+pl9fX3R1tYWu3btirFjx9Y5XAAAaDrOf5ubORMAAAy+wTgHHlVn471798b69etj0aJFB9eNGDEiZs2aFWvXrh1wn3J9eXXVocqrq55++ukj/pw9e/ZUrwPKN3zg/wAAADjRHTjvrXltEw3AnAkAAJp33lQrmOzcuTP27dsX48eP77e+XN60adOA+2zbtm3A7cv1R7JkyZK466673rG+vCoLAACy+O///u/qiimahzkTAAA077ypVjAZKuXVWIdeYfX666/He9/73tiyZYsJI0ddF8vJ4tatW30kAUfFmKEO44W6jBnqKu8WOOuss+L0008f7kOhQZkz8fvydxN1GTPUZcxQlzFDI8ybagWTcePGxciRI2P79u391pfLEyZMGHCfcn2d7Uutra3V63Dlib9/WaijHC/GDHUYM9RhvFCXMUNd5Uc50VzMmWg2/m6iLmOGuowZ6jJmGM55U63vNHr06Jg2bVqsXr364LryAYbl8syZMwfcp1x/6PalZ5999ojbAwAANCtzJgAAaF61P5KrvO173rx5MX369JgxY0YsXbo0du/eHfPnz6++Pnfu3Jg0aVL1mbqlz3zmM/Gxj30svvSlL8UVV1wRy5cvjx/+8Ifx8MMPH/93AwAAMMzMmQAAIEkwmTNnTuzYsSMWL15cPYRw6tSp0dvbe/AhheVn5h56C8zFF18cTzzxRNx5551x++23x5/+6Z/G008/Heeff/5R/8zyVvPu7u4BbzmHgRgz1GXMUIfxQl3GDHUZM83NnIlmYMxQlzFDXcYMdRkzNMKYaSmKojhu3w0AAAAAAKAJeYokAAAAAACQnmACAAAAAACkJ5gAAAAAAADpCSYAAAAAAEB6DRNMenp6YvLkyTFmzJjo6OiIdevWvev23/jGN+K8886rtr/gggti1apVQ3asNN+YeeSRR+LSSy+N97znPdVr1qxZv3OMcWKp+zvmgOXLl0dLS0tceeWVg36MNPeYef311+OWW26JiRMnRmtra5x77rn+bkqm7phZunRpvP/974+TTz452tvbY8GCBfGb3/xmyI6X4fX9738/Zs+eHWeeeWb198zTTz/9O/dZs2ZNfOQjH6l+x7zvfe+Lxx9/fEiOlcZhzkRd5kzUZd5EXeZN1GXeRMPPmYoGsHz58mL06NHFY489Vvznf/5nccMNNxSnnXZasX379gG3/8EPflCMHDmyuO+++4of//jHxZ133lmcdNJJxYsvvjjkx05zjJmrr7666OnpKV544YXipZdeKv7qr/6qaGtrK/7rv/5ryI+dxh8vB7z66qvFpEmTiksvvbT41Kc+NWTHS/ONmT179hTTp08vLr/88uK5556rxs6aNWuKjRs3Dvmx0xxj5l//9V+L1tbW6p/leHnmmWeKiRMnFgsWLBjyY2d4rFq1qrjjjjuKJ598sihPyZ966ql33X7z5s3FKaecUnR1dVXnv1/+8per8+He3t4hO2aGlzkTdZkzUZd5E3WZN1GXeRPNMGdqiGAyY8aM4pZbbjm4vG/fvuLMM88slixZMuD2n/70p4srrrii37qOjo7ir//6rwf9WGkMdcfM4d5+++3i1FNPLb72ta8N4lHSzOOlHCMXX3xx8dWvfrWYN2+eE/9k6o6Zr3zlK8XZZ59d7N27dwiPkmYeM+W2H//4x/utK0/qLrnkkkE/VhrP0Zz8f/azny0+9KEP9Vs3Z86corOzc5CPjkZhzkRd5kzUZd5EXeZN1GXeRDPMmYb9I7n27t0b69evr273PWDEiBHV8tq1awfcp1x/6Palzs7OI27PieVYxszh3nzzzXjrrbfi9NNPH8QjpZnHyxe+8IU444wz4rrrrhuiI6WZx8y3vvWtmDlzZnVr+fjx4+P888+Pe+65J/bt2zeER04zjZmLL7642ufA7eebN2+uPorg8ssvH7Ljprk4/83NnIm6zJmoy7yJusybqMu8icF2vM5/R8Uw27lzZ/WLsfxFeahyedOmTQPus23btgG3L9dz4juWMXO42267rfr8u8P/JeLEcyzj5bnnnotHH300Nm7cOERHSbOPmfKk7bvf/W5cc8011cnbK6+8EjfffHP1Hxm6u7uH6MhppjFz9dVXV/t99KMfLe/2jbfffjtuuummuP3224foqGk2Rzr/7evri1//+tfVZzpz4jJnoi5zJuoyb6Iu8ybqMm+iWeZMw36HCQy1e++9t3og3VNPPVU9YAoO9cYbb8S1115bPfRy3Lhxw304NIn9+/dXV9Y9/PDDMW3atJgzZ07ccccdsWzZsuE+NBpU+SC68mq6hx56KDZs2BBPPvlkrFy5Mu6+++7hPjQAMGfidzJv4liYN1GXeRPDYdjvMCn/Yh05cmRs37693/pyecKECQPuU66vsz0nlmMZMwfcf//91cn/d77znbjwwgsH+UhpxvHy05/+NH72s5/F7Nmz+53UlUaNGhUvv/xynHPOOUNw5DTT75iJEyfGSSedVO13wAc+8IHq6obytuPRo0cP+nHTXGPmc5/7XPUfGa6//vpq+YILLojdu3fHjTfeWE0ay1vT4WjOf8eOHevukgTMmajLnIm6zJuoy7yJusybaJY507CPqvKXYVmVV69e3e8v2XK5/FzDgZTrD92+9Oyzzx5xe04sxzJmSvfdd19VoHt7e2P69OlDdLQ023g577zz4sUXX6xuKz/w+uQnPxmXXXZZ9ef29vYhfgc0w++YSy65pLqd/MAksfSTn/ykmhA46T/xHcuYKT8X/vCT+wMTx/9/nh305/w3N3Mm6jJnoi7zJuoyb6Iu8yYG23E7/y0awPLly4vW1tbi8ccfL3784x8XN954Y3HaaacV27Ztq75+7bXXFgsXLjy4/Q9+8INi1KhRxf3331+89NJLRXd3d3HSSScVL7744jC+Cxp5zNx7773F6NGji29+85vFL3/5y4OvN954YxjfBY06Xg43b9684lOf+tQQHjHNNma2bNlSnHrqqcXf/u3fFi+//HLx7W9/uzjjjDOKf/zHfxzGd0Ejj5ny3KUcM//2b/9WbN68ufj3f//34pxzzik+/elPD+O7YCiV5yAvvPBC9SpPyR944IHqzz//+c+rr5fjpRw3B5Tj5JRTTin+4R/+oTr/7enpKUaOHFn09vYO47tgKJkzUZc5E3WZN1GXeRN1mTfRDHOmhggmpS9/+cvFWWedVZ2gzZgxo/iP//iPg1/72Mc+Vv3Fe6ivf/3rxbnnnltt/6EPfahYuXLlMBw1zTJm3vve91b/Yh3+Kn/xkkPd3zGHcuKfU90x8/zzzxcdHR3Vyd/ZZ59dfPGLXyzefvvtYThymmHMvPXWW8XnP//56mR/zJgxRXt7e3HzzTcX//M//zNMR89Q+973vjfgucmBcVL+sxw3h+8zderUaoyVv2f+5V/+ZZiOnuFizkRd5kzUZd5EXeZN1GXeRKPPmVrK/zm+N78AAAAAAAA0l2F/hgkAAAAAAMBwE0wAAAAAAID0BBMAAAAAACA9wQQAAAAAAEhPMAEAAAAAANITTAAAAAAAgPQEEwAAAAAAID3BBAAAAAAASE8wAQAAAAAA0hNMAAAAAACA9AQTAAAAAAAgPcEEAAAAAACI7P4PMa4Vmc2CFPIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create confusion matrices - 4 plots (2x2 grid)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "# Top row: Basic (No Fallback)\n",
    "# Department confusion matrix (top left)\n",
    "dept_cm_basic = confusion_matrix(dept_true, dept_preds_basic)\n",
    "dept_labels_basic = sorted(set(dept_true + dept_preds_basic))\n",
    "\n",
    "sns.heatmap(dept_cm_basic, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=dept_labels_basic, yticklabels=dept_labels_basic, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Department - Basic (No Fallback)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "axes[0, 0].tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "# Seniority confusion matrix (top right)\n",
    "sen_cm_basic = confusion_matrix(sen_true, sen_preds_basic)\n",
    "sen_labels_basic = sorted(set(sen_true + sen_preds_basic))\n",
    "\n",
    "sns.heatmap(sen_cm_basic, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=sen_labels_basic, yticklabels=sen_labels_basic, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Seniority - Basic (No Fallback)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('True Label', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "axes[0, 1].tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "# Bottom row: Enhanced (With Fallback)\n",
    "# Department confusion matrix (bottom left)\n",
    "dept_cm_enhanced = confusion_matrix(dept_true, dept_preds_enhanced)\n",
    "dept_labels_enhanced = sorted(set(dept_true + dept_preds_enhanced))\n",
    "\n",
    "sns.heatmap(dept_cm_enhanced, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=dept_labels_enhanced, yticklabels=dept_labels_enhanced, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Department - Enhanced (With Fallback)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('True Label', fontsize=12)\n",
    "axes[1, 0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "axes[1, 0].tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "# Seniority confusion matrix (bottom right)\n",
    "sen_cm_enhanced = confusion_matrix(sen_true, sen_preds_enhanced)\n",
    "sen_labels_enhanced = sorted(set(sen_true + sen_preds_enhanced))\n",
    "\n",
    "sns.heatmap(sen_cm_enhanced, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=sen_labels_enhanced, yticklabels=sen_labels_enhanced, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Seniority - Enhanced (With Fallback)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1, 1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "axes[1, 1].tick_params(axis='y', rotation=0, labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb5884",
   "metadata": {},
   "source": [
    "### Analysis: Why the Fallback Improves Results\n",
    "\n",
    "The **Enhanced** version shows significantly higher performance than the **Basic** version. This is for several key reasons:\n",
    "\n",
    "1. **Majority Class Capture**: In real-world data like LinkedIn, many job titles are generic or unique to a company. Our EDA showed that `Other` (for department) and `Professional` (for seniority) are the dominant classes. By falling back to these when unsure, the model correctly handles the large volume of \"unmatchable\" titles.\n",
    "\n",
    "2. **Handling Exhaustiveness**: Seniority, in particular, is an exhaustive set of 6 levels. Every job has a seniority level, but not every title contains a clear seniority keyword. Assuming `Professional` for unknown titles is a strong statistical prior that covers most individual contributors.\n",
    "\n",
    "3. **Coverage vs. Precision**: The Basic model has higher precision for the titles it *does* classify but suffers in recall and overall accuracy because it leaves over 50% of titles unclassified. The Enhanced model provides a classification for every input, leveraging the dataset's distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d4965",
   "metadata": {},
   "source": [
    "## 6. Saving Results for Comparison\n",
    "\n",
    "We save the **Basic (No Fallback)** results to the standard path. In the final comparison notebook, we use this version as the rule-based baseline to show its \"raw\" intelligence, while noting how fallbacks can drastically improve these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5e2892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "RESULTS_DIR = Path('results')\n",
    "if not RESULTS_DIR.exists():\n",
    "    # Fallback to local results if not in standard project structure\n",
    "    RESULTS_DIR = Path('notebooks/results')\n",
    "\n",
    "dept_p, dept_r, dept_f1, _ = precision_recall_fscore_support(dept_true, dept_preds_basic, average='macro', zero_division=0)\n",
    "sen_p, sen_r, sen_f1, _ = precision_recall_fscore_support(sen_true, sen_preds_basic, average='macro', zero_division=0)\n",
    "\n",
    "# Accuracy values from the comparison table\n",
    "results = {\n",
    "    'approach': 'Rule-Based (No Fallback)',\n",
    "    'department': {\n",
    "        'accuracy': float(comparison.loc[0, 'Accuracy']),\n",
    "        'f1_macro': float(comparison.loc[0, 'F1 Macro']),\n",
    "        'precision': float(dept_p),\n",
    "        'recall': float(dept_r)\n",
    "    },\n",
    "    'seniority': {\n",
    "        'accuracy': float(comparison.loc[2, 'Accuracy']),\n",
    "        'f1_macro': float(comparison.loc[2, 'F1 Macro'])\n",
    "    },\n",
    "    'metadata': {\n",
    "        'note': 'This version excludes fallbacks to show raw matching capability.',\n",
    "        'enhanced_accuracy_dept': float(comparison.loc[1, 'Accuracy']),\n",
    "        'enhanced_accuracy_sen': float(comparison.loc[3, 'Accuracy'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'rule_based_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
