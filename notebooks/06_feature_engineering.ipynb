{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Feature Engineering + Random Forest (Semi-Supervised)\n",
    "\n",
    "**Objective**: Combine hand-crafted features with TF-IDF and train a Random Forest classifier.\n",
    "\n",
    "**Key Innovation**: Semi-supervised learning using:\n",
    "- **Gold Data**: CSV lookup tables (~2.5k per class after balancing)\n",
    "- **Silver Data**: Pseudo-labeled unannotated LinkedIn data (~50 usable examples)\n",
    "\n",
    "**Features**:\n",
    "1. **TF-IDF**: Captures important job title keywords (1-2 grams)\n",
    "2. **Manual Features**: Length, word count, keyword presence\n",
    "3. **Career History**: Number of previous jobs, total positions (only in Silver/JSON)\n",
    "\n",
    "**Data Usage**:\n",
    "- **Training**: CSV (Gold) + Pseudo-labeled JSON (Silver)\n",
    "- **In-Distribution Eval**: 80/20 split on CSV\n",
    "- **Real-World Eval**: Annotated LinkedIn CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from src.data.loader import load_label_lists, load_evaluation_dataset, balance_dataset\n",
    "\n",
    "DATA_DIR = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying encoding fix...\n",
      "Deduplicating department labels...\n",
      "  Deduplication: 10145 -> 10145 (removed 0 duplicates)\n",
      "Deduplicating seniority labels...\n",
      "  Deduplication: 9428 -> 9428 (removed 0 duplicates)\n",
      "ðŸ¥ˆ Loaded 314 department silver labels\n",
      "ðŸ¥ˆ Loaded 314 seniority silver labels\n",
      "\n",
      "ðŸ“Š Gold Department: 10,145 examples\n",
      "ðŸ“Š Gold Seniority:  9,428 examples\n",
      "ðŸ“Š Real-world JSON CVs: 478\n"
     ]
    }
   ],
   "source": [
    "# Load Gold Data (CSVs) - these have 'text' and 'label' columns\n",
    "dept_gold, sen_gold = load_label_lists(DATA_DIR, fix_encoding=True, deduplicate=True, max_per_class=None)\n",
    "\n",
    "# Load Silver Data (Pseudo-labeled Unannotated JSON)\n",
    "silver_path = DATA_DIR / \"processed/unannotated_pseudo_labeled.csv\"\n",
    "if silver_path.exists():\n",
    "    silver_df = pd.read_csv(silver_path)\n",
    "    \n",
    "    # Extract department silver labels (rename 'title' to 'text' for consistency)\n",
    "    dept_silver = silver_df[silver_df['dept_pseudo'].notna()][['title', 'dept_pseudo']].copy()\n",
    "    dept_silver = dept_silver.rename(columns={'dept_pseudo': 'label', 'title': 'text'})\n",
    "    \n",
    "    # Extract seniority silver labels\n",
    "    sen_silver = silver_df[silver_df['sen_pseudo'].notna()][['title', 'sen_pseudo']].copy()\n",
    "    sen_silver = sen_silver.rename(columns={'sen_pseudo': 'label', 'title': 'text'})\n",
    "    \n",
    "    print(f\"ðŸ¥ˆ Loaded {len(dept_silver)} department silver labels\")\n",
    "    print(f\"ðŸ¥ˆ Loaded {len(sen_silver)} seniority silver labels\")\n",
    "else:\n",
    "    dept_silver = pd.DataFrame(columns=['text', 'label'])\n",
    "    sen_silver = pd.DataFrame(columns=['text', 'label'])\n",
    "    print(\"âš ï¸  Silver data not found, falling back to Gold only.\")\n",
    "\n",
    "# Load Evaluation Data (has 'title' column)\n",
    "eval_df = load_evaluation_dataset(DATA_DIR)\n",
    "\n",
    "print(f\"\\nðŸ“Š Gold Department: {len(dept_gold):,} examples\")\n",
    "print(f\"ðŸ“Š Gold Seniority:  {len(sen_gold):,} examples\")\n",
    "print(f\"ðŸ“Š Real-world JSON CVs: {len(eval_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    \"\"\"\n",
    "    Extract hand-crafted features from job titles and history.\n",
    "    \n",
    "    Works with DataFrames that have either 'text' or 'title' column.\n",
    "    \"\"\"\n",
    "    # Auto-detect text column\n",
    "    text_col = 'title' if 'title' in df.columns else 'text'\n",
    "    \n",
    "    # Get the text data as a clean 1D array\n",
    "    texts = df[text_col].astype(str).values\n",
    "    \n",
    "    # Initialize features\n",
    "    feats = {}\n",
    "    \n",
    "    # 1. Basic Title Stats\n",
    "    feats['title_len'] = [len(t) for t in texts]\n",
    "    feats['word_count'] = [len(t.split()) for t in texts]\n",
    "    \n",
    "    # 2. Career History (only available in Silver/JSON)\n",
    "    if 'num_previous_jobs' in df.columns:\n",
    "        feats['num_prev'] = df['num_previous_jobs'].fillna(0).values\n",
    "        feats['total_pos'] = df['total_positions'].fillna(1).values\n",
    "    else:\n",
    "        feats['num_prev'] = [0] * len(texts)\n",
    "        feats['total_pos'] = [1] * len(texts)\n",
    "    \n",
    "    # 3. Keyword Features\n",
    "    sen_keywords = ['senior', 'lead', 'principal', 'manager', 'director', 'vp', 'head', 'junior', 'intern', 'trainee']\n",
    "    for kw in sen_keywords:\n",
    "        feats[f'has_{kw}'] = [int(kw in t.lower()) for t in texts]\n",
    "    \n",
    "    dept_keywords = {\n",
    "        'it': ['engineer', 'developer', 'software', 'tech', 'data', 'it'],\n",
    "        'sales': ['sales', 'account', 'revenue'],\n",
    "        'mkt': ['marketing', 'brand', 'content'],\n",
    "        'hr': ['hr', 'recruitment', 'people', 'talent'],\n",
    "        'fin': ['finance', 'accounting', 'audit', 'tax']\n",
    "    }\n",
    "    for dept, keywords in dept_keywords.items():\n",
    "        feats[f'has_{dept}'] = [int(any(k in t.lower() for k in keywords)) for t in texts]\n",
    "    \n",
    "    return pd.DataFrame(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Department Classifier (Gold + Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined: 8116 gold + 314 silver = 8430 total\n",
      "Balancing: 8430 -> 9075 samples\n",
      "  Class distribution: {'Marketing': 2000, 'Sales': 2000, 'Information Technology': 1054, 'Business Development': 521, 'Project Management': 500, 'Consulting': 500, 'Administrative': 500, 'Other': 500, 'Purchasing': 500, 'Human Resources': 500, 'Customer Support': 500}\n",
      "After balancing: 9075 examples\n",
      "\n",
      "Training features: (9075, 2019)\n",
      "Testing features:  (2029, 2019)\n"
     ]
    }
   ],
   "source": [
    "# A. Train/Test Split (In-Distribution on Gold)\n",
    "gold_train, gold_test = train_test_split(\n",
    "    dept_gold, test_size=0.2, random_state=42, stratify=dept_gold['label']\n",
    ")\n",
    "\n",
    "# B. Combine Gold Train + Silver\n",
    "dept_train = pd.concat([gold_train, dept_silver], ignore_index=True)\n",
    "print(f\"Combined: {len(gold_train)} gold + {len(dept_silver)} silver = {len(dept_train)} total\")\n",
    "\n",
    "# C. Apply Tier 1 Data Balancing\n",
    "dept_train, dept_weights = balance_dataset(\n",
    "    dept_train, label_col='label', min_samples=500, max_samples=2000, return_weights=True\n",
    ")\n",
    "print(f\"After balancing: {len(dept_train)} examples\\n\")\n",
    "\n",
    "# D. Feature Extraction\n",
    "X_train_manual = extract_features(dept_train)\n",
    "X_test_manual = extract_features(gold_test)\n",
    "\n",
    "# E. TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(dept_train['text'])\n",
    "X_test_tfidf = tfidf.transform(gold_test['text'])\n",
    "\n",
    "# F. Combine Features\n",
    "X_train = hstack([X_train_manual.values, X_train_tfidf])\n",
    "X_test = hstack([X_test_manual.values, X_test_tfidf])\n",
    "y_train = dept_train['label'].values\n",
    "y_test = gold_test['label'].values\n",
    "\n",
    "print(f\"Training features: {X_train.shape}\")\n",
    "print(f\"Testing features:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEPARTMENT CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "In-Distribution (CSV Test):  0.9093\n",
      "Real-World (Annotated JSON): 0.4079\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# G. Train Random Forest\n",
    "dept_rf = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=20,\n",
    "    random_state=42, \n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "dept_rf.fit(X_train, y_train)\n",
    "\n",
    "# H. In-Distribution Evaluation (CSV test set)\n",
    "y_pred_id = dept_rf.predict(X_test)\n",
    "acc_id = accuracy_score(y_test, y_pred_id)\n",
    "\n",
    "# I. Real-World Evaluation (Annotated JSON)\n",
    "real_dept_df = eval_df[eval_df['department'].notna()].copy()\n",
    "X_real_manual = extract_features(real_dept_df)\n",
    "X_real_tfidf = tfidf.transform(real_dept_df['title'])  # eval_df has 'title' column\n",
    "X_real = hstack([X_real_manual.values, X_real_tfidf])\n",
    "y_real = real_dept_df['department'].values\n",
    "\n",
    "y_pred_real = dept_rf.predict(X_real)\n",
    "acc_real = accuracy_score(y_real, y_pred_real)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DEPARTMENT CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"In-Distribution (CSV Test):  {acc_id:.4f}\")\n",
    "print(f\"Real-World (Annotated JSON): {acc_real:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Seniority Classifier (Gold + Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined: 7542 gold + 314 silver = 7856 total\n",
      "Balancing: 7856 -> 6012 samples\n",
      "  Class distribution: {'Senior': 2000, 'Lead': 2000, 'Director': 818, 'Management': 694, 'Junior': 500}\n",
      "After balancing: 6012 examples\n",
      "\n",
      "Training features: (6012, 2019)\n",
      "Testing features:  (1886, 2019)\n"
     ]
    }
   ],
   "source": [
    "# A. Train/Test Split (In-Distribution on Gold)\n",
    "gold_train, gold_test = train_test_split(\n",
    "    sen_gold, test_size=0.2, random_state=42, stratify=sen_gold['label']\n",
    ")\n",
    "\n",
    "# B. Combine Gold Train + Silver\n",
    "sen_train = pd.concat([gold_train, sen_silver], ignore_index=True)\n",
    "print(f\"Combined: {len(gold_train)} gold + {len(sen_silver)} silver = {len(sen_train)} total\")\n",
    "\n",
    "# C. Apply Tier 1 Data Balancing\n",
    "sen_train, sen_weights = balance_dataset(\n",
    "    sen_train, label_col='label', min_samples=500, max_samples=2000, return_weights=True\n",
    ")\n",
    "print(f\"After balancing: {len(sen_train)} examples\\n\")\n",
    "\n",
    "# D. Feature Extraction\n",
    "X_train_manual = extract_features(sen_train)\n",
    "X_test_manual = extract_features(gold_test)\n",
    "\n",
    "# E. TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(sen_train['text'])\n",
    "X_test_tfidf = tfidf.transform(gold_test['text'])\n",
    "\n",
    "# F. Combine Features\n",
    "X_train = hstack([X_train_manual.values, X_train_tfidf])\n",
    "X_test = hstack([X_test_manual.values, X_test_tfidf])\n",
    "y_train = sen_train['label'].values\n",
    "y_test = gold_test['label'].values\n",
    "\n",
    "print(f\"Training features: {X_train.shape}\")\n",
    "print(f\"Testing features:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SENIORITY CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "In-Distribution (CSV Test):  0.9380\n",
      "Real-World (Annotated JSON): 0.4310\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# G. Train Random Forest\n",
    "sen_rf = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=20,\n",
    "    random_state=42, \n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "sen_rf.fit(X_train, y_train)\n",
    "\n",
    "# H. In-Distribution Evaluation (CSV test set)\n",
    "y_pred_id = sen_rf.predict(X_test)\n",
    "acc_id = accuracy_score(y_test, y_pred_id)\n",
    "\n",
    "# I. Real-World Evaluation (Annotated JSON)\n",
    "real_sen_df = eval_df[eval_df['seniority'].notna()].copy()\n",
    "X_real_manual = extract_features(real_sen_df)\n",
    "X_real_tfidf = tfidf.transform(real_sen_df['title'])\n",
    "X_real = hstack([X_real_manual.values, X_real_tfidf])\n",
    "y_real = real_sen_df['seniority'].values\n",
    "\n",
    "y_pred_real = sen_rf.predict(X_real)\n",
    "acc_real = accuracy_score(y_real, y_pred_real)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SENIORITY CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"In-Distribution (CSV Test):  {acc_id:.4f}\")\n",
    "print(f\"Real-World (Annotated JSON): {acc_real:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
