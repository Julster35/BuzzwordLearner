{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04 - Transformer Classifier\n",
                "\n",
                "This notebook implements **Approach 1: Fine-tuned Classification Model**.\n",
                "\n",
                "## Strategy: Two-Stage Training\n",
                "1. **Stage 1:** Pre-train on CSV patterns (~20K examples)\n",
                "2. **Stage 2:** Domain adaptation on annotated LinkedIn CVs (609 examples)\n",
                "\n",
                "## Objectives\n",
                "- Train a transformer on patternâ†’label mappings\n",
                "- Fine-tune on real LinkedIn data for domain adaptation\n",
                "- Evaluate on held-out test set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import torch\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "\n",
                "# Add src to path\n",
                "sys.path.insert(0, os.path.abspath(\"../\"))\n",
                "\n",
                "from src.models.transformer_classifier import TransformerClassifier\n",
                "from src.data.loader import load_linkedin_data, prepare_dataset, load_label_lists\n",
                "\n",
                "# Reproducibility\n",
                "torch.manual_seed(42)\n",
                "if torch.cuda.is_available():\n",
                "    torch.cuda.manual_seed_all(42)\n",
                "\n",
                "print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Department patterns: 10145\n",
                        "Seniority patterns: 9428\n",
                        "\n",
                        "Annotated LinkedIn positions: 478\n",
                        "With department label: 478\n",
                        "With seniority label: 478\n"
                    ]
                }
            ],
            "source": [
                "# Load CSV patterns\n",
                "dept_df, seniority_df = load_label_lists(\"../data\")\n",
                "\n",
                "print(f\"Department patterns: {len(dept_df)}\")\n",
                "print(f\"Seniority patterns: {len(seniority_df)}\")\n",
                "\n",
                "# Load LinkedIn data\n",
                "cv_data = load_linkedin_data(\"../data/linkedin-cvs-annotated.json\")\n",
                "cv_df = prepare_dataset(cv_data)\n",
                "\n",
                "print(f\"\\nAnnotated LinkedIn positions: {len(cv_df)}\")\n",
                "print(f\"With department label: {cv_df['department'].notna().sum()}\")\n",
                "print(f\"With seniority label: {cv_df['seniority'].notna().sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Stage 1: Train on CSV Patterns (Department)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Department classes: 11\n",
                        "Pattern train: 9130, val: 1015\n"
                    ]
                }
            ],
            "source": [
                "# Prepare label mappings for Department\n",
                "dept_labels = dept_df['label'].unique().tolist()\n",
                "label2id = {label: i for i, label in enumerate(dept_labels)}\n",
                "id2label = {i: label for label, i in label2id.items()}\n",
                "\n",
                "print(f\"Department classes: {len(label2id)}\")\n",
                "\n",
                "# Prepare training data from CSV\n",
                "pattern_texts = dept_df['text'].astype(str).tolist()\n",
                "pattern_labels = [label2id[l] for l in dept_df['label']]\n",
                "\n",
                "# Split patterns for validation\n",
                "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
                "    pattern_texts, pattern_labels, test_size=0.1, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Pattern train: {len(train_texts)}, val: {len(val_texts)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded on cuda\n",
                        "Training on 9130 examples...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='572' max='572' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [572/572 01:42, Epoch 2/2]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>0.129400</td>\n",
                            "      <td>0.098740</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>0.068300</td>\n",
                            "      <td>0.062031</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training complete!\n"
                    ]
                }
            ],
            "source": [
                "# Initialize and train Stage 1\n",
                "dept_classifier = TransformerClassifier(\n",
                "    model_name=\"distilbert-base-multilingual-cased\",\n",
                "    num_labels=len(label2id),\n",
                "    id2label=id2label,\n",
                "    label2id=label2id\n",
                ")\n",
                "\n",
                "# Train on patterns\n",
                "dept_classifier.train(\n",
                "    texts=train_texts,\n",
                "    labels=train_labels,\n",
                "    val_texts=val_texts,\n",
                "    val_labels=val_labels,\n",
                "    output_dir=\"./results/stage1_dept\",\n",
                "    epochs=2,\n",
                "    batch_size=32\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Stage 2: Domain Adaptation on LinkedIn Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "LinkedIn train: 382, test: 96\n"
                    ]
                }
            ],
            "source": [
                "# Prepare LinkedIn data\n",
                "cv_labeled = cv_df.dropna(subset=['department']).copy()\n",
                "\n",
                "# Filter to labels we know\n",
                "cv_labeled = cv_labeled[cv_labeled['department'].isin(label2id.keys())]\n",
                "\n",
                "# Split for train/test\n",
                "cv_train, cv_test = train_test_split(cv_labeled, test_size=0.2, random_state=42)\n",
                "\n",
                "cv_train_texts = cv_train['text'].tolist()\n",
                "cv_train_labels = [label2id[l] for l in cv_train['department']]\n",
                "\n",
                "cv_test_texts = cv_test['text'].tolist()\n",
                "cv_test_labels = cv_test['department'].tolist()\n",
                "\n",
                "print(f\"LinkedIn train: {len(cv_train)}, test: {len(cv_test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training on 382 examples...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [144/144 00:11, Epoch 3/3]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Step</th>\n",
                            "      <th>Training Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>50</td>\n",
                            "      <td>1.726200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>100</td>\n",
                            "      <td>1.100300</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training complete!\n"
                    ]
                }
            ],
            "source": [
                "# Continue training on LinkedIn data (Stage 2)\n",
                "dept_classifier.train(\n",
                "    texts=cv_train_texts,\n",
                "    labels=cv_train_labels,\n",
                "    output_dir=\"./results/stage2_dept\",\n",
                "    epochs=3,\n",
                "    batch_size=8,\n",
                "    learning_rate=1e-5  # Lower LR for fine-tuning\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================================\n",
                        "DEPARTMENT CLASSIFICATION RESULTS\n",
                        "==================================================\n",
                        "Accuracy: 0.6146\n",
                        "\n",
                        "Classification Report:\n",
                        "                        precision    recall  f1-score   support\n",
                        "\n",
                        "        Administrative       0.00      0.00      0.00         3\n",
                        "  Business Development       0.50      0.33      0.40         3\n",
                        "            Consulting       1.00      0.83      0.91         6\n",
                        "      Customer Support       0.00      0.00      0.00         3\n",
                        "       Human Resources       0.00      0.00      0.00         2\n",
                        "Information Technology       0.73      0.50      0.59        16\n",
                        "             Marketing       0.50      1.00      0.67         1\n",
                        "                 Other       0.57      0.91      0.70        43\n",
                        "    Project Management       0.75      0.43      0.55         7\n",
                        "            Purchasing       0.00      0.00      0.00         3\n",
                        "                 Sales       0.67      0.22      0.33         9\n",
                        "\n",
                        "              accuracy                           0.61        96\n",
                        "             macro avg       0.43      0.38      0.38        96\n",
                        "          weighted avg       0.57      0.61      0.56        96\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\julie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "c:\\Users\\julie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "c:\\Users\\julie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
                    ]
                }
            ],
            "source": [
                "# Predict on test set\n",
                "predictions = dept_classifier.predict_labels(cv_test_texts)\n",
                "\n",
                "# Metrics\n",
                "print(\"=\" * 50)\n",
                "print(\"DEPARTMENT CLASSIFICATION RESULTS\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Accuracy: {accuracy_score(cv_test_labels, predictions):.4f}\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(cv_test_labels, predictions))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to ..\\models\\transformer_dept\n",
                        "Model saved!\n"
                    ]
                }
            ],
            "source": [
                "# Save the trained model\n",
                "dept_classifier.save(\"../models/transformer_dept\")\n",
                "print(\"Model saved!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
