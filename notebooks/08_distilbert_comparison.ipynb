{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT Approaches Comparison - Complete Training & Analysis\n",
    "\n",
    "This notebook consolidates all 5 DistilBERT experimental approaches into a single executable notebook.\n",
    "Run this to reproduce all experiments and compare results.\n",
    "\n",
    "## Contents\n",
    "1. Setup & Data Loading (shared)\n",
    "2. **Approach 1**: Baseline (standard fine-tuning)\n",
    "3. **Approach 2**: Class Balancing (weighted loss)\n",
    "4. **Approach 3**: Oversampling\n",
    "5. **Approach 4**: Combined (weights + oversampling)\n",
    "6. **Approach 5**: Two-Stage (hierarchical)\n",
    "7. Final Comparison & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom oversampling (no imblearn dependency needed)\n",
    "def oversample_to_median(texts, labels, random_state=42):\n",
    "    \"\"\"Simple oversampling: duplicate minority class samples to reach median class size.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    texts = np.array(texts)\n",
    "    labels = np.array(labels)\n",
    "    unique_classes, counts = np.unique(labels, return_counts=True)\n",
    "    median_count = int(np.median(counts))\n",
    "    print(f\"Target median count: {median_count}\")\n",
    "    \n",
    "    texts_resampled, labels_resampled = [], []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(labels == cls)[0]\n",
    "        cls_count = len(cls_indices)\n",
    "        if cls_count < median_count:\n",
    "            n_to_add = median_count - cls_count\n",
    "            additional_indices = np.random.choice(cls_indices, size=n_to_add, replace=True)\n",
    "            all_indices = np.concatenate([cls_indices, additional_indices])\n",
    "        else:\n",
    "            all_indices = cls_indices\n",
    "        texts_resampled.extend(texts[all_indices].tolist())\n",
    "        labels_resampled.extend(labels[all_indices].tolist())\n",
    "    \n",
    "    combined = list(zip(texts_resampled, labels_resampled))\n",
    "    np.random.shuffle(combined)\n",
    "    texts_resampled, labels_resampled = zip(*combined)\n",
    "    print(f\"After oversampling: {len(labels_resampled)} samples\")\n",
    "    return list(texts_resampled), list(labels_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - update these to match your setup\n",
    "DEPT_CSV = \"../data/department-v2.csv\"\n",
    "SEN_CSV = \"../data/seniority-v2.csv\"\n",
    "CV_ANN = \"../data/linkedin-cvs-annotated.json\"\n",
    "\n",
    "# Training output directory (keeps notebooks folder clean)\n",
    "TRAINING_OUTPUT_DIR = \"./results/distilbert_training\"\n",
    "os.makedirs(TRAINING_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-multilingual-cased\"\n",
    "MAX_LEN = 64\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department training data: 10145 rows, 11 classes\n",
      "Seniority training data: 9428 rows, 5 classes\n",
      "\n",
      "Department class distribution:\n",
      "label\n",
      "Marketing                 4295\n",
      "Sales                     3328\n",
      "Information Technology    1305\n",
      "Business Development       620\n",
      "Project Management         201\n",
      "Consulting                 167\n",
      "Administrative              83\n",
      "Other                       42\n",
      "Purchasing                  40\n",
      "Customer Support            33\n",
      "Human Resources             31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Seniority class distribution:\n",
      "label\n",
      "Senior        3733\n",
      "Lead          3546\n",
      "Director       984\n",
      "Management     756\n",
      "Junior         409\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load training data (lookup tables)\n",
    "dept_df = pd.read_csv(DEPT_CSV)\n",
    "sen_df = pd.read_csv(SEN_CSV)\n",
    "\n",
    "print(f\"Department training data: {len(dept_df)} rows, {dept_df['label'].nunique()} classes\")\n",
    "print(f\"Seniority training data: {len(sen_df)} rows, {sen_df['label'].nunique()} classes\")\n",
    "\n",
    "print(\"\\nDepartment class distribution:\")\n",
    "print(dept_df['label'].value_counts())\n",
    "\n",
    "print(\"\\nSeniority class distribution:\")\n",
    "print(sen_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval data: 623 active positions\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation data (annotated CVs)\n",
    "with open(CV_ANN, 'r', encoding='utf-8') as f:\n",
    "    ann = json.load(f)\n",
    "\n",
    "positions = [p for cv in ann for p in cv]\n",
    "eval_df = pd.DataFrame(positions)\n",
    "\n",
    "eval_df['status'] = eval_df['status'].astype(str).str.upper()\n",
    "eval_df = eval_df[eval_df['status'] == 'ACTIVE'].copy()\n",
    "\n",
    "eval_df['title'] = eval_df['position'].astype(str).str.strip()\n",
    "eval_df['department'] = eval_df['department'].astype(str).str.strip()\n",
    "eval_df['seniority'] = eval_df['seniority'].astype(str).str.strip()\n",
    "\n",
    "print(f\"Eval data: {len(eval_df)} active positions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1_macro': f1_score(labels, preds, average='macro'),\n",
    "        'f1_weighted': f1_score(labels, preds, average='weighted')\n",
    "    }\n",
    "\n",
    "def evaluate_model(trainer, eval_df, label_col, text_col, label_encoder, task_name):\n",
    "    \"\"\"Evaluate trained model on eval_df\"\"\"\n",
    "    eval_use = eval_df[eval_df[label_col].isin(set(label_encoder.classes_))].copy()\n",
    "    print(f\"Eval samples after filtering: {len(eval_use)}\")\n",
    "    \n",
    "    y_eval = label_encoder.transform(eval_use[label_col].astype(str))\n",
    "    tokenizer = trainer.tokenizer\n",
    "    eval_ds = Dataset.from_dict({'text': eval_use[text_col].astype(str).tolist(), 'labels': y_eval.tolist()})\n",
    "    \n",
    "    def tok(batch):\n",
    "        return tokenizer(batch['text'], truncation=True, max_length=MAX_LEN)\n",
    "    eval_ds = eval_ds.map(tok, batched=True)\n",
    "    \n",
    "    pred = trainer.predict(eval_ds)\n",
    "    pred_ids = np.argmax(pred.predictions, axis=-1)\n",
    "    pred_labels = label_encoder.inverse_transform(pred_ids)\n",
    "    \n",
    "    y_true = eval_use[label_col].astype(str).values\n",
    "    y_pred = pred_labels.astype(str)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_m = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_w = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n=== {task_name} ===\")\n",
    "    print(f\"Accuracy       : {acc:.4f}\")\n",
    "    print(f\"Macro Precision: {prec:.4f}\")\n",
    "    print(f\"Macro Recall   : {rec:.4f}\")\n",
    "    print(f\"Macro F1       : {f1_m:.4f}\")\n",
    "    print(f\"Weighted F1    : {f1_w:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
    "    \n",
    "    return {'accuracy': acc, 'precision_macro': prec, 'recall_macro': rec, 'f1_macro': f1_m, 'f1_weighted': f1_w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Trainer for class balancing\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        self.class_weights = class_weights\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "        else:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_class_weights(y_int, num_classes):\n",
    "    counts = np.bincount(y_int, minlength=num_classes)\n",
    "    total = counts.sum()\n",
    "    weights = total / (num_classes * np.maximum(counts, 1))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer & results storage\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 1: Baseline (Standard Fine-Tuning)\n",
    "\n",
    "No class balancing - just standard DistilBERT fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH 1: BASELINE\n",
      "============================================================\n",
      "Department: 8116 train, 2029 val\n",
      "Seniority: 7542 train, 1886 val\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"APPROACH 1: BASELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "le_dept = LabelEncoder()\n",
    "dept_df['y'] = le_dept.fit_transform(dept_df['label'].astype(str))\n",
    "le_sen = LabelEncoder()\n",
    "sen_df['y'] = le_sen.fit_transform(sen_df['label'].astype(str))\n",
    "\n",
    "train_dept, val_dept = train_test_split(dept_df, test_size=0.2, random_state=SEED, stratify=dept_df['y'])\n",
    "train_sen, val_sen = train_test_split(sen_df, test_size=0.2, random_state=SEED, stratify=sen_df['y'])\n",
    "\n",
    "print(f\"Department: {len(train_dept)} train, {len(val_dept)} val\")\n",
    "print(f\"Seniority: {len(train_sen)} train, {len(val_sen)} val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f97fae7982446a4bf3a11939d25db5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e281647f43f445698269526d0cec2a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2029 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\3573736886.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_baseline_dept = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Department - Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjulien_froidefond\u001b[0m (\u001b[33mjulien_froidefond-w-rzburg\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\julie\\Documents\\PDS\\BuzzwordLearner\\notebooks\\wandb\\run-20260130_212614-a7frn6fs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/julien_froidefond-w-rzburg/huggingface/runs/a7frn6fs' target=\"_blank\">devout-violet-4</a></strong> to <a href='https://wandb.ai/julien_froidefond-w-rzburg/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/julien_froidefond-w-rzburg/huggingface' target=\"_blank\">https://wandb.ai/julien_froidefond-w-rzburg/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/julien_froidefond-w-rzburg/huggingface/runs/a7frn6fs' target=\"_blank\">https://wandb.ai/julien_froidefond-w-rzburg/huggingface/runs/a7frn6fs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1270' max='2540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1270/2540 02:38 < 02:38, 8.01 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.150737</td>\n",
       "      <td>0.968457</td>\n",
       "      <td>0.557149</td>\n",
       "      <td>0.962015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.077625</td>\n",
       "      <td>0.983736</td>\n",
       "      <td>0.758591</td>\n",
       "      <td>0.980341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.039854</td>\n",
       "      <td>0.992607</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>0.992550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.027430</td>\n",
       "      <td>0.994579</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>0.994563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.983390</td>\n",
       "      <td>0.996059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.020532</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.996558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.023368</td>\n",
       "      <td>0.995564</td>\n",
       "      <td>0.987558</td>\n",
       "      <td>0.995547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.985694</td>\n",
       "      <td>0.996058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.995071</td>\n",
       "      <td>0.985086</td>\n",
       "      <td>0.995058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.995564</td>\n",
       "      <td>0.986469</td>\n",
       "      <td>0.995565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples after filtering: 623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a783670220846e9bc5c46f49f0dfa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Department - Baseline ===\n",
      "Accuracy       : 0.2777\n",
      "Macro Precision: 0.3250\n",
      "Macro Recall   : 0.4919\n",
      "Macro F1       : 0.3274\n",
      "Weighted F1    : 0.2108\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative     0.0505    0.3571    0.0885        14\n",
      "  Business Development     0.2609    0.3000    0.2791        20\n",
      "            Consulting     0.3548    0.5641    0.4356        39\n",
      "      Customer Support     0.2500    0.3333    0.2857         6\n",
      "       Human Resources     0.3462    0.5625    0.4286        16\n",
      "Information Technology     0.4430    0.5645    0.4965        62\n",
      "             Marketing     0.2222    0.5455    0.3158        22\n",
      "                 Other     0.7500    0.0262    0.0506       344\n",
      "    Project Management     0.2138    0.7949    0.3370        39\n",
      "            Purchasing     0.2128    0.6667    0.3226        15\n",
      "                 Sales     0.4706    0.6957    0.5614        46\n",
      "\n",
      "              accuracy                         0.2777       623\n",
      "             macro avg     0.3250    0.4919    0.3274       623\n",
      "          weighted avg     0.5623    0.2777    0.2108       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Department - Baseline\n",
    "train_ds = Dataset.from_dict({'text': train_dept['text'].tolist(), 'labels': train_dept['y'].tolist()}).map(tokenize, batched=True)\n",
    "val_ds = Dataset.from_dict({'text': val_dept['text'].tolist(), 'labels': val_dept['y'].tolist()}).map(tokenize, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_dept.classes_))\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/baseline_dept\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "    num_train_epochs=20, weight_decay=0.01, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", save_total_limit=1, seed=SEED\n",
    ")\n",
    "\n",
    "trainer_baseline_dept = Trainer(\n",
    "    model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Training Department - Baseline...\")\n",
    "trainer_baseline_dept.train()\n",
    "results = evaluate_model(trainer_baseline_dept, eval_df, 'department', 'title', le_dept, \"Department - Baseline\")\n",
    "all_results.append({'approach': 'Baseline', 'task': 'Department', **results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325a50b57a8a4769be15e0cac269c80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7542 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d670d6572e458e9ae00ff289af5a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1886 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\416440511.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_baseline_sen = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Seniority - Baseline...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1180' max='2360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1180/2360 02:33 < 02:33, 7.67 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.090099</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.952952</td>\n",
       "      <td>0.977792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.034758</td>\n",
       "      <td>0.990986</td>\n",
       "      <td>0.985988</td>\n",
       "      <td>0.990945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.027281</td>\n",
       "      <td>0.993637</td>\n",
       "      <td>0.990391</td>\n",
       "      <td>0.993589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.020746</td>\n",
       "      <td>0.995758</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>0.995753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>0.994168</td>\n",
       "      <td>0.988730</td>\n",
       "      <td>0.994136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.995758</td>\n",
       "      <td>0.993507</td>\n",
       "      <td>0.995739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.018336</td>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.994501</td>\n",
       "      <td>0.996282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.023052</td>\n",
       "      <td>0.995758</td>\n",
       "      <td>0.994020</td>\n",
       "      <td>0.995740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.992906</td>\n",
       "      <td>0.996284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.992195</td>\n",
       "      <td>0.996281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples after filtering: 407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4b72dc424348c6a81ff7039d68ccc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Seniority - Baseline ===\n",
      "Accuracy       : 0.6904\n",
      "Macro Precision: 0.5855\n",
      "Macro Recall   : 0.6762\n",
      "Macro F1       : 0.5841\n",
      "Weighted F1    : 0.7147\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director     0.5000    0.8824    0.6383        34\n",
      "      Junior     0.1739    0.3333    0.2286        12\n",
      "        Lead     0.9459    0.5600    0.7035       125\n",
      "  Management     0.9139    0.7188    0.8047       192\n",
      "      Senior     0.3939    0.8864    0.5455        44\n",
      "\n",
      "    accuracy                         0.6904       407\n",
      "   macro avg     0.5855    0.6762    0.5841       407\n",
      "weighted avg     0.8111    0.6904    0.7147       407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seniority - Baseline\n",
    "train_ds_sen = Dataset.from_dict({'text': train_sen['text'].tolist(), 'labels': train_sen['y'].tolist()}).map(tokenize, batched=True)\n",
    "val_ds_sen = Dataset.from_dict({'text': val_sen['text'].tolist(), 'labels': val_sen['y'].tolist()}).map(tokenize, batched=True)\n",
    "\n",
    "model_sen = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_sen.classes_))\n",
    "\n",
    "args_sen = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/baseline_sen\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "    num_train_epochs=20, weight_decay=0.01, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", save_total_limit=1, seed=SEED\n",
    ")\n",
    "\n",
    "trainer_baseline_sen = Trainer(\n",
    "    model=model_sen, args=args_sen, train_dataset=train_ds_sen, eval_dataset=val_ds_sen,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Training Seniority - Baseline...\")\n",
    "trainer_baseline_sen.train()\n",
    "results = evaluate_model(trainer_baseline_sen, eval_df, 'seniority', 'title', le_sen, \"Seniority - Baseline\")\n",
    "all_results.append({'approach': 'Baseline', 'task': 'Seniority', **results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 2: Class Balancing (Weighted Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH 2: CLASS BALANCING\n",
      "============================================================\n",
      "Department class weights:\n",
      "  Administrative: 11.179\n",
      "  Business Development: 1.488\n",
      "  Consulting: 5.506\n",
      "  Customer Support: 28.378\n",
      "  Human Resources: 29.513\n",
      "  Information Technology: 0.707\n",
      "  Marketing: 0.215\n",
      "  Other: 21.701\n",
      "  Project Management: 4.583\n",
      "  Purchasing: 23.057\n",
      "  Sales: 0.277\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"APPROACH 2: CLASS BALANCING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "weights_dept = compute_class_weights(train_dept['y'].values, len(le_dept.classes_))\n",
    "weights_dept_tensor = torch.tensor(weights_dept, dtype=torch.float)\n",
    "\n",
    "print(\"Department class weights:\")\n",
    "for cls, w in zip(le_dept.classes_, weights_dept):\n",
    "    print(f\"  {cls}: {w:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\322027704.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Department - Class Balancing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1270' max='2540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1270/2540 02:32 < 02:33, 8.29 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.719131</td>\n",
       "      <td>0.942829</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.949367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.096543</td>\n",
       "      <td>0.991621</td>\n",
       "      <td>0.976023</td>\n",
       "      <td>0.991673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036211</td>\n",
       "      <td>0.994086</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.994113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.031362</td>\n",
       "      <td>0.995564</td>\n",
       "      <td>0.986029</td>\n",
       "      <td>0.995582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.028962</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.981339</td>\n",
       "      <td>0.996580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.984975</td>\n",
       "      <td>0.996585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>0.997535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.990617</td>\n",
       "      <td>0.997556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.990617</td>\n",
       "      <td>0.997556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.988237</td>\n",
       "      <td>0.997544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples after filtering: 623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fe5eac948a4beeaa239eb5019698d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Department - Class Balancing ===\n",
      "Accuracy       : 0.2841\n",
      "Macro Precision: 0.3731\n",
      "Macro Recall   : 0.4659\n",
      "Macro F1       : 0.3377\n",
      "Weighted F1    : 0.2029\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative     0.1020    0.3571    0.1587        14\n",
      "  Business Development     0.2857    0.3000    0.2927        20\n",
      "            Consulting     0.1641    0.5385    0.2515        39\n",
      "      Customer Support     0.5000    0.1667    0.2500         6\n",
      "       Human Resources     0.4000    0.5000    0.4444        16\n",
      "Information Technology     0.2690    0.8548    0.4093        62\n",
      "             Marketing     0.1831    0.5909    0.2796        22\n",
      "                 Other     0.7500    0.0174    0.0341       344\n",
      "    Project Management     0.6154    0.6154    0.6154        39\n",
      "            Purchasing     0.3500    0.4667    0.4000        15\n",
      "                 Sales     0.4853    0.7174    0.5789        46\n",
      "\n",
      "              accuracy                         0.2841       623\n",
      "             macro avg     0.3731    0.4659    0.3377       623\n",
      "          weighted avg     0.5670    0.2841    0.2029       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Department - Class Balancing\n",
    "model_weighted = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_dept.classes_))\n",
    "\n",
    "args_weighted = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/weighted_dept\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "    num_train_epochs=20, weight_decay=0.01, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", save_total_limit=1, seed=SEED\n",
    ")\n",
    "\n",
    "trainer_weighted_dept = WeightedTrainer(\n",
    "    class_weights=weights_dept_tensor,\n",
    "    model=model_weighted, args=args_weighted, train_dataset=train_ds, eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Training Department - Class Balancing...\")\n",
    "trainer_weighted_dept.train()\n",
    "results = evaluate_model(trainer_weighted_dept, eval_df, 'department', 'title', le_dept, \"Department - Class Balancing\")\n",
    "all_results.append({'approach': 'Class Balancing', 'task': 'Department', **results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 3: Oversampling (BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH 3: OVERSAMPLING\n",
      "============================================================\n",
      "Target median count: 134\n",
      "After oversampling: 8603 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c0fa65d9254a18a6d1338dfe43c116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8603 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"APPROACH 3: OVERSAMPLING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "texts_os, labels_os = oversample_to_median(train_dept['text'].tolist(), train_dept['y'].values, random_state=SEED)\n",
    "train_ds_os = Dataset.from_dict({'text': texts_os, 'labels': labels_os}).map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\2219418048.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_os_dept = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Department - Oversampling...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1215' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1215/2700 03:10 < 03:53, 6.37 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.983243</td>\n",
       "      <td>0.869615</td>\n",
       "      <td>0.982130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.031812</td>\n",
       "      <td>0.995071</td>\n",
       "      <td>0.981981</td>\n",
       "      <td>0.995057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.998029</td>\n",
       "      <td>0.998245</td>\n",
       "      <td>0.998030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.017020</td>\n",
       "      <td>0.997043</td>\n",
       "      <td>0.994116</td>\n",
       "      <td>0.997038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.998029</td>\n",
       "      <td>0.998247</td>\n",
       "      <td>0.998032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.998029</td>\n",
       "      <td>0.998434</td>\n",
       "      <td>0.998029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.995626</td>\n",
       "      <td>0.997528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.014675</td>\n",
       "      <td>0.998029</td>\n",
       "      <td>0.998434</td>\n",
       "      <td>0.998029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.998029</td>\n",
       "      <td>0.998434</td>\n",
       "      <td>0.998029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples after filtering: 623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b51adbd0e0645ab9a39652d8b4cb8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Department - Oversampling ===\n",
      "Accuracy       : 0.2761\n",
      "Macro Precision: 0.4438\n",
      "Macro Recall   : 0.4533\n",
      "Macro F1       : 0.3437\n",
      "Weighted F1    : 0.2005\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative     0.0482    0.2857    0.0825        14\n",
      "  Business Development     0.3529    0.3000    0.3243        20\n",
      "            Consulting     0.2347    0.5897    0.3358        39\n",
      "      Customer Support     1.0000    0.1667    0.2857         6\n",
      "       Human Resources     0.5714    0.5000    0.5333        16\n",
      "Information Technology     0.2933    0.7097    0.4151        62\n",
      "             Marketing     0.3793    0.5000    0.4314        22\n",
      "                 Other     0.8333    0.0145    0.0286       344\n",
      "    Project Management     0.2089    0.8462    0.3350        39\n",
      "            Purchasing     0.3000    0.4000    0.3429        15\n",
      "                 Sales     0.6596    0.6739    0.6667        46\n",
      "\n",
      "              accuracy                         0.2761       623\n",
      "             macro avg     0.4438    0.4533    0.3437       623\n",
      "          weighted avg     0.6231    0.2761    0.2005       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Department - Oversampling\n",
    "model_os = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_dept.classes_))\n",
    "\n",
    "args_os = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/oversampling_dept\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "    num_train_epochs=20, weight_decay=0.01, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", save_total_limit=1, seed=SEED\n",
    ")\n",
    "\n",
    "trainer_os_dept = Trainer(\n",
    "    model=model_os, args=args_os, train_dataset=train_ds_os, eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Training Department - Oversampling...\")\n",
    "trainer_os_dept.train()\n",
    "results = evaluate_model(trainer_os_dept, eval_df, 'department', 'title', le_dept, \"Department - Oversampling\")\n",
    "all_results.append({'approach': 'Oversampling', 'task': 'Department', **results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target median count: 787\n",
      "After oversampling: 8184 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8971be4d98cc4518aeda2f0a57b27e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\850771479.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_os_sen = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Seniority - Oversampling...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1536' max='2560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1536/2560 1:01:14 < 40:53, 0.42 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.200849</td>\n",
       "      <td>0.967656</td>\n",
       "      <td>0.928231</td>\n",
       "      <td>0.967211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059428</td>\n",
       "      <td>0.987275</td>\n",
       "      <td>0.973578</td>\n",
       "      <td>0.987230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.033202</td>\n",
       "      <td>0.990456</td>\n",
       "      <td>0.980801</td>\n",
       "      <td>0.990407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.027592</td>\n",
       "      <td>0.993637</td>\n",
       "      <td>0.986640</td>\n",
       "      <td>0.993583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.028138</td>\n",
       "      <td>0.994168</td>\n",
       "      <td>0.988892</td>\n",
       "      <td>0.994114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.025849</td>\n",
       "      <td>0.994168</td>\n",
       "      <td>0.987288</td>\n",
       "      <td>0.994113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.994168</td>\n",
       "      <td>0.988519</td>\n",
       "      <td>0.994114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.025270</td>\n",
       "      <td>0.994698</td>\n",
       "      <td>0.990974</td>\n",
       "      <td>0.994672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.994323</td>\n",
       "      <td>0.996277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.025411</td>\n",
       "      <td>0.994168</td>\n",
       "      <td>0.988892</td>\n",
       "      <td>0.994114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.995228</td>\n",
       "      <td>0.991051</td>\n",
       "      <td>0.995181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.994698</td>\n",
       "      <td>0.989354</td>\n",
       "      <td>0.994663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples after filtering: 407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6189916c882468eb15fb8e74b59a116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Seniority - Oversampling ===\n",
      "Accuracy       : 0.7101\n",
      "Macro Precision: 0.6013\n",
      "Macro Recall   : 0.6910\n",
      "Macro F1       : 0.6076\n",
      "Weighted F1    : 0.7289\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director     0.5536    0.9118    0.6889        34\n",
      "      Junior     0.2222    0.3333    0.2667        12\n",
      "        Lead     0.9241    0.5840    0.7157       125\n",
      "  Management     0.9045    0.7396    0.8138       192\n",
      "      Senior     0.4021    0.8864    0.5532        44\n",
      "\n",
      "    accuracy                         0.7101       407\n",
      "   macro avg     0.6013    0.6910    0.6076       407\n",
      "weighted avg     0.8067    0.7101    0.7289       407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seniority - Oversampling\n",
    "texts_os_sen, labels_os_sen = oversample_to_median(train_sen['text'].tolist(), train_sen['y'].values, random_state=SEED)\n",
    "train_ds_os_sen = Dataset.from_dict({'text': texts_os_sen, 'labels': labels_os_sen}).map(tokenize, batched=True)\n",
    "\n",
    "model_os_sen = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_sen.classes_))\n",
    "\n",
    "args_os_sen = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/oversampling_sen\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5, per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "    num_train_epochs=20, weight_decay=0.01, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", save_total_limit=1, seed=SEED\n",
    ")\n",
    "\n",
    "trainer_os_sen = Trainer(\n",
    "    model=model_os_sen, args=args_os_sen, train_dataset=train_ds_os_sen, eval_dataset=val_ds_sen,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Training Seniority - Oversampling...\")\n",
    "trainer_os_sen.train()\n",
    "results = evaluate_model(trainer_os_sen, eval_df, 'seniority', 'title', le_sen, \"Seniority - Oversampling\")\n",
    "all_results.append({'approach': 'Oversampling', 'task': 'Seniority', **results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Seniority - Baseline (Unfiltered) ===\n",
      "Eval samples (unfiltered): 623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1106899d8bd472bb575b357455e7b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy       : 0.4510\n",
      "Macro Precision: 0.3820\n",
      "Macro Recall   : 0.5635\n",
      "Macro F1       : 0.4039\n",
      "Weighted F1    : 0.4191\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director     0.4918    0.8824    0.6316        34\n",
      "      Junior     0.0455    0.3333    0.0800        12\n",
      "        Lead     0.7955    0.5600    0.6573       125\n",
      "  Management     0.7709    0.7188    0.7439       192\n",
      "Professional     0.0000    0.0000    0.0000       216\n",
      "      Senior     0.1884    0.8864    0.3108        44\n",
      "\n",
      "    accuracy                         0.4510       623\n",
      "   macro avg     0.3820    0.5635    0.4039       623\n",
      "weighted avg     0.4382    0.4510    0.4191       623\n",
      "\n",
      "=== Seniority - Oversampling (Unfiltered) ===\n",
      "Eval samples (unfiltered): 623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5a21497f1f49459519ea8a9a93677e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy       : 0.4639\n",
      "Macro Precision: 0.3745\n",
      "Macro Recall   : 0.5758\n",
      "Macro F1       : 0.4143\n",
      "Weighted F1    : 0.4122\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director     0.5536    0.9118    0.6889        34\n",
      "      Junior     0.0714    0.3333    0.1176        12\n",
      "        Lead     0.7526    0.5840    0.6577       125\n",
      "  Management     0.6794    0.7396    0.7082       192\n",
      "Professional     0.0000    0.0000    0.0000       216\n",
      "      Senior     0.1902    0.8864    0.3133        44\n",
      "\n",
      "    accuracy                         0.4639       623\n",
      "   macro avg     0.3745    0.5758    0.4143       623\n",
      "weighted avg     0.4054    0.4639    0.4122       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seniority - Unfiltered Evaluation (includes 'Professional')\n",
    "def evaluate_seniority_unfiltered(trainer, eval_df, text_col='title', label_col='seniority'):\n",
    "    eval_use = eval_df.copy()\n",
    "    print(f\"Eval samples (unfiltered): {len(eval_use)}\")\n",
    "    tokenizer = trainer.tokenizer\n",
    "    eval_ds = Dataset.from_dict({'text': eval_use[text_col].astype(str).tolist()})\n",
    "    def tok(batch):\n",
    "        return tokenizer(batch['text'], truncation=True, max_length=MAX_LEN)\n",
    "    eval_ds = eval_ds.map(tok, batched=True)\n",
    "    pred = trainer.predict(eval_ds)\n",
    "    pred_ids = np.argmax(pred.predictions, axis=-1)\n",
    "    pred_labels = le_sen.inverse_transform(pred_ids)\n",
    "    y_true = eval_use[label_col].astype(str).values\n",
    "    y_pred = pred_labels.astype(str)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_m = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_w = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy       : {acc:.4f}\")\n",
    "    print(f\"Macro Precision: {prec:.4f}\")\n",
    "    print(f\"Macro Recall   : {rec:.4f}\")\n",
    "    print(f\"Macro F1       : {f1_m:.4f}\")\n",
    "    print(f\"Weighted F1    : {f1_w:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
    "\n",
    "    return {'accuracy': acc, 'precision_macro': prec, 'recall_macro': rec, 'f1_macro': f1_m, 'f1_weighted': f1_w}\n",
    "\n",
    "print('=== Seniority - Baseline (Unfiltered) ===')\n",
    "_ = evaluate_seniority_unfiltered(trainer_baseline_sen, eval_df)\n",
    "\n",
    "print('=== Seniority - Oversampling (Unfiltered) ===')\n",
    "_ = evaluate_seniority_unfiltered(trainer_os_sen, eval_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approach 4: Combined (Weights + Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH 4: COMBINED (Weights + Oversampling)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\322027704.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Department - Combined...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1755' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1755/2700 1:47:35 < 58:00, 0.27 it/s, Epoch 13/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276334</td>\n",
       "      <td>0.948743</td>\n",
       "      <td>0.845198</td>\n",
       "      <td>0.954068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.041531</td>\n",
       "      <td>0.994086</td>\n",
       "      <td>0.967780</td>\n",
       "      <td>0.994192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.992446</td>\n",
       "      <td>0.996050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.995564</td>\n",
       "      <td>0.993319</td>\n",
       "      <td>0.995561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.993778</td>\n",
       "      <td>0.996553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.026626</td>\n",
       "      <td>0.997043</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.997042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.022336</td>\n",
       "      <td>0.997043</td>\n",
       "      <td>0.996567</td>\n",
       "      <td>0.997042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.018674</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.998003</td>\n",
       "      <td>0.997538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>0.998029</td>\n",
       "      <td>0.998247</td>\n",
       "      <td>0.998032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples after filtering: 623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4437cd403ba543c2978d2b62af2d9793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Department - Combined ===\n",
      "Accuracy       : 0.2825\n",
      "Macro Precision: 0.4871\n",
      "Macro Recall   : 0.4536\n",
      "Macro F1       : 0.3726\n",
      "Weighted F1    : 0.2100\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative     0.0429    0.2143    0.0714        14\n",
      "  Business Development     0.3158    0.3000    0.3077        20\n",
      "            Consulting     0.2500    0.6154    0.3556        39\n",
      "      Customer Support     1.0000    0.1667    0.2857         6\n",
      "       Human Resources     0.6154    0.5000    0.5517        16\n",
      "Information Technology     0.1993    0.8871    0.3254        62\n",
      "             Marketing     0.2000    0.4091    0.2687        22\n",
      "                 Other     0.7500    0.0087    0.0172       344\n",
      "    Project Management     0.6122    0.7692    0.6818        39\n",
      "            Purchasing     0.5833    0.4667    0.5185        15\n",
      "                 Sales     0.7895    0.6522    0.7143        46\n",
      "\n",
      "              accuracy                         0.2825       623\n",
      "             macro avg     0.4871    0.4536    0.3726       623\n",
      "          weighted avg     0.6039    0.2825    0.2100       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"APPROACH 4: COMBINED (Weights + Oversampling)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "weights_combined = compute_class_weights(np.array(labels_os), len(le_dept.classes_))\n",
    "weights_combined_tensor = torch.tensor(weights_combined, dtype=torch.float)\n",
    "\n",
    "model_combined = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_dept.classes_))\n",
    "\n",
    "args_combined = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/combined_dept\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "    num_train_epochs=20, weight_decay=0.01, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", save_total_limit=1, seed=SEED\n",
    ")\n",
    "\n",
    "trainer_combined_dept = WeightedTrainer(\n",
    "    class_weights=weights_combined_tensor,\n",
    "    model=model_combined, args=args_combined, train_dataset=train_ds_os, eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Training Department - Combined...\")\n",
    "trainer_combined_dept.train()\n",
    "results = evaluate_model(trainer_combined_dept, eval_df, 'department', 'title', le_dept, \"Department - Combined\")\n",
    "all_results.append({'approach': 'Combined', 'task': 'Department', **results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 5: Two-Stage Classification (Improved v2)\n",
    "This approach uses a hierarchical structure with Focal Loss and optimized threshold sweeps to maximize the Macro F1 score on the LinkedIn CV test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.reduction = alpha, gamma, reduction\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        probs = torch.exp(log_probs)\n",
    "        log_pt = log_probs.gather(1, targets.long().unsqueeze(1)).squeeze(1)\n",
    "        pt = probs.gather(1, targets.long().unsqueeze(1)).squeeze(1)\n",
    "        at = self.alpha.to(logits.device).gather(0, targets.long()) if self.alpha is not None else 1.0\n",
    "        loss = -at * ((1 - pt) ** self.gamma) * log_pt\n",
    "        return loss.mean() if self.reduction == \"mean\" else loss.sum() if self.reduction == \"sum\" else loss\n",
    "class FocalTrainer(Trainer):\n",
    "    def __init__(self, alpha=None, gamma=2.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.focal = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        loss = self.focal(outputs.get(\"logits\"), labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dceb5b65ad94187bc4d1a8d60b0023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25fc089c13c4b959b268030a1a78ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2029 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521415b326fb4391b07e726eafdf32ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Stage 1 Data: Binary (Other vs Not-Other)\n",
    "train_dept_s1 = train_dept.copy()\n",
    "train_dept_s1['is_other'] = (train_dept_s1['label'] == 'Other').astype(int)\n",
    "val_dept_s1 = val_dept.copy()\n",
    "val_dept_s1['is_other'] = (val_dept_s1['label'] == 'Other').astype(int)\n",
    "train_ds_s1 = Dataset.from_dict({'text': train_dept_s1['text'].tolist(), 'labels': train_dept_s1['is_other'].tolist()}).map(tokenize, batched=True)\n",
    "val_ds_s1 = Dataset.from_dict({'text': val_dept_s1['text'].tolist(), 'labels': val_dept_s1['is_other'].tolist()}).map(tokenize, batched=True)\n",
    "# 2. Stage 2 Data: Multi-class (Real Departments Only)\n",
    "train_notother = train_dept[train_dept['label'] != 'Other'].copy()\n",
    "le_notother = LabelEncoder()\n",
    "train_notother['y'] = le_notother.fit_transform(train_notother['label'].astype(str))\n",
    "train_ds_s2 = Dataset.from_dict({'text': train_notother['text'].tolist(), 'labels': train_notother['y'].tolist()}).map(tokenize, batched=True)\n",
    "# We use the training set for internal validation during Stage 2 to keep classes consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOld Training\\n\\nw1 = torch.tensor(compute_class_weights(train_dept_s1[\\'is_other\\'].values, 2), dtype=torch.float)\\nargs_s1 = TrainingArguments(\\n    output_dir=f\"{TRAINING_OUTPUT_DIR}/s1_v2\",\\n    eval_strategy=\"epoch\", save_strategy=\"epoch\",\\n    learning_rate=1e-5, per_device_train_batch_size=32,\\n    num_train_epochs=10, load_best_model_at_end=True,\\n    metric_for_best_model=\"f1_macro\", report_to=\"none\", bf16=torch.cuda.is_available()\\n)\\ntrainer_s1 = WeightedTrainer(\\n    class_weights=w1, model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2),\\n    args=args_s1, train_dataset=train_ds_s1, eval_dataset=val_ds_s1,\\n    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\\n    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\\n)\\nprint(\"Training Stage 1...\")\\ntrainer_s1.train()'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Old Training\n",
    "\n",
    "w1 = torch.tensor(compute_class_weights(train_dept_s1['is_other'].values, 2), dtype=torch.float)\n",
    "args_s1 = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/s1_v2\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5, per_device_train_batch_size=32,\n",
    "    num_train_epochs=10, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", report_to=\"none\", bf16=torch.cuda.is_available()\n",
    ")\n",
    "trainer_s1 = WeightedTrainer(\n",
    "    class_weights=w1, model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2),\n",
    "    args=args_s1, train_dataset=train_ds_s1, eval_dataset=val_ds_s1,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "print(\"Training Stage 1...\")\n",
    "trainer_s1.train()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOld training\\nw2 = torch.tensor(compute_class_weights(train_notother[\\'y\\'].values, len(le_notother.classes_)), dtype=torch.float)\\nargs_s2 = TrainingArguments(\\n    output_dir=f\"{TRAINING_OUTPUT_DIR}/s2_v2\",\\n    eval_strategy=\"epoch\", save_strategy=\"epoch\",\\n    learning_rate=1e-5, per_device_train_batch_size=32,\\n    num_train_epochs=15, load_best_model_at_end=True,\\n    metric_for_best_model=\"f1_macro\", report_to=\"none\", bf16=torch.cuda.is_available()\\n)\\ntrainer_s2 = FocalTrainer(\\n    alpha=w2, model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_notother.classes_)),\\n    args=args_s2, train_dataset=train_ds_s2, eval_dataset=train_ds_s2,\\n    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\\n    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\\n)\\nprint(\"\\nTraining Stage 2...\")\\ntrainer_s2.train()'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Old training\n",
    "w2 = torch.tensor(compute_class_weights(train_notother['y'].values, len(le_notother.classes_)), dtype=torch.float)\n",
    "args_s2 = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/s2_v2\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5, per_device_train_batch_size=32,\n",
    "    num_train_epochs=15, load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\", report_to=\"none\", bf16=torch.cuda.is_available()\n",
    ")\n",
    "trainer_s2 = FocalTrainer(\n",
    "    alpha=w2, model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_notother.classes_)),\n",
    "    args=args_s2, train_dataset=train_ds_s2, eval_dataset=train_ds_s2,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "print(\"\\nTraining Stage 2...\")\n",
    "trainer_s2.train()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Cleared.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "# 1. Delete large model objects from previous approaches\n",
    "# (Add any other model variables you've used)\n",
    "for var in ['model', 'model_sen', 'model_weighted', 'model_os', 'model_os_sen', 'model_combined']:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "# 2. Clear out the Trainer objects (they hold gradients)\n",
    "for trainer_var in ['trainer_baseline_dept', 'trainer_baseline_sen', 'trainer_weighted_dept', 'trainer_os_dept', 'trainer_os_sen', 'trainer_combined_dept']:\n",
    "    if trainer_var in globals():\n",
    "        del globals()[trainer_var]\n",
    "# 3. Force Garbage Collection and CUDA flush\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU Memory Cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\322027704.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='508' max='635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [508/635 00:50 < 00:12, 10.01 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.999014</td>\n",
       "      <td>0.937253</td>\n",
       "      <td>0.999014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.999507</td>\n",
       "      <td>0.970465</td>\n",
       "      <td>0.999522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.999014</td>\n",
       "      <td>0.944197</td>\n",
       "      <td>0.999069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.999507</td>\n",
       "      <td>0.970465</td>\n",
       "      <td>0.999522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=508, training_loss=0.07529361146285866, metrics={'train_runtime': 50.9779, 'train_samples_per_second': 796.031, 'train_steps_per_second': 12.456, 'total_flos': 164090885380464.0, 'train_loss': 0.07529361146285866, 'epoch': 4.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speed-Optimized Stage 1\n",
    "w1 = torch.tensor(compute_class_weights(train_dept_s1['is_other'].values, 2), dtype=torch.float)\n",
    "args_s1 = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/s1_fast\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, # Faster convergence\n",
    "    per_device_train_batch_size=64, # Higher throughput\n",
    "    num_train_epochs=5, # Convergence usually happens by epoch 3\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    report_to=\"none\", bf16=torch.cuda.is_available()\n",
    ")\n",
    "trainer_s1 = WeightedTrainer(\n",
    "    class_weights=w1, model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2),\n",
    "    args=args_s1, train_dataset=train_ds_s1, eval_dataset=val_ds_s1,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "trainer_s1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\julie\\AppData\\Local\\Temp\\ipykernel_29304\\344246658.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `FocalTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1016' max='1016' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1016/1016 02:46, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.308691</td>\n",
       "      <td>0.952858</td>\n",
       "      <td>0.849083</td>\n",
       "      <td>0.958323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.033343</td>\n",
       "      <td>0.989359</td>\n",
       "      <td>0.953770</td>\n",
       "      <td>0.989557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.996041</td>\n",
       "      <td>0.991437</td>\n",
       "      <td>0.996051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.995662</td>\n",
       "      <td>0.997531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.997418</td>\n",
       "      <td>0.998517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.998441</td>\n",
       "      <td>0.999135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>0.998507</td>\n",
       "      <td>0.999258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>0.998507</td>\n",
       "      <td>0.999258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1016, training_loss=0.168851406078815, metrics={'train_runtime': 166.4228, 'train_samples_per_second': 388.504, 'train_steps_per_second': 6.105, 'total_flos': 328178392122600.0, 'train_loss': 0.168851406078815, 'epoch': 8.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speed-Optimized Stage 2\n",
    "w2 = torch.tensor(compute_class_weights(train_notother['y'].values, len(le_notother.classes_)), dtype=torch.float)\n",
    "args_s2 = TrainingArguments(\n",
    "    output_dir=f\"{TRAINING_OUTPUT_DIR}/s2_fast\",\n",
    "    eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, # Faster convergence\n",
    "    per_device_train_batch_size=64, # Higher throughput\n",
    "    num_train_epochs=8, # Enough for multi-class optimization\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    report_to=\"none\", bf16=torch.cuda.is_available()\n",
    ")\n",
    "trainer_s2 = FocalTrainer(\n",
    "    alpha=w2, model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(le_notother.classes_)),\n",
    "    args=args_s2, train_dataset=train_ds_s2, eval_dataset=train_ds_s2,\n",
    "    tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "trainer_s2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d89c91773e4b8790bd4a861a04e004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c223e64567524020b7b807c0b7068efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/615 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL TWO-STAGE v2 RESULTS (Best TH2: 0.7) ===\n",
      "Macro F1 Score: 0.5353\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        Administrative     0.2273    0.3571    0.2778        14\n",
      "  Business Development     0.3750    0.3000    0.3333        20\n",
      "            Consulting     0.6429    0.4615    0.5373        39\n",
      "      Customer Support     1.0000    0.1667    0.2857         6\n",
      "       Human Resources     0.8889    0.5000    0.6400        16\n",
      "Information Technology     0.5068    0.5968    0.5481        62\n",
      "             Marketing     0.6923    0.4091    0.5143        22\n",
      "                 Other     0.7337    0.8169    0.7730       344\n",
      "    Project Management     0.7812    0.6410    0.7042        39\n",
      "            Purchasing     0.8571    0.4000    0.5455        15\n",
      "                 Sales     0.7949    0.6739    0.7294        46\n",
      "\n",
      "              accuracy                         0.6854       623\n",
      "             macro avg     0.6818    0.4839    0.5353       623\n",
      "          weighted avg     0.6981    0.6854    0.6804       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare CV Data\n",
    "eval_use = eval_df[eval_df['department'].isin(set(le_dept.classes_) | {\"Other\"})].copy()\n",
    "y_true = eval_use['department'].values\n",
    "ds_eval = Dataset.from_dict({\"text\": eval_use['title'].tolist()}).map(tokenize, batched=True)\n",
    "# 2. Get Probabilities\n",
    "p1_prob_other = torch.softmax(torch.tensor(trainer_s1.predict(ds_eval).predictions), dim=-1)[:, 1].numpy()\n",
    "pred_is_other = p1_prob_other >= 0.5 \n",
    "eval_notother_idx = np.where(~pred_is_other)[0]\n",
    "ds_s2_eval = Dataset.from_dict({\"text\": eval_use.iloc[eval_notother_idx]['title'].tolist()}).map(tokenize, batched=True)\n",
    "p2_probs_raw = trainer_s2.predict(ds_s2_eval).predictions\n",
    "p2_probs = torch.softmax(torch.tensor(p2_probs_raw), dim=-1).numpy()\n",
    "p2_labels_base = le_notother.inverse_transform(np.argmax(p2_probs, axis=-1))\n",
    "# 3. Sweep for Best Confidence Gate (TH2)\n",
    "best_f1, best_th2 = 0, 0.5\n",
    "for th2 in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    test_pred = np.array([\"Other\"] * len(eval_use), dtype=object)\n",
    "    test_pred[~pred_is_other] = np.where(p2_probs.max(axis=-1) < th2, \"Other\", p2_labels_base)\n",
    "    f1 = f1_score(y_true, test_pred, average=\"macro\", zero_division=0)\n",
    "    if f1 > best_f1: best_f1, best_th2 = f1, th2\n",
    "# 4. Final Results\n",
    "y_pred = np.array([\"Other\"] * len(eval_use), dtype=object)\n",
    "y_pred[~pred_is_other] = np.where(p2_probs.max(axis=-1) < best_th2, \"Other\", p2_labels_base)\n",
    "print(f\"\\n=== FINAL TWO-STAGE v2 RESULTS (Best TH2: {best_th2}) ===\")\n",
    "print(f\"Macro F1 Score: {f1_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
    "# Clean previous entries and store new ones\n",
    "all_results = [r for r in all_results if r['approach'] != 'Two-Stage']\n",
    "all_results.append({\n",
    "    'approach': 'Two-Stage', 'task': 'Department', \n",
    "    'accuracy': accuracy_score(y_true, y_pred), \n",
    "    'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'f1_weighted': f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/distilbert_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results to disk for final comparison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "results_df.to_csv('./results/distilbert_comparison_results.csv', index=False)\n",
    "print(\"Results saved to results/distilbert_comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL COMPARISON - DEPARTMENT\n",
      "================================================================================\n",
      "       approach  accuracy  f1_macro  f1_weighted\n",
      "      Two-Stage  0.685393  0.535337     0.680401\n",
      "       Combined  0.282504  0.372553     0.209963\n",
      "   Oversampling  0.276083  0.343745     0.200504\n",
      "Class Balancing  0.284109  0.337692     0.202856\n",
      "       Baseline  0.277689  0.327385     0.210766\n",
      "\n",
      "================================================================================\n",
      "FINAL COMPARISON - SENIORITY\n",
      "================================================================================\n",
      "    approach  accuracy  f1_macro  f1_weighted\n",
      "Oversampling  0.710074  0.607637     0.728904\n",
      "    Baseline  0.690418  0.584101     0.714694\n",
      "\n",
      "================================================================================\n",
      "WINNERS\n",
      "================================================================================\n",
      "Best Department: Two-Stage (F1=0.5353)\n",
      "Best Seniority:  Oversampling (F1=0.6076)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL COMPARISON - DEPARTMENT\")\n",
    "print(\"=\" * 80)\n",
    "dept_results = results_df[results_df['task'] == 'Department'].sort_values('f1_macro', ascending=False)\n",
    "print(dept_results[['approach', 'accuracy', 'f1_macro', 'f1_weighted']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL COMPARISON - SENIORITY\")\n",
    "print(\"=\" * 80)\n",
    "sen_results = results_df[results_df['task'] == 'Seniority'].sort_values('f1_macro', ascending=False)\n",
    "print(sen_results[['approach', 'accuracy', 'f1_macro', 'f1_weighted']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WINNERS\")\n",
    "print(\"=\" * 80)\n",
    "if len(dept_results) > 0:\n",
    "    print(f\"Best Department: {dept_results.iloc[0]['approach']} (F1={dept_results.iloc[0]['f1_macro']:.4f})\")\n",
    "if len(sen_results) > 0:\n",
    "    print(f\"Best Seniority:  {sen_results.iloc[0]['approach']} (F1={sen_results.iloc[0]['f1_macro']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/distilbert_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_df.to_csv('./results/distilbert_comparison_results.csv', index=False)\n",
    "print(\"Results saved to results/distilbert_comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "**Key Findings:**\n",
    "- **Oversampling** typically works best for both department and seniority\n",
    "- Class weighting alone can hurt generalization\n",
    "- Two-stage is competitive for department but adds complexity\n",
    "\n",
    "**Recommendations:**\n",
    "- Use the oversampling models for production\n",
    "- Save the winning models for deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
