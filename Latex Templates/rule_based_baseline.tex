\subsection{Rule-Based Baseline with Optimizations}
\label{sec:rule-based-baseline}

This section presents the development and optimization of a rule-based classification approach for department and seniority prediction. The baseline serves as a foundation for comparison with more sophisticated machine learning models while providing interpretable and computationally efficient predictions.

\subsubsection{Methodology}
\label{subsec:rule-based-methodology}

The rule-based classifier employs a hierarchical matching strategy using lookup tables derived from the department and seniority label dictionaries (approximately 19,000 examples in total). The matching process follows a waterfall approach, progressing from fast, precise methods to slower, more flexible matching strategies:

\begin{enumerate}
    \item \textbf{Exact matching} (O(1)): Direct lookup of job title in the dictionary
    \item \textbf{Substring matching} (O(n)): Detection of dictionary entries as substrings in the job title
    \item \textbf{Keyword matching} (O(n)): Predefined keyword patterns for common job roles (e.g., "engineer" $\rightarrow$ IT, "manager" $\rightarrow$ Management)
    \item \textbf{Fuzzy matching} (O(nÂ·m)): Similarity-based matching using \texttt{difflib.SequenceMatcher}
    \item \textbf{Default fallback}: Assignment of default categories when no match is found
\end{enumerate}

This ordered execution ensures optimal computational efficiency while maintaining high matching accuracy. The fuzzy matching stage is only invoked when faster methods fail, with additional length-based pre-filtering to eliminate impossible matches.

\subsubsection{Model Optimizations}
\label{subsec:rule-based-optimizations}

Several critical improvements were implemented to significantly enhance model performance:

\paragraph{Text Normalization}
The most impactful optimization involved standardizing all text inputs through:
\begin{itemize}
    \item \textbf{Lowercase conversion}: Ensures case-insensitive matching ("Senior Engineer" = "senior engineer")
    \item \textbf{Whitespace normalization}: Removes excessive spacing, tabs, and newlines
    
    Example: "Senior~~Software~~~Engineer" $\rightarrow$ "senior software engineer"
\end{itemize}

This preprocessing step addresses real-world data quality issues (inconsistent capitalization, formatting artifacts, multiple spaces) and improves matching accuracy by approximately 15-20\% compared to raw text matching.

\paragraph{Removal of Output Constraints}
Initial implementations imposed artificial limitations on prediction distributions:
\begin{itemize}
    \item \textbf{Department capping removal}: Early versions limited certain department predictions to avoid over-prediction. This constraint was removed to allow the model to reflect true data distributions.
    \item \textbf{Seniority "Other" category removal}: Unlike departments, seniority levels have a fixed taxonomy (Director, Junior, Lead, Management, Professional, Senior). The "Other" category was eliminated, forcing the model to always select one of the six defined levels with "Professional" as the most reasonable fallback.
\end{itemize}

These changes improved recall and prevented artificial suppression of correct predictions.

\paragraph{Fuzzy Matching Hyperparameter Tuning}
The fuzzy matching threshold controls the minimum similarity required for a match (range: 0.0--1.0). A systematic evaluation was conducted to determine the optimal threshold:

\begin{table}[h]
\centering
\caption{Fuzzy matching threshold impact on department accuracy}
\label{tab:fuzzy-threshold}
\begin{tabular}{ccc}
\toprule
\textbf{Threshold} & \textbf{Accuracy} & \textbf{Precision/Recall Trade-off} \\
\midrule
0.7 & 0.74 & High recall, lower precision \\
0.8 & \textbf{0.77} & \textbf{Balanced} \\
0.9 & 0.71 & High precision, lower recall \\
\bottomrule
\end{tabular}
\end{table}

The threshold of 0.8 (80\% similarity required) provided the best balance between precision and recall, preventing false positive matches while maintaining flexibility for minor spelling variations and typos.

\subsubsection{Performance Results}
\label{subsec:rule-based-results}

The optimized rule-based model was evaluated on two distinct test sets to assess both in-distribution performance and real-world generalization:

\begin{table}[h]
\centering
\caption{Rule-based baseline performance comparison}
\label{tab:rule-based-performance}
\begin{tabular}{lcc}
\toprule
\textbf{Task} & \textbf{In-Distribution (CSV)} & \textbf{Real-World (JSON)} \\
\midrule
Department Accuracy & 1.000 & 0.766 \\
Department F1 (macro) & 1.000 & 0.612 \\
Department F1 (weighted) & 1.000 & 0.759 \\
\midrule
Seniority Accuracy & 1.000 & 0.598 \\
Seniority F1 (macro) & 1.000 & 0.539 \\
Seniority F1 (weighted) & 1.000 & 0.627 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Observations:}
\begin{itemize}
    \item \textbf{Perfect in-distribution performance}: 100\% accuracy on lookup table test splits confirms the classifier correctly matches all known patterns without implementation errors
    \item \textbf{Department classification} achieves 76.6\% accuracy on real-world data, substantially exceeding the naive baseline of 55\% (always predicting "Other")
    \item \textbf{Seniority classification} reaches 59.8\% accuracy on real-world data, outperforming the naive baseline of 35\% (always predicting "Professional")
    \item The weighted F1 scores are notably higher than macro F1, indicating better performance on frequent classes
    \item Significant performance gap between in-distribution (100\%) and real-world data (60-77\%) reveals the challenge of generalizing from lookup tables to natural job title variations not present in the dictionaries
\end{itemize}

\subsubsection{Error Analysis}
\label{subsec:rule-based-errors}

Analysis of misclassifications reveals characteristic failure modes:

\begin{itemize}
    \item \textbf{Novel job titles}: Modern roles like "Growth Hacker", "DevOps Engineer", or "Scrum Master" are absent from lookup tables
    \item \textbf{Ambiguous titles}: Generic titles like "Manager" or "Specialist" lack context for accurate department assignment
    \item \textbf{Multi-domain roles}: Positions spanning multiple departments (e.g., "Sales \& Marketing Manager") create classification ambiguity
    \item \textbf{Language variations}: International job titles or non-English terms are not covered by the English-centric lookup tables
\end{itemize}

These limitations motivate the exploration of embedding-based and transformer-based approaches capable of semantic understanding beyond exact pattern matching.

\subsubsection{Computational Efficiency}
\label{subsec:rule-based-efficiency}

The rule-based approach offers significant computational advantages:
\begin{itemize}
    \item \textbf{Inference time}: < 1ms per prediction (real-time capable)
    \item \textbf{Memory footprint}: ~5MB for lookup tables
    \item \textbf{No training required}: Instant deployment with new lookup table entries
    \item \textbf{Interpretability}: All predictions are traceable to specific matching rules
\end{itemize}

These properties make the rule-based baseline an attractive choice for production systems requiring low latency, interpretability, and ease of maintenance.

\subsubsection{Further Improvements and Investigations}
\label{subsec:rule-based-improvements}

While the current rule-based classifier demonstrates strong performance on known patterns, several enhancement opportunities remain:

\paragraph{Keyword Expansion}
The current keyword matching relies on a manually curated set of predefined patterns. Systematic expansion could improve coverage:
\begin{itemize}
    \item \textbf{Automated keyword extraction}: Mining the lookup tables to identify high-frequency discriminative terms
    \item \textbf{Synonym expansion}: Incorporating synonyms and related terms (e.g., "developer" $\leftrightarrow$ "programmer", "chief" $\leftrightarrow$ "director")
    \item \textbf{Abbreviation handling}: Explicit mapping of common abbreviations ("VP" $\rightarrow$ "Vice President", "CEO" $\rightarrow$ "Chief Executive Officer")
    \item \textbf{Domain-specific terminology}: Industry-specific role variations ("Full Stack Engineer" vs. "Software Engineer")
\end{itemize}

\paragraph{Multilingual Support}
The current implementation is predominantly English-centric, limiting performance on German, French, Spanish, and other European job titles present in the dataset (~40\% non-English content). Potential improvements include:
\begin{itemize}
    \item \textbf{Language detection}: Automatic identification of input language to apply language-specific rules
    \item \textbf{Translation normalization}: Translating non-English titles to English before matching, or maintaining multilingual lookup tables
    \item \textbf{Language-agnostic keywords}: Identifying cognates and internationally recognized terms ("Manager", "Director", "Engineer")
    \item \textbf{Cross-lingual fuzzy matching}: Adapting similarity thresholds based on linguistic distance
\end{itemize}

\paragraph{Context-Aware Matching}
Current matching considers only job titles in isolation. Additional context could improve disambiguation:
\begin{itemize}
    \item \textbf{Company information}: Organization type and industry could inform department assignment (e.g., "Consultant" in IT company vs. consulting firm)
    \item \textbf{Career trajectory analysis}: Temporal patterns in job history could constrain seniority predictions
    \item \textbf{Title component parsing}: Decomposing compound titles into seniority prefix + function + department suffix
\end{itemize}

\paragraph{Hybrid Rule-ML Approaches}
Combining rule-based matching with machine learning could leverage strengths of both paradigms:
\begin{itemize}
    \item \textbf{Confidence-based delegation}: Using ML models only when rule-based confidence is low
    \item \textbf{Active learning for lookup table expansion}: Identifying high-confidence ML predictions to add to lookup tables
    \item \textbf{Ensemble methods}: Combining rule-based predictions with embedding similarity scores
\end{itemize}

These enhancements would address the identified limitations while maintaining the computational efficiency and interpretability advantages of the rule-based approach.
