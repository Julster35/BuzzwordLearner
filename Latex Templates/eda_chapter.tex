\subsection{Exploratory Data Analysis (EDA)}
\label{sec:eda}

The exploratory data analysis serves to systematically investigate the BuzzwordLearner dataset for predicting career domains and seniority levels from LinkedIn profiles. The goal is to develop a comprehensive understanding of the data structure, distributions, and potential challenges for modeling.

\subsubsection{Dataset Overview}
\label{subsec:dataset-overview}

The dataset consists of four main components:
\begin{itemize}
    \item \textbf{Annotated LinkedIn CVs}: 1,000 resumes with manually assigned department and seniority labels
    \item \textbf{Non-annotated LinkedIn CVs}: 200 resumes for inference without ground-truth labels
    \item \textbf{Department Label Dictionary}: approx. 10,000 job title $\rightarrow$ department mappings
    \item \textbf{Seniority Label Dictionary}: approx. 9,000 job title $\rightarrow$ seniority mappings
\end{itemize}

Each resume is structured as a list of positions, where each position contains the following attributes: \texttt{organization}, \texttt{position} (job title), \texttt{startDate}, \texttt{endDate}, \texttt{status} (ACTIVE/INACTIVE/UNKNOWN), as well as the target variables \texttt{department} and \texttt{seniority} (only in annotated data).

\subsubsection{Career History Patterns}
\label{subsec:career-patterns}

The analysis of career trajectories reveals the following characteristics:
\begin{itemize}
    \item \textbf{Positions per CV}: On average, resumes contain 4.5 positions (median: 4), with a range from 1 to 20 positions
    \item \textbf{Active positions}: 1,430 active positions form the training dataset
    \item \textbf{Multiple employments}: Approx. 8\% of individuals have multiple active positions simultaneously
\end{itemize}

The focus on active positions (status = ACTIVE) aligns with the task of classifying the current professional situation.

\subsubsection{Department Distribution}
\label{subsec:department-distribution}

The analysis of department labels reveals a significant \textbf{class imbalance} in the active positions:
\begin{table}[h]
\centering
\begin{tabular}{lr}
\toprule
\textbf{Department} & \textbf{Proportion (\%)} \\
\midrule
Other & 55.22 \\
Information Technology & 9.95 \\
Sales & 7.38 \\
Consulting & 6.26 \\
Project Management & 6.26 \\
Marketing & 3.53 \\
Business Development & 3.21 \\
Human Resources & 2.57 \\
Purchasing & 2.41 \\
Administrative & 2.25 \\
Customer Support & 0.96 \\
\bottomrule
\end{tabular}
\caption{Distribution of departments in active positions}
\label{tab:department-distribution}
\end{table}

\textbf{Modeling implication}: The dominance of "Other" (55\%) as a catch-all category requires class weighting or resampling techniques to avoid bias toward the majority class.

\subsubsection{Seniority Distribution}
\label{subsec:seniority-distribution}

In contrast to departments, the seniority distribution shows a more balanced structure:
\begin{table}[h]
\centering
\begin{tabular}{lr}
\toprule
\textbf{Seniority Level} & \textbf{Proportion (\%)} \\
\midrule
Professional & 34.7 \\
Management & 30.8 \\
Lead & 20.1 \\
Senior & 7.1 \\
Director & 5.5 \\
Junior & 1.9 \\
\bottomrule
\end{tabular}
\caption{Distribution of seniority levels in the annotated dataset}
\label{tab:seniority-distribution}
\end{table}

All seniority levels are represented, with Professional and Management positions expectedly dominating.

\subsubsection{Text Characteristics of Position Titles}
\label{subsec:text-characteristics}

Position titles are compact: average 35 characters (median: 32) and 3.5 words (median: 3), mostly 2--5 words. This limited context poses challenges for language models and requires approaches that effectively handle few but informative tokens.

\subsubsection{Multilinguality}
\label{subsec:multilingualism}

The dataset contains multiple languages (English $\sim$60\%, German $\sim$25\%, others $\sim$15\%). Language detection is challenging due to the short text lengths of position titles, which often contain only 2--5 words. This makes clear language separation difficult, as titles may mix languages or lack sufficient context for reliable classification. Despite these challenges, addressing multilinguality is crucial for model performance. The approach requires multilingual embeddings (e.g., \texttt{paraphrase-multilingual-MiniLM-L12-v2}) and language-agnostic features to ensure robust predictions across all languages.

\subsubsection{Label Dictionary Analysis}
\label{subsec:label-dictionaries}

The provided dictionaries contain 10,000+ department and 9,000+ seniority mappings with text characteristics similar to the actual position titles (avg. 28--30 characters). These enable rule-based baseline approaches and can serve as additional features for supervised models.

\subsubsection{Comparison of Annotated and Non-Annotated Datasets}
\label{subsec:dataset-comparison}

Both datasets show consistent patterns: similar positions per CV (4.3 vs. 4.5), comparable title lengths, and matching language/status distributions. This homogeneity suggests good model generalization from training to inference data.

\subsubsection{Key Findings and Implications}
\label{subsec:key-findings}

In summary, the following essential findings emerge with relevance for modeling:

\begin{enumerate}
    \item \textbf{Class imbalance for departments}: Requires special treatment (class weighting, SMOTE, stratified sampling)
    
    \item \textbf{Short text sequences}: Limit contextual information; concise representations necessary
    
    \item \textbf{Multilingual data}: Mandatory: Use of multilingual models or language-independent features
    
    \item \textbf{Available label dictionaries}: Enable hybrid approaches combining rule-based matching and machine learning
    
    \item \textbf{Sufficient data volume}: 1,430 active positions provide a solid basis for supervised learning, especially with transfer learning
    
    \item \textbf{Homogeneous distributions}: Training and inference datasets are structurally consistent
\end{enumerate}

These findings guide the choice of modeling strategies: A combination of rule-based baselines, embedding-based similarity methods, and fine-tuning of pre-trained transformer models appears promising.
